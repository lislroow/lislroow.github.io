[{"body":"1. 이클립스 기본 단축키 이클립스에 기본으로 등록된 단축키 목록입니다.\n중요도에 따라 ★를 표시했습니다.\n1.1 Ctrl + K (★★★)   블록 선택된 단어가 다음에 일치하는 곳을 찾아갑니다.\n  Ctrl + Shift + K 일 경우 역방향으로 실행됩니다.\n  대소문자 구분 옵션을 설정하려면 Ctrl + F 찾기에서 Case sentive 옵션을 선택해야합니다.\nWhole word 옵션으로 온전한 단어일 경우에만 검색되는 옵션도 있습니다.\n새 창 보기\n  1.2 Ctrl + Alt + DOWN (★★☆)   블록 선택된 라인(혹은 커서가 있는 행)을 복제합니다.\n  DOWN 은 방향키를 의미합니다.\n  DOWN 일 경우 아래에 복제하고, UP 일 경우 위에 복제합니다.\n새 창 보기   1.3 Ctrl + Alt + A (★★★)   블록 선택을 반전시키는 기능입니다.\n  일반 모드일 경우에는 행을 선택하는 형태이고, 컬럼 단위로 선택을 하기 위해 사용합니다.\n새 창 보기   1.4 Ctrl + Shift + G (★★★)   유틸리티 클래스를 리팩토링 할 경우 영향도 체크를 위해 반드시 익혀야 합니다.\n  References in Workspace 라는 기능입니다.\n기본 설명은 Search for references to the selected element in the workspace 라고 되어 있습니다.\n  java 의 클래스, 메소드, 변수가 참조되고 있는 파일의 라인을 찾아 줍니다.\n  주로 프레임워크/공통 개발 시 제공된 클래스가 업무서비스의 어디서 참조되고 있는지를 검색해야 할 때 사용하면 좋습니다.\n새 창 보기\n  1.5 Alt + LEFT (★☆☆)  이전에 활성화 했었던 파일을 re-open 해줍니다. Ctrl + W 로 에디터에 열려진 파일을 닫은 직후 다시 열어야할 때 유용합니다. RIGHT 일 경우는 LEFT 의 반대 방향입니다.  1.6 Ctrl + PAGEUP (★☆☆)  현재 활성화된 탭의 왼쪽 탭을 활성화 시킵니다. 에디터에 매우 많은 파일이 열려있을 경우 탭간의 이동을 마우스 클릭으로 이동하기 번거로울 경우 사용할 수 있습니다.\n개발의 집중도를 높이기 위해 관련없는 파일들은 수정이 끝나면 Ctrl + W 로 탭을 닫는 습관을 들이도록 해야겠습니다. PAGEDOWN 일 경우는 PAGEUP 의 반대 방향, 오른쪽 탭을 활성화합니다.  1.7 Ctrl + Q (☆☆☆)   이전에 수정했던 파일의 라인으로 이동합니다.\n새 창 보기   1.8 Ctrl + T (☆☆☆)   java 클래스의 상속 구조를 봐야하는 경우 사용됩니다.\nextends 에 대한 구조를 보여주며, implements 에 대한 구조는 보여주지 않습니다.\n  프레임워크/공통 개발 시 오픈소스 라이브러리를 상속받고 구현체 클래스를 생성하는 경우가 많기에 알아둬야 겠습니다.\n새 창 보기   1.8 Ctrl + L (★☆☆)   editing 중인 파일의 해당 라인으로 이동하는 기능입니다.\n새 창 보기   1.9 Ctrl + Shift + R (★★★)   이클립스 프로젝트에서 파일명으로 파일을 찾아서 open 하는 기능입니다.\n  매우 사용 빈도가 높기에 필수로 기억해둬야 할 것입니다.\n새 창 보기   1.10 Ctrl + = (☆☆☆)  이클립스 에디터의 font 크기를 변경하는 기능입니다. (= 은 더 크게, -는 더 작게) 메뉴를 통해 font 크기를 변경하려면,\nWindow \u003e Preferences \u003e General \u003e Appearance \u003e Colors and Fonts 로 이동한 다음\nBasic \u003e Text Font 에서 변경할 수 있습니다. 코드 리뷰 시간에 일시적으로 font 크기를 조절해야 할 경우 이 단축키를 사용할 것을 권합니다. 단축키 Ctrl + = 에서 = 는 키보드의 숫자 라인에 + 와 같이 있는 키 입니다.  1.11 Ctrl + Alt + Shifh + L (★★☆)   이클립스에 기본 탑재된 Quick Search 기능입니다.\n이클립스 InstaSearch 플러그인과 유사합니다.\n  검색할 문자열을 블록 선택한 다음 Ctrl + Alt + Shifh + L 을 입력하면 팝업이 open 되면서 검색이 시작됩니다.\n새 창 보기\n  2. svn 단축키 2.1 Ctrl + Alt + L (★★★)   현재 editing 중인 파일이 svn 저장소에 commit 된 파일과 비교를 합니다.\n  commit 을 하기전에는 무엇이 변경되었는지 빠르게 확인을 하기 위해 자주 사용되는 diff 단축키 입니다.\n새 창 보기\n  2.2 Ctrl + Alt + S (★★★)   svn 저장소와 동기화 단축키 입니다.\n  project explorer 에서 이클립스 프로젝트를 선택한 다음\n우클릭 \u003e Team \u003e Synchronized with Repository 를 선택하는 것과 동일합니다.\n마우스 클릭으로 sync 를 하기 위해서는 번거롭다고 생각하시면 익혀두셔야 겠습니다.\n  svn-commit(Ctrl + Alt + C), svn-update(Ctrl + Alt + U) 에 대한 단축키도 익혀두시면 좋겠습니다.\n새 창 보기\n  3. anyedit 플러그인 단축키 3.1 Ctrl + Alt + K (★☆☆)   camelcase 와 underscore-case 를 변환해주는 기능입니다.\n  두 가지 case 에 대한 예시 입니다.\n# e.g employName 은 camelcase 이고, employ_name 는 underscore-case 입니다.   oracle 에서는 컬럼에 대해 대소문자가 구분이되지 않기 때문에 underscore-case 표기법을 사용하게 됩니다.\njava 에서는 oracle 컬럼에 대응되는 변수를 생성할 때\ncamelcase 를 사용하는 경우가 일반적이므로 이 기능의 활용도가 있을 것으로 예상합니다.\n  사용법은 변환할 문자열을 블록 선택한 다음 Ctrl + Alt + K 를 입력하면 됩니다.\n  4. 사용자 지정 단축키 개발을 하면서 자주 사용되는 기능에 대해 설정한 단축키 입니다.\n사용자 지정 단축키는 User 부분에 U 라고 표시가 되어 있습니다.\n만일 기존 단축키와 충돌이 발생할 경우 C 라는 문자가 같이 포함되어 있으며,\n해제 하고자 하는 명령을 선택하고 Unbind Command 버튼을 클릭하면 해제할 수 있게 됩니다.\n새 창 보기\n4.1 Ctrl + Alt + H (★★☆)   project explorer 에서 선택된 파일 혹은 디렉토리의 svn 에 commit 된 history 를 볼 수 있습니다.\n  특정 파일을 편집 상태에서도 Ctrl + Alt + H 를 입력하면, 편집 중인 파일의 svn-history 를 볼 수 있습니다.\n새 창 보기\n  4.2 Alt + C (★☆☆)   이클립스 프로젝트를 다시 build(compile) 해야할 때 clean 을 사용되는 단축키 입니다.\n  프로젝트를 선택한 상태에서 Alt + C 를 입력하면 선택된 프로젝트가 Clean 대상으로 체크가 되어있습니다.\n  java 파일을 editing 하는 상태에서 Alt + C 를 입력하면 현재 파일을 포함하는 프로젝트가 Clean 대상으로 체크됩니다.\n새 창 보기\n  4.3 Alt + U (★★★)  maven 프로젝트에서는 pom.xml 이 변경이 있거나, 의존성 library 의 최신 버전을 받아오기 위해 maven-update 를 자주 하게 됩니다. 이클립스 기본 단축키는 Alt + F5 이며, F5 키가 접근이 용이하지 않아 Alt + U 단축키를 별도로 추가했습니다.  5. 단축키 설정 방법 5.1 설정창 이동 이클립스 상단 context 메뉴에서 Window \u003e Preferences 를 선택합니다. (Preferences 창이 열림)\nPreferences 창에서 General \u003e Keys 를 선택하면 단축키 설정 화면이 보입니다.\n새 창 보기\n5.2 binding 상태 확인 검색 영역에서 binding 으로도 검색이 가능합니다.\n새 창 보기\n5.3 단축키 변경 단축키를 변경하기 위해서는 Binding 에서 단축키를 직접 입력합니다.\nWhen 은 In Windows 를 선택해주세요.\n새 창 보기\n참고로 Editing Text 일 경우 텍스트를 편집할 때에만 적용된다는 의미가 됩니다.\n아래는 기존 단축키를 유지하면서 새로운 단축키를 하나 더 설정하는 방법입니다.\n(이클립스에 기본으로 Binding 된 단축키는 가급적이면 그대로 유지할 것을 권합니다.)\n새 창 보기\n5.4 Ctrl + Shift + L   단축키 목록을 우측 하단에 표시 합니다.\n  한 번 더 Ctrl + Shift + L 를 입력하면 단축키 설정 창을 open 합니다.\n새 창 보기   ","categories":"","description":"","excerpt":"1. 이클립스 기본 단축키 이클립스에 기본으로 등록된 단축키 목록입니다.\n중요도에 따라 ★를 표시했습니다.\n1.1 Ctrl + …","ref":"/localenv/04_%EC%B0%B8%EA%B3%A0_eclipse-%EB%8B%A8%EC%B6%95%ED%82%A4/","tags":"","title":"04_참고_eclipse-단축키"},{"body":" apache 로그파일 \u003e filebeat \u003e logstash \u003e elastic 저장 과정에 대한 이해\n apache 로그에 대한 포맷 logstash 의 filter elastic 에 저장된 내용을 kibana 에서 조회   apache 로그 로그 포맷 \u003cVirtualHost *:443\u003e ServerName nexus # combined 포맷은 httpd.conf 에 정의되어 있음 LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/nexus_ssl-access.log.%Y-%m-%d 86400 +540%\" combined ... 로그 설명 combined 라는 이름의 \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" 형식을 풀이하면 이렇다.\n   포맷 설명     %h 원격 호스트 이름   %l ident 인증으로 알아낸 os 의 사용자명 rfc14   %u http 인증으로 알아낸 사용자ID   %r 요청 uri (%m %U%q %H 와 같다.)   %\u003es http status   %b 클라이언트에 보낸 http body 의 byte 크기   %{Referer}i http header 명 Referer의 값   %{User-Agent}i http header 명 User-Agent의 값    로그 예시 $ curl -X GET https://nexus/repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml # apache 로그 172.28.200.30 - - [29/Jan/2022:22:35:05 +0900] \"GET /repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml HTTP/1.1\" 200 599 \"-\" \"curl/7.61.1\" # kibana 에서 grok pattern: %{COMBINEDAPACHELOG} { \"request\": \"/repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml\", \"agent\": \"\\\"curl/7.61.1\\\"\", \"auth\": \"-\", \"ident\": \"-\", \"verb\": \"GET\", \"referrer\": \"\\\"-\\\"\", \"response\": \"200\", \"bytes\": \"599\", \"clientip\": \"172.28.200.30\", \"httpversion\": \"1.1\", \"timestamp\": \"29/Jan/2022:22:35:05 +0900\" } 로그 포맷 추가 combined 포맷에 http header txid 를 추가 후 curl 테스트\ntxid 가 포함된 로그를 kibana grok debugger 에서 %{COMBINEDAPACHELOG} \u003e %{COMBINEDAPACHELOG} \\\"%{GREEDYDATA:txid}\\\" 로 테스트\n$ vi /etc/httpd/conf.d/vhost-nexus.conf \u003cVirtualHost *:443\u003e ServerName nexus # combined_nexus 포맷에 \"txid\" 추가 # LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" \\\"%{txid}i\\\"\" combined_nexus # access log 의 포맷을 combined_nexus 로 변경 CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/nexus_ssl-access.log.%Y-%m-%d 86400 +540%\" combined_nexus ... $ systemctl restart httpd $ curl -X GET -H \"txid: t1hruu5xl7le0o\" https://nexus/repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml # apache 로그 172.28.200.30 - - [29/Jan/2022:22:43:39 +0900] \"GET /repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml HTTP/1.1\" 200 599 \"-\" \"curl/7.61.1\" \"t1hruu5xl7le0o\" # kibana 에서 grok pattern: %{COMBINEDAPACHELOG} \\\"%{GREEDYDATA:txid}\\\" { \"request\": \"/repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml\", \"agent\": \"\\\"curl/7.61.1\\\"\", \"auth\": \"-\", \"ident\": \"-\", \"verb\": \"GET\", \"txid\": \"t1hruu5xl7le0o\", \"referrer\": \"\\\"-\\\"\", \"response\": \"200\", \"bytes\": \"599\", \"clientip\": \"172.28.200.30\", \"httpversion\": \"1.1\", \"timestamp\": \"29/Jan/2022:22:43:39 +0900\" } kibana grok debugger 에서 txid 를 parsing 하기 위해 %{GREEDYDATA:txid} 를 사용함\ngrok 패턴: %{GREEDYDATA} github: https://github.com/logstash-plugins/logstash-patterns-core.git\ngrok-patterns\n$ git pull https://github.com/logstash-plugins/logstash-patterns-core.git $ find ./logstash-patterns-core/patterns/ -type f | grep grok | xargs grep -E \"^[^#\\ ]\" | grep 'GREEDYDATA' ./logstash-patterns-core/patterns/ecs-v1/grok-patterns:GREEDYDATA .* ./logstash-patterns-core/patterns/legacy/grok-patterns:GREEDYDATA .* $ head -n 5 ./logstash-patterns-core/patterns/legacy/grok-patterns USERNAME [a-zA-Z0-9._-]+ USER %{USERNAME} EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+ EMAILADDRESS %{EMAILLOCALPART}@%{HOSTNAME} INT (?:[+-]?(?:[0-9]+)) $ find ./logstash-patterns-core/patterns/ -type f | xargs grep -E \"^[^#\\ ]\" | grep 'COMBINEDAPACHELOG' ./logstash-patterns-core/patterns/legacy/httpd:COMBINEDAPACHELOG %{HTTPD_COMBINEDLOG} logstash filter 에 “txid” 추가  filebeat 테스트 준비  # \"weblog.txt-txid\" 파일을 읽도록 수정 $ vi /etc/filebeat/filebeat.yml paths: #- /var/log/*.log #- /root/ls-test/weblog.txt - /root/ls-test/weblog.txt-txid $ # \"weblog.txt-txid\" 파일 생성 $ cat \u003c\u003c EOF \u003e /root/ls-test/weblog.txt-txid 172.28.200.30 - - [29/Jan/2022:22:43:39 +0900] \"GET /repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml HTTP/1.1\" 200 599 \"-\" \"curl/7.61.1\" \"t1hruu5xl7le0o\" EOF $  logstash 테스트 준비  kibana grok debugger 에서 테스트가 완료된 패턴을 logstash 에 추가\n# grok \u003e match 의 message 에 \\\"%{GREEDYDATA:txid}\\\" 추가 $ vi /etc/logstash/conf.d/exam_filebeat.conf filter { mutate { remove_field =\u003e [\"agent\"] } grok { #match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG} \\\"%{GREEDYDATA:txid}\\\"\" } $  logstash 및 filebeat 재시작  $ systemctl stop logstash $ systemctl stop filebeat $ vi /etc/filebeat/filebeat.yml $ rm -rf /data/PROD/filebeat/* $ systemctl start logstash $ systemctl start filebeat  kibana 에서 조회  #GET _cat/indices/mgkim*?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open mgkim-apache-log-2022.01.29 DvbnByKXS9a56Rn8Vb_RMg 1 1 1 0 19.4kb 19.4kb GET mgkim-apache-log-2022.01.29/_search { \"took\" : 0, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1, \"relation\" : \"eq\" }, \"max_score\" : 1.0, \"hits\" : [ { \"_index\" : \"mgkim-apache-log-2022.01.29\", \"_type\" : \"_doc\", \"_id\" : \"9uPYqX4BOw_Yo7UZd8Fg\", \"_score\" : 1.0, \"_source\" : { \"tags\" : [ \"beats_input_codec_plain_applied\", \"_geoip_lookup_failure\" ], \"bytes\" : 599, \"ecs\" : { \"version\" : \"1.12.0\" }, \"useragent\" : { \"minor\" : \"61\", \"device\" : \"Other\", \"os_name\" : \"Other\", \"os_full\" : \"Other\", \"major\" : \"7\", \"version\" : \"7.61.1\", \"name\" : \"curl\", \"os\" : \"Other\", \"patch\" : \"1\" }, \"response\" : \"200\", \"auth\" : \"-\", \"clientip\" : \"172.28.200.30\", \"ident\" : \"-\", \"log\" : { \"offset\" : 0, \"file\" : { \"path\" : \"/root/ls-test/weblog.txt-txid\" } }, \"message\" : \"172.28.200.30 - - [29/Jan/2022:22:43:39 +0900] \\\"GET /repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml HTTP/1.1\\\" 200 599 \\\"-\\\" \\\"curl/7.61.1\\\" \\\"t1hruu5xl7le0o\\\"\", \"referrer\" : \"\\\"-\\\"\", \"httpversion\" : \"1.1\", \"request\" : \"/repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml\", \"txid\" : \"t1hruu5xl7le0o\", \"geoip\" : { }, \"verb\" : \"GET\", \"input\" : { \"type\" : \"log\" }, \"@timestamp\" : \"2022-01-29T13:43:39.000Z\" } } ] } } #grok { # patterns_dir =\u003e [ \"패턴파일경로\" ] # match =\u003e { # \"message\" =\u003e { \"%{COMBINEDAPACHELOG} \\\"%{GREEDYDATA:txid}\\\"\" } # }  elastic logstash: https://www.elastic.co/kr/blog/a-practical-introduction-to-logstash grok 테스트: http://grokdebug.herokuapp.com regex 테스트: https://regex101.com regex 참고1: https://velog.io/@koseungbin/%EC%A0%95%EA%B7%9C-%ED%91%9C%ED%98%84%EC%8B%9D regex 참고2: https://heropy.blog/2018/10/28/regexp/  172.28.200.30 - - [29/Jan/2022:22:43:39 +0900] “GET /repository/maven-snapshot/mgkim/framework/framework-core/maven-metadata.xml HTTP/1.1” 200 599 “-” “curl/7.61.1” “t1hruu5xl7le0o|s1jetbjlo0kpx0” %{COMBINEDAPACHELOG} \"%{GREEDYDATA:txid}|%{GREEDYDATA:ssid}\"\n","categories":"","description":"","excerpt":" apache 로그파일 \u003e filebeat \u003e logstash \u003e elastic 저장 과정에 대한 이해\n apache 로그에  …","ref":"/elk/20220129-apache_log/","tags":"","title":"2022.01.29"},{"body":" elasticsearch 의 index 의 _mapping 을 수정하여 특정 field 관리할 수 있도록 정리\n mapping 기존 index mgkim-apache-log-2022.01.29로 신규 index mgkim-apache-log-remapping 생성\n기존 index 의 mapping 정보 조회 GET mgkim-apache-log-2022.01.29/_mapping \"mappings\": {...} 를 전체 복사하여 신규 index 를 편집하는곳에 붙여넣기로 시작\n새 창 보기\n신규 index 생성 mappings 편집 항목\n\"auth\": \"text\" \u003e \"auth\": \"keyword\": 집계만하기 위해 변경\nPUT mgkim-apache-log-remapping 새 창 보기\nreindex POST _reindex { \"source\": { \"index\": \"mgkim-apache-log-2022.01.29\" }, \"dest\": { \"index\": \"mgkim-apache-log-mapping\" } } 웹 어플리케이션 vhost-dwww.conf 로그 포맷 변경 (combined + ROUTEID + txid + ssid)\nLogFormat “%h %l %u %t \"%r\" %\u003es %b \"%{Referer}i\" \"%{User-Agent}i\"” \"%{ROUTEID}C\" \"%{txid}i|%{ssid}i\"\" combined_trace\nHeader add Set-Cookie “ROUTEID=%{BALANCER_WORKER_ROUTE}e; path=/” env=BALANCER_ROUTE_CHANGED\n\u003cVirtualHost *:80\u003e ServerName dwww LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" \\\"%{ROUTEID}C\\\" \\\"%{txid}i|%{ssid}i\\\"\" combined_trace ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dwww-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dwww-access.log.%Y-%m-%d 86400 +540\" combined_trace AllowEncodedSlashes On # reverse proxy 사용 시 Off ProxyRequests Off ProxyPreserveHost On # BALANCER_WORKER_ROUTE: BalancerMember 의 route 값을 쿠키에 포함 (dwww11, dwww12) Header add Set-Cookie \"ROUTEID=%{BALANCER_WORKER_ROUTE}e; path=/\" env=BALANCER_ROUTE_CHANGED Header set Access-Control-Allow-Origin \"*\" \u003cProxy balancer://cluster\u003e BalancerMember http://127.0.0.1:7100 route=dwww11 BalancerMember http://127.0.0.1:7101 route=dwww12 ProxySet stickysession=ROUTEID ## lbmethod # byrequests: 요청별 분배 # bytraffic: byte 트래픽 가중치 분배 # bybusyness: 보류중 요청 분배 #ProxySet lbmethod=byrequests \u003c/Proxy\u003e ProxyPass / balancer://cluster/ ProxyPassReverse / balancer://cluster/ \u003c/VirtualHost\u003e ","categories":"","description":"","excerpt":" elasticsearch 의 index 의 _mapping 을 수정하여 특정 field …","ref":"/elk/20220130-elastic_mappings/","tags":"","title":"2022.01.30"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"1. 서비스 1.1 port systemd: /etc/systemd/system/*.service\n   service port user running execute connect     httpd 80 apache:web automatically httpd.service -   cockpit 8000 root:root automatically cockpit.socket https://centos8/   nexus 8100 nexus:ci automatically nexus.service https://nexus/   elasticsearch 8200 elasticsearch:- automatically elasticsearch.service -   kibana 8300 kibana:- automatically kibana.service http://kibana/   jenkins 8400 jenkins:ci automatically jenkins.service http://jenkins/   logstash 9600 logstash:- automatically logstash.service -   logstash 10000 logstash:- automatically logstash.service tcp:10000   logstash 11000 logstash:- automatically logstash.service filebeat:11000   oracle(dbms) - oracle:oinstall automatically ora12c@dbms.service -   oracle(lsnrctl) 1521 oracle:oinstall automatically ora12c@lsnrctl.service -   svn 3690 root:root manually start-svn.sh -    1.2 주요 파일    service 경로 내용 보기     httpd /etc/httpd/conf.d/*.conf 다운로드   cockpit /etc/systemd/system/sockets.target.wants/cockpit.socket 새 창 보기   nexus /prod/nexus/nexus-3.28.1-01/* 새 창 보기   elasticsearch /etc/elasticsearch/elasticsearch.yml 새 창 보기   kibana /etc/kibana/kibana.yml 새 창 보기   jenkins /prod/jenkins/jenkins.sh 새 창 보기   logstash /etc/logstash/conf.d/*.conf 새 창 보기   oracle(dbms) - 생략   oracle(lsnrctl) - 생략   svn /root/bin/start-svn.sh 새 창 보기   maven /prod/maven/maven-3.6.3/conf/settings.xml 새 창 보기    2. 패키지    패키지     cockpit   mosh   xmlstarlet   cloud-utils-growpart    전체 목록(yum): yum list installed\n새 창 보기\n","categories":"","description":"","excerpt":"1. 서비스 1.1 port systemd: /etc/systemd/system/*.service\n   service port …","ref":"/system/centos8/","tags":"","title":"centos8"},{"body":"\rdev-log\rgithub \r\r\r\r\r\r\r\r\r","categories":"","description":"","excerpt":"\rdev-log\rgithub \r\r\r\r\r\r\r\r\r","ref":"/","tags":"","title":"dev-log"},{"body":"","categories":"","description":"","excerpt":"","ref":"/elk/","tags":"","title":"ELK"},{"body":"elasticsearch 설치 artifacts.elastic.co 에서 rpm 다운로드 후 설치\n$ curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.3-x86_64.rpm $ rpm -i elasticsearch-7.16.3-x86_64.rpm $ systemctl restart elasticsearch $ curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-7.16.3-linux-x86_64.tar.gz $ rpm -i elasticsearch-7.16.3-x86_64.rpm 경고: elasticsearch-7.16.3-x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID d88e42b4: NOKEY Creating elasticsearch group... OK Creating elasticsearch user... OK ### NOT starting on installation, please execute the following statements to configure elasticsearch service to start automatically using systemd sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service ### You can start elasticsearch service by executing sudo systemctl start elasticsearch.service warning: usage of JAVA_HOME is deprecated, use ES_JAVA_HOME Created elasticsearch keystore in /etc/elasticsearch/elasticsearch.keystore [/usr/lib/tmpfiles.d/elasticsearch.conf:1] Line references path below legacy directory /var/run/, updating /var/run/elasticsearch → /run/elasticsearch; please update the tmpfiles.d/ drop-in file accordingly. $ curl http://127.0.0.1:9200 { \"name\" : \"centos8\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"_e3hsZBwTtS2aAyJvCfqbA\", \"version\" : { \"number\" : \"7.16.3\", \"build_flavor\" : \"default\", \"build_type\" : \"rpm\", \"build_hash\" : \"4e6e4eab2297e949ec994e688dad46290d018022\", \"build_date\" : \"2022-01-06T23:43:02.825887787Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.10.1\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } $ \nelasticsearch 설정 설정 파일 /etc/elasticsearch/elasticsearch.yml에서 데이터/로그 디렉토리 변경\n## $ mkdir -p /data/PROD/es \u0026\u0026 chown elasticsearch:elasticsearch /data/PROD/es $ mkdir -p /data/PROD/es \u0026\u0026 chown elasticsearch:elasticsearch /outlog/PROD/es ##  33 #path.data: /var/lib/elasticsearch 34 path.data: /data/PROD/es 38 #path.logs: /var/log/elasticsearch 39 path.logs: /outlog/PROD/es 58 #network.host: 192.168.0.1 59 network.host: 0.0.0.0 73 #discovery.seed_hosts: [\"host1\", \"host2\"] 74 discovery.seed_hosts: [\"0.0.0.0\"] \nkibana 설치 (binary) artifacts.elastic.co에서 tar.gz 다운로드 후 아카이브 해제\n$ curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-7.16.3-linux-x86_64.tar.gz $ tar zxvf kibana-7.16.3-linux-x86_64.tar.gz $ mkdir -p /prod/kibana $ mv kibana-7.16.3-linux-x86_64 /prod/kibana $ cd /prod/kibana \u0026\u0026 ln -s kibana-7.16.3-linux-x86_64 kibana $ chown -R tomcat:ap /prod/kibana $ tree -L 2 . ├── kibana -\u003e kibana-7.16.3-linux-x86_64/ └── kibana-7.16.3-linux-x86_64 ├── LICENSE.txt ├── NOTICE.txt ├── README.txt ├── bin ├── config ├── data ├── node ├── node_modules ├── package.json ├── plugins ├── src └── x-pack 10 directories, 4 files $ \nkibana 설치 (yum) PGP 를 추가합니다.\n$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch vi /etc/yum.repos.d/kibana.repo 아래 내용을 추가합니다.\n[kibana-7.x] name=Kibana repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md yum 으로 kibana 를 설치합니다.\n$ yum install kibana systemd\n$ systemctl enable kibana $ systemctl start kibana \nkibana 설정 (binary) 설정 파일 /prod/kibana/kibana/config/kibana.yml\n# 기본 설정 파일로 실행 시 `server.publicBaseUrl` 에 대한 경고가 표시 됩니다. # \"server.publicBaseUrl\" 는 \"server.basePath\" 의 경로를 반드시 포함해야 합니다. 24 #server.publicBaseUrl: \"\" 25 server.publicBaseUrl: \"http://localhost:5601\" # logging off 103 #logging.silent: false 104 logging.silent: true www.elastic.co kibana 설정 가이드\nkibana 설정 (yum) 설정 파일 /etc/kibana/kibana.yml\nserver.port: 5601 server.publicBaseUrl: \"http://localhost:5601\" logging.silent: true rpm-layout\n 설정: /etc/kibana 로그: /var/log/kibana 데이터: /var/lib/kibana  로그 경로 변경 (/var/log/kibana \u003e /outlog/PROD/kibana)\n$ mkdir -p /outlog/PROD/kibana \u0026\u0026 chown kibana:kibana /outlog/PROD/kibana $ vi /etc/systemd/system/kibana.service 18 #ExecStart=/usr/share/kibana/bin/kibana --logging.dest=\"/var/log/kibana/kibana.log\" --pid.file=\"/run/kibana/kibana.pid\" 19 ExecStart=/usr/share/kibana/bin/kibana --logging.dest=\"/outlog/PROD/kibana/kibana.log\" --pid.file=\"/run/kibana/kibana.pid\" $ systemctl restart kibana Warning: The unit file, source configuration file or drop-ins of kibana.service changed on disk. Run 'systemctl daemon-reload' to reload units. $ systemctl daemon-reload $ systemctl restart kibana \nhttpd 가상호스트 설정\n\u003cVirtualHost *:80\u003e ServerName kibana ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/kibana-error.log.%Y-%m-%d 86400 +540%\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/kibana-access.log.%Y-%m-%d 86400 +540%\" combined AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" ProxyRequests Off ProxyPreserveHost On \u003cProxy *\u003e Require all granted \u003c/Proxy\u003e ProxyPass / http://localhost:5601/ # \"kibana.yml\" 파일 \"server.host\" 에 설정된 호스트로 할 것 ProxyPassReverse / http://localhost:5601/ \u003c/VirtualHost\u003e \nkibana는 elasticsearch 와 connect 가 되지 않은 상태일 경우 Kibana server is not ready yet 메시지가 표시됩니다.\n#/etc/kibana/kibana.yml #elasticsearch.hosts: [\"http://localhost:9200\"] elasticsearch.hosts: [\"http://localhost:8200\"] \nlogstash 설치 $ yum install logstash systemd\n$ systemctl enable logstash $ systemctl start logstash \nlogstash 설정 데이터 경로path.data, log 경로path.logs를 변경합니다.\n$ mkdir -p /outlog/PROD/logstash \u0026\u0026 chown logstash:logstash /outlog/PROD/logstash $ vi /etc/logstash/logstash.yml 28 #path.data: /var/lib/logstash 29 path.data: /data/PROD/logstash 87 # config.reload.automatic: false 88 config.reload.automatic: true 95 # config.reload.interval: 3s 96 config.reload.interval: 1s 269 #path.logs: /var/log/logstash 270 path.logs: /outlog/PROD/logstash $ mkdir /data/PROD/logstash \u0026\u0026 chown logstash:logstash /data/PROD/logstash $ mkdir /outlog/PROD/logstash \u0026\u0026 chown logstash:logstash /outlog/PROD/logstash logstash 서비스는 pipelines.yml 의 conf 파일 설정이 되었을때 start 를 하는 것을 권합니다.\nconf 파일이 없을 경우 config.reload.automatic: true에 의해 config.reload.interval: 1s 마다 아래와 같은 로그가 /outlog/PROD/logstash/logstash-plain.log 파일에 출력됩니다.\n[2022-01-28T11:09:33,537][INFO ][logstash.config.source.local.configpathloader] No config files found in path {:path=\u003e\"/etc/logstash/conf.d/*.conf\"} [2022-01-28T11:09:33,539][ERROR][logstash.config.sourceloader] No configuration found in the configured sources. \nlogstash 설정 (pipelines.yml) logstash 는 /etc/logstash/pipelines.yml 에는 conf 파일(input-filter-output 처리를 정의한 파일)의 경로를 설정합니다.\n기본 설치된 pipelines.yml 내용을 보면 다음과 같습니다.\n$ cat /etc/logstash/pipelines.yml # This file is where you define your pipelines. You can define multiple. # For more information on multiple pipelines, see the documentation: # https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html - pipeline.id: main path.config: \"/etc/logstash/conf.d/*.conf\" 아래와 같이 설정 파일을 추가하면 config.reload.automatic: true 설정에 의해 자동으로 conf 파일을 reload 합니다.\n$ cat \u003c\u003c EOF \u003e /etc/logstash/conf.d/exam_tcp.conf input { tcp { port =\u003e 10000 } } output { stdout {} } EOF $ $ ls -al /etc/logstash/conf.d/exam_tcp.conf -rw-r--r-- 1 root root 77 2022-01-28 01:59 /etc/logstash/conf.d/exam_tcp.conf $ exam_tcp.conf 파일을 추가했을 때와 port 를 10000 에서 10001 로 변경했을 때에 대한 로그입니다.\n[2022-01-28T11:09:35,939][INFO ][logstash.javapipeline ][main] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e4, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e500, \"pipeline.sources\"=\u003e[\"/etc/logstash/conf.d/exam_tcp.conf\"], :thread=\u003e\"#\u003cThread:0x9fd78a8 run\u003e\"} [2022-01-28T11:09:35,967][INFO ][logstash.javapipeline ][main] Pipeline Java execution initialization time {\"seconds\"=\u003e0.03} [2022-01-28T11:09:35,982][INFO ][logstash.javapipeline ][main] Pipeline started {\"pipeline.id\"=\u003e\"main\"} [2022-01-28T11:09:35,984][INFO ][logstash.inputs.tcp ][main][d83c273d53113db5c7c05a26049443aedcdfcd34e3deae0d6abd509db45a5e87] Starting tcp input listener {:address=\u003e\"0.0.0.0:10000\", :ssl_enable=\u003efalse} [2022-01-28T11:09:35,987][INFO ][logstash.agent ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]} [2022-01-28T11:10:40,988][INFO ][logstash.pipelineaction.reload] Reloading pipeline {\"pipeline.id\"=\u003e:main} [2022-01-28T11:10:45,149][INFO ][logstash.javapipeline ][main] Pipeline terminated {\"pipeline.id\"=\u003e\"main\"} [2022-01-28T11:10:46,510][INFO ][logstash.javapipeline ][main] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e4, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e500, \"pipeline.sources\"=\u003e[\"/etc/logstash/conf.d/exam_tcp.conf\"], :thread=\u003e\"#\u003cThread:0x58a6a0d5 run\u003e\"} [2022-01-28T11:10:46,529][INFO ][logstash.javapipeline ][main] Pipeline Java execution initialization time {\"seconds\"=\u003e0.02} [2022-01-28T11:10:46,543][INFO ][logstash.javapipeline ][main] Pipeline started {\"pipeline.id\"=\u003e\"main\"} [2022-01-28T11:10:46,543][INFO ][logstash.inputs.tcp ][main][735f4ed1b2193b470c8f3f5019940dab9a73e81dbd8046b87dd2d15ff6bf5850] Starting tcp input listener {:address=\u003e\"0.0.0.0:10001\", :ssl_enable=\u003efalse} [2022-01-28T11:10:46,559][INFO ][logstash.agent ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]} \nlogstash 이해 실행파일/usr/share/logstash/bin/logstash이 PATH 에 추가하는 것을 권합니다.\nexport LOGSTASH_HOME=/usr/share/logstash export PATH=$PATH:/usr/local/go/bin:$LOGSTASH_HOME/bin logstash 가 동작하는 방식을 이해하기 위한 단계별 예시입니다.\n# logstash daemon 을 실행합니다. # -e 파라미터에는 매우 단순한 표준 입출력을 정의했습니다. # daemon  $ logstash -e ' input { stdin {} } output { stdout {} }' \n별도의 터미널을 열고 logstash 9900 에 “hello logstash” 문자열을 nc(netcat)명령어로 전송해봅니다.\n$ echo \"hello logstash\" | nc localhost 9900 logstash 콘솔에서는 “hello logstash” 문자열을 stdout 으로 출력한 문자열을 볼 수 있습니다.\n{ \"@version\" =\u003e \"1\", \"host\" =\u003e \"localhost\", \"port\" =\u003e 64924, \"message\" =\u003e \"hello logstash\", \"@timestamp\" =\u003e 2022-01-26T16:20:17.308Z } exam_tpc.ls 라는 텍스트 파일을 생성하고 logstash daemon 을 실행합니다.\n$ cat \u003c\u003c EOF \u003e exam_tcp.ls input { tcp { port =\u003e 9900 } } output { stdout {} } EOF $ logstash -f exam_tcp.ls nc 명령으로 “hello” 문자열을 전송해봅니다.\n$ echo \"hello\" | nc localhost 9900 { \"@version\" =\u003e \"1\", \"host\" =\u003e \"localhost\", \"port\" =\u003e 64924, \"message\" =\u003e \"hello\", \"@timestamp\" =\u003e 2022-01-26T16:30:27.908Z } logstash -f filename 형태로 실행했을 경우 filename에 변경이 있을 경우 자동으로 reload 하는 옵션을 추가 합니다.\n(logstash 를 systemctl 서비스로 실행하는 방식이 아니기에 아래 옵션을 추가해야 합니다.)\nlogstash -r -f filename\n$ logstash --help | grep '\\-r' -r, --config.reload.automatic Monitor configuration changes and reload apache access 로그파일을 하나 준비합니다.\n(참고로 apache 로그파일의 레이아웃은 기본이어야 합니다.)\n로그파일의 1번째 행을 읽어들이고 9900 으로 전송하고 logstash 에서 처리한 로그를 확인합니다.\n“message” 필드에 보낸 문자열을 출력하고 있는 점을 확인하면 됩니다.\n$ cp /outlog/WEB/httpd/dwww-access.log.2022-01-09 weblog.txt $ head -n 1 weblog.txt | nc localhost 9900 { \"port\" =\u003e 65366, \"@version\" =\u003e \"1\", \"host\" =\u003e \"localhost\", \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"@timestamp\" =\u003e 2022-01-26T16:48:45.155Z } 이번에는 exam_filter.ls 파일을 생성하고, filter 에 grok을 이용하여 “message” 필드를 parsing 해보겠습니다.\ngrok 에 대한 설명은 아래 링크로 대체합니다.\n새 창 보기\ngrok-filter에 의해 message 가 parsing 된 결과를 확인할 수 있습니다.\n$ logstash -f exam_filter.ls $ cat \u003c\u003c EOF \u003e exam_filter.ls input { tcp { port =\u003e 9900 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } } output { stdout {} } EOF $ $ head -n 1 weblog.txt | nc localhost 9900 { \"httpversion\" =\u003e \"1.1\", \"host\" =\u003e \"localhost\", \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"referrer\" =\u003e \"\\\"http://dwww/status.html\\\"\", \"agent\" =\u003e \"\\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"ident\" =\u003e \"-\", \"@version\" =\u003e \"1\", \"clientip\" =\u003e \"218.39.220.90\", \"bytes\" =\u003e \"299\", \"timestamp\" =\u003e \"09/Jan/2022:17:52:49 +0900\", \"auth\" =\u003e \"-\", \"@timestamp\" =\u003e 2022-01-26T16:59:54.543Z, \"response\" =\u003e \"503\", \"port\" =\u003e 9122, \"verb\" =\u003e \"GET\", \"request\" =\u003e \"/resources/jquery.min.js\" } grok-filter에서 parsing 되어 생성된 필드인 \"clientip\"를 geoip-filter가 처리할 수 있도록 설정하고 테스트 해봅니다.\ngeoip-filter는 grok-filter 다음에 정의해야 한다는 것을 이해해야 합니다.\n처리 결과에 geoip 라는 필드에 하위 세부 정보가 출력되는 것을 확인할 수 있습니다.\ngeoip 에 대한 설명은 아래 링크로 대체 합니다.\n새 창 보기\n# grok 에서 parsing 된 정보 중 clientip 필드를 geoip 필터에 전달한다는 의미 $ cat \u003c\u003c EOF \u003e exam_filter.ls input { tcp { port =\u003e 9900 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } geoip { source =\u003e \"clientip\" } } output { stdout {} } EOF $ $ head -n 1 weblog.txt | nc localhost 9900 { \"auth\" =\u003e \"-\", \"@timestamp\" =\u003e 2022-01-26T17:08:31.046Z, \"response\" =\u003e \"503\", \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"port\" =\u003e 9306, \"ident\" =\u003e \"-\", \"agent\" =\u003e \"\\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"host\" =\u003e \"localhost\", \"request\" =\u003e \"/resources/jquery.min.js\", \"@version\" =\u003e \"1\", \"verb\" =\u003e \"GET\", \"geoip\" =\u003e { \"longitude\" =\u003e 126.9754, \"country_code3\" =\u003e \"KR\", \"region_code\" =\u003e \"11\", \"city_name\" =\u003e \"Seoul\", \"country_name\" =\u003e \"South Korea\", \"region_name\" =\u003e \"Seoul\", \"location\" =\u003e { \"lat\" =\u003e 37.5794, \"lon\" =\u003e 126.9754 }, \"latitude\" =\u003e 37.5794, \"continent_code\" =\u003e \"AS\", \"country_code2\" =\u003e \"KR\", \"postal_code\" =\u003e \"04524\", \"ip\" =\u003e \"218.39.220.90\", \"timezone\" =\u003e \"Asia/Seoul\" }, \"timestamp\" =\u003e \"09/Jan/2022:17:52:49 +0900\", \"bytes\" =\u003e \"299\", \"referrer\" =\u003e \"\\\"http://dwww/status.html\\\"\", \"httpversion\" =\u003e \"1.1\", \"clientip\" =\u003e \"218.39.220.90\" } logstash 의 output 으로 나오는 항목들은 모두 문자열입니다.\n결과 필드를 정수(integer)형으로 변환하는 기능을 추가합니다.\nfilter 에 mutate 를 보면 됩니다.\n$ cat \u003c\u003c EOF \u003e exam_filter.ls input { tcp { port =\u003e 9900 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } geoip { source =\u003e \"clientip\" } mutate { convert =\u003e { \"bytes\" =\u003e \"integer\" } } } output { stdout {} } EOF $ $ head -n 1 weblog.txt | nc localhost 9900 { \"auth\" =\u003e \"-\", \"host\" =\u003e \"localhost\", \"response\" =\u003e \"503\", \"verb\" =\u003e \"GET\", \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"port\" =\u003e 9540, \"bytes\" =\u003e 299, \"geoip\" =\u003e { \"continent_code\" =\u003e \"AS\", \"region_name\" =\u003e \"Seoul\", \"postal_code\" =\u003e \"04524\", \"timezone\" =\u003e \"Asia/Seoul\", \"country_code3\" =\u003e \"KR\", \"country_name\" =\u003e \"South Korea\", \"ip\" =\u003e \"218.39.220.90\", \"region_code\" =\u003e \"11\", \"city_name\" =\u003e \"Seoul\", \"latitude\" =\u003e 37.5794, \"country_code2\" =\u003e \"KR\", \"longitude\" =\u003e 126.9754, \"location\" =\u003e { \"lat\" =\u003e 37.5794, \"lon\" =\u003e 126.9754 } }, \"ident\" =\u003e \"-\", \"@timestamp\" =\u003e 2022-01-26T17:19:32.250Z, \"@version\" =\u003e \"1\", \"timestamp\" =\u003e \"09/Jan/2022:17:52:49 +0900\", \"agent\" =\u003e \"\\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"request\" =\u003e \"/resources/jquery.min.js\", \"clientip\" =\u003e \"218.39.220.90\", \"referrer\" =\u003e \"\\\"http://dwww/status.html\\\"\", \"httpversion\" =\u003e \"1.1\" } useragent라는 filter 가 있습니다.\napache log 에 기본 포함되어있는 “agent” 필드를 parsing 하여 세분화합니다.\n$ cat \u003c\u003c EOF \u003e exam_filter.ls input { tcp { port =\u003e 9900 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } geoip { source =\u003e \"clientip\" } mutate { convert =\u003e { \"bytes\" =\u003e \"integer\" } } useragent { source =\u003e \"agent\" target =\u003e \"useragent\" } } output { stdout {} } EOF $ $ head -n 1 weblog.txt | nc localhost 9900 { \"request\" =\u003e \"/resources/jquery.min.js\", \"bytes\" =\u003e 299, \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"ident\" =\u003e \"-\", \"httpversion\" =\u003e \"1.1\", \"geoip\" =\u003e { \"postal_code\" =\u003e \"04524\", \"city_name\" =\u003e \"Seoul\", \"continent_code\" =\u003e \"AS\", \"country_name\" =\u003e \"South Korea\", \"region_code\" =\u003e \"11\", \"timezone\" =\u003e \"Asia/Seoul\", \"country_code2\" =\u003e \"KR\", \"country_code3\" =\u003e \"KR\", \"location\" =\u003e { \"lat\" =\u003e 37.5794, \"lon\" =\u003e 126.9754 }, \"region_name\" =\u003e \"Seoul\", \"longitude\" =\u003e 126.9754, \"latitude\" =\u003e 37.5794, \"ip\" =\u003e \"218.39.220.90\" }, \"auth\" =\u003e \"-\", \"referrer\" =\u003e \"\\\"http://dwww/status.html\\\"\", \"response\" =\u003e \"503\", \"useragent\" =\u003e { \"os_major\" =\u003e \"10\", \"os_version\" =\u003e \"10\", \"os_full\" =\u003e \"Windows 10\", \"minor\" =\u003e \"0\", \"os\" =\u003e \"Windows\", \"name\" =\u003e \"Chrome\", \"patch\" =\u003e \"4692\", \"major\" =\u003e \"97\", \"version\" =\u003e \"97.0.4692.71\", \"os_name\" =\u003e \"Windows\", \"device\" =\u003e \"Other\" }, \"verb\" =\u003e \"GET\", \"@timestamp\" =\u003e 2022-01-26T17:23:55.151Z, \"timestamp\" =\u003e \"09/Jan/2022:17:52:49 +0900\", \"host\" =\u003e \"localhost\", \"agent\" =\u003e \"\\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"@version\" =\u003e \"1\", \"port\" =\u003e 9638, \"clientip\" =\u003e \"218.39.220.90\" } date filter 입니다.\n$ cat \u003c\u003c EOF \u003e exam_filter.ls input { tcp { port =\u003e 9900 } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } geoip { source =\u003e \"clientip\" } mutate { convert =\u003e { \"bytes\" =\u003e \"integer\" } } useragent { source =\u003e \"agent\" target =\u003e \"useragent\" } date { match =\u003e [\"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\"] target =\u003e \"logdate\" } } output { stdout {} } EOF $ $ head -n 1 weblog.txt | nc localhost 9900 { \"port\" =\u003e 9818, \"message\" =\u003e \"218.39.220.90 - - [09/Jan/2022:17:52:49 +0900] \\\"GET /resources/jquery.min.js HTTP/1.1\\\" 503 299 \\\"http://dwww/status.html\\\" \\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"clientip\" =\u003e \"218.39.220.90\", \"ident\" =\u003e \"-\", \"referrer\" =\u003e \"\\\"http://dwww/status.html\\\"\", \"agent\" =\u003e \"\\\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\\\"\", \"@timestamp\" =\u003e 2022-01-26T17:31:50.864Z, \"request\" =\u003e \"/resources/jquery.min.js\", \"useragent\" =\u003e { \"os_name\" =\u003e \"Windows\", \"os_full\" =\u003e \"Windows 10\", \"patch\" =\u003e \"4692\", \"name\" =\u003e \"Chrome\", \"os_version\" =\u003e \"10\", \"device\" =\u003e \"Other\", \"version\" =\u003e \"97.0.4692.71\", \"minor\" =\u003e \"0\", \"os\" =\u003e \"Windows\", \"os_major\" =\u003e \"10\", \"major\" =\u003e \"97\" }, \"timestamp\" =\u003e \"09/Jan/2022:17:52:49 +0900\", \"host\" =\u003e \"localhost\", \"@version\" =\u003e \"1\", \"verb\" =\u003e \"GET\", \"bytes\" =\u003e 299, \"geoip\" =\u003e { \"longitude\" =\u003e 126.9754, \"ip\" =\u003e \"218.39.220.90\", \"country_name\" =\u003e \"South Korea\", \"continent_code\" =\u003e \"AS\", \"postal_code\" =\u003e \"04524\", \"location\" =\u003e { \"lat\" =\u003e 37.5794, \"lon\" =\u003e 126.9754 }, \"country_code2\" =\u003e \"KR\", \"region_code\" =\u003e \"11\", \"latitude\" =\u003e 37.5794, \"timezone\" =\u003e \"Asia/Seoul\", \"region_name\" =\u003e \"Seoul\", \"country_code3\" =\u003e \"KR\", \"city_name\" =\u003e \"Seoul\" }, \"auth\" =\u003e \"-\", \"response\" =\u003e \"503\", \"logdate\" =\u003e 2022-01-09T08:52:49.000Z, \"httpversion\" =\u003e \"1.1\" } \n지금까지 logstash 가 network 에서 읽어들인 데이터를 filter 처리를하고 output 으로 console 에 출력하는 예시를 봤습니다.\n예시에 사용된 모든 exam_*.ls 파일들은 pipelines.yml 에서 인식할 수 있는 경로에 두면 logstash 서비스가 실행하게 됩니다.\n다음은 테스트에 사용된 nc명령이 아닌 filebeat 가 읽어들인 파일을 logstash 로 전송하는 설명을 하겠습니다.\nfilebeat 설치 $ yum list filebeat filebeat 설정 filebeat 와 elasticsearch 의 관계를 설명하는 다이어그램입니다.\nfilebeat의 주요 기능은 는 로그파일을 읽어들이고(input) elasticsearch 혹은 logstash 로 출력(output)하는 것입니다.\n새 창 보기\nfilebeat 설정 파일/etc/filebeat/filebeat.yml에 기본 설정된 상태를 보면 output.elasticsearch 가 활성화 되어있고, output.logstash는 비활성화로 되어있습니다.\n132 output.elasticsearch: 133 # Array of hosts to connect to. 134 hosts: [\"localhost:9200\"] ... 145 #output.logstash: 146 # The Logstash hosts 147 #hosts: [\"localhost:5044\"] filebeat는 filebeat \u003e logstash \u003e elasticsearch 혹은 filebeat \u003e elasticsearch 형태로 구성할 수 있습니다.\nelasticsearch 에 전송하는 것이 목적이지만 테스트를 위해 logstash 에서 stdout 으로 원하는 포맷으로 logstash-filter 처리가 되었는지를 확인할 때 사용할 수 있습니다.\nfilebeat 를 yum 으로 설치했을 경우 systemd 에 추가할 수 있습니다.\n기본적인 운용 개념은 다음과 같습니다.\n filebeat 서비스 실행 filebeat 설정 변경 및 모듈 추가 filebeat 서비스 재시작 kibana 에서 filebeat 가 elasticsearch 로 출력(output)한 내용 확인 filebeat 모듈 설정 (예: 활성화 상태 변경) filebeat 서비스 재시작으로 모듈 설정된 내용 반영  주요 내용은 설정을 변경하면 filebeat 서비스를 재시작해야 반영된다는 사항이 있습니다.\nfilebeat 가 읽어들일 로그파일이 잘 알려진 프로그램의 로그일 경우 modules 에 포함 되어있습니다.\n그 중 apache 모듈에 access_log 를 읽어들이도록 모듈을 설정하고 활성화하는 예시입니다.\n(활성화된 모듈 목록을 확인하고 apache 모듈을 enable 해봅니다.)\n$ filebeat modules list Enabled: Disabled: activemq apache auditd ... $ $ filebeat modules enable apache Enabled apache $ $ filebeat modules list Enabled: apache Disabled: activemq auditd $ filebeat 의 module 설정은 아래 경로에 있습니다.\n$ ls /etc/filebeat/modules.d/ activemq.yml.disabled cylance.yml.disabled iptables.yml.disabled o365.yml.disabled sophos.yml.disabled apache.yml elasticsearch.yml.disabled juniper.yml.disabled okta.yml.disabled squid.yml.disabled auditd.yml.disabled envoyproxy.yml.disabled kafka.yml.disabled oracle.yml.disabled suricata.yml.disabled aws.yml.disabled f5.yml.disabled kibana.yml.disabled osquery.yml.disabled system.yml.disabled awsfargate.yml.disabled fortinet.yml.disabled logstash.yml.disabled panw.yml.disabled threatintel.yml.disabled azure.yml.disabled gcp.yml.disabled microsoft.yml.disabled pensando.yml.disabled tomcat.yml.disabled barracuda.yml.disabled google_workspace.yml.disabled misp.yml.disabled postgresql.yml.disabled traefik.yml.disabled bluecoat.yml.disabled googlecloud.yml.disabled mongodb.yml.disabled proofpoint.yml.disabled zeek.yml.disabled cef.yml.disabled gsuite.yml.disabled mssql.yml.disabled rabbitmq.yml.disabled zookeeper.yml.disabled checkpoint.yml.disabled haproxy.yml.disabled mysql.yml.disabled radware.yml.disabled zoom.yml.disabled cisco.yml.disabled ibmmq.yml.disabled mysqlenterprise.yml.disabled redis.yml.disabled zscaler.yml.disabled coredns.yml.disabled icinga.yml.disabled nats.yml.disabled santa.yml.disabled crowdstrike.yml.disabled iis.yml.disabled netflow.yml.disabled snort.yml.disabled cyberark.yml.disabled imperva.yml.disabled netscout.yml.disabled snyk.yml.disabled cyberarkpas.yml.disabled infoblox.yml.disabled nginx.yml.disabled sonicwall.yml.disabled $ $ ls -al /etc/filebeat/modules.d/apache.yml -rw-r--r-- 1 root root 476 2022-01-07 09:36 /etc/filebeat/modules.d/apache.yml apache.yml에 access_log, error_log 를 수집할 수 있도록 설정합니다.\n설정 전 확인할 사항\n access_log 경로: (예) /outlog/WEB/httpd/nexus_ssl-access.log.2022-01-26  - module: apache access: enabled: true input: fields: server_name: develop-httpd log_type: nexus_access var.paths: [\"/outlog/WEB/httpd/nexus_ssl-access.log.*\"] error: enabled: true #var.paths: [] filebeat modules enable apache 명령으로 모듈을 활성화 상태로 설정합니다.\nsystemctl restart filebeat 명령으로 서비스를 재시작합니다.\n아래와 같이 kibana 에서 access_log 를 확인합니다.\n새 창 보기\nfilebeat 이해 (filebeat-logstash-elastic) logstash 설정 filebeat-elastic 구성을 filebeat-logstash-elastic 으로 변경하여 apache 로그를 수집하는 예시입니다.\nlogstash 에 filebeat 를 수신하기 위한 pipeline(exam_filebeat.conf)을 하나 추가합니다.\n테스트를 단계별로 진행하기 위해 output 은 stdout 만 남기고 주석처리를 합니다.\n$ cat \u003c\u003c EOF \u003e /etc/logstash/conf.d/exam_filebeat.conf input { # exam_tcp.conf 는 tcp 소캣으로 읽어들이도록 설정되어 있습니다. #tcp { # port =\u003e 10000 #} # exam_filebeat.conf 는 filebeat 에서 읽어들이도록 설정합니다. beats { port =\u003e 11000 } } filter { mutate { remove_field =\u003e [\"agent\"] } grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } geoip { source =\u003e \"clientip\" } mutate { convert =\u003e { \"bytes\" =\u003e \"integer\" } } useragent { source =\u003e \"agent\" target =\u003e \"useragent\" } date { match =\u003e [\"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\"] } mutate { remove_field =\u003e [\"timestamp\", \"host\", \"@version\", \"agent\"] } } output { stdout { # 대량 데이터일 경우 1건당 .으로 표시되도록 설정 #codec =\u003e \"dots\" } #elasticsearch { # # 로그발생 일자(timestamp)별로 elasticsearch 에 생성되는 index가 을 rolling 되도록 설정 # # 의 값으로 %{+yyyy.MM.dd} 포맷의 index가 일자별로 생성됨 # index =\u003e \"mgkim-apache-log-%{+yyyy.MM.dd}\" # # elasticsearch 에 전송시 id/pw 정보가 필요합니다. # # security 미적용 시 평문으로된 \"votmdnjem\" 를 입력 # hosts =\u003e [\"localhost:8200\"] # user =\u003e \"elastic\" # password =\u003e \"votmdnjem\" #} } EOF $ logstash 에 pipeline(exam_filebeat.conf) 추가 후 정상적으로 시작된 로그를 확인합니다.\ntail -f /outlog/PROD/logstash/logstash-plain.log\n[2022-01-28T17:02:00,967][INFO ][logstash.javapipeline ][main] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e4, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e500, \"pipeline.sources\"=\u003e[\"/etc/logstash/conf.d/exam_filebeat.conf\", \"/etc/logstash/conf.d/exam_tcp.conf\"], :thread=\u003e\"#\u003cThread:0x1625cd85 run\u003e\"} [2022-01-28T17:02:01,912][INFO ][logstash.javapipeline ][main] Pipeline Java execution initialization time {\"seconds\"=\u003e0.94} [2022-01-28T17:02:01,937][INFO ][logstash.inputs.beats ][main] Starting input listener {:address=\u003e\"0.0.0.0:11000\"} [2022-01-28T17:02:02,118][INFO ][logstash.javapipeline ][main] Pipeline started {\"pipeline.id\"=\u003e\"main\"} [2022-01-28T17:02:02,133][INFO ][logstash.inputs.tcp ][main][71e68810c5b50adf6cf53d1923400c9bc4a6e144d1df3de0b7607e41a062c940] Starting tcp input listener {:address=\u003e\"0.0.0.0:10000\", :ssl_enable=\u003efalse} [2022-01-28T17:02:02,219][INFO ][org.logstash.beats.Server][main][cfcaf5386821113b776dd2ed8e280ac14652eefa6917b906e2915cdb2ac8904c] Starting server on port: 11000 [2022-01-28T17:02:02,265][INFO ][logstash.agent ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]} \nfilebeat 설정 filebeat 서비스를 활성화합니다.\n$ systemctl enable filebeat.service Synchronizing state of filebeat.service with SysV service script with /usr/lib/systemd/systemd-sysv-install. Executing: /usr/lib/systemd/systemd-sysv-install enable filebeat Created symlink /etc/systemd/system/multi-user.target.wants/filebeat.service → /usr/lib/systemd/system/filebeat.service. $ \nfilebeat 서비스 파일/usr/lib/systemd/system/filebeat.service에서 로그 디렉토리와 데이터 디렉토리를 변경합니다.\n(systemd 서비스 파일을 수정하면 systemctl daemon-reload 실행해야 반영됩니다.)\n$ vi /usr/lib/systemd/system/filebeat.service 1 [Unit] 2 Description=Filebeat sends log files to Logstash or directly to Elasticsearch. 3 Documentation=https://www.elastic.co/beats/filebeat 4 Wants=network-online.target 5 After=network-online.target 6 7 [Service] 8 9 Environment=\"GODEBUG='madvdontneed=1'\" 10 Environment=\"BEAT_LOG_OPTS=\" 11 Environment=\"BEAT_CONFIG_OPTS=-c /etc/filebeat/filebeat.yml\" 12 #Environment=\"BEAT_PATH_OPTS=--path.home /usr/share/filebeat --path.config /etc/filebeat --path.data /var/lib/filebeat --path.logs /var/log/filebeat\" 13 Environment=\"BEAT_PATH_OPTS=--path.home /usr/share/filebeat --path.config /etc/filebeat --path.data /data/PROD/filebeat --path.logs /outlog/PROD/filebeat\" 14 ExecStart=/usr/share/filebeat/bin/filebeat --environment systemd $BEAT_LOG_OPTS $BEAT_CONFIG_OPTS $BEAT_PATH_OPTS 15 Restart=always 16 17 [Install] 18 WantedBy=multi-user.target $ systemctl daemon-reload $ mkdir -p /data/PROD/filebeat $ mkdir -p /outlog/PROD/filebeat \nfilebeat 의 output 을 logstash 로 되도록 수정합니다.\n설정파일/etc/filebeat/filebeat.yml에서 output.elasticsearch 를 주석처리하고, output.logstash 를 주석해제 합니다.\n테스트의 단순화를 위해 filebeat module 이 enable 된 것들을 모두 disable 로 변경합니다.\nfilebeat modules disable apache\nfilebeat 가 읽어들일 테스트용 apache access 로그파일/root/test/weblog.txt을 설정합니다.\nweblog.txt 파일: 다운로드\n$ vi /etc/filebeat/filebeat.yml #- type: filestream - type: log enabled: true - /root/ls-test/weblog.txt #output.elasticsearch: #hosts: [\"localhost:9200\"] output.logstash: hosts: [\"localhost:11000\"] \nfilebeat-logstash 테스트   logstash 서비스의 startup 로그에서 pipeline 이 정상적으로 설정되었는지 확인\ntail -f /outlog/PROD/logstash/logstash-plain.log   logstash 의 console 로그를 보기위해 실행\ntail -f /var/log/messages | grep logstash   filebeat 의 console 로그를 보기위해 실행\ntail -f /var/log/messages | grep filebeat   filebeat 서비스를 실행하기 전에 데이터 디렉토리 하위 파일 삭제\nfilebeat 가 읽어들인 정보는 /data/PROD/filebeat 에 보관되어 있으며 하위 파일을 삭제하면 filebeat 서비스가 재시작할때 다시 읽어들입니다.\nrm -rf /data/PROD/filebeat/*   logstash 서비스 시작\nsystemctl restart logstash.service   테스트 로그 파일 확인\n테스트용으로 1건만 추가되어있는 파일이 준비되어 있는지 확인합니다.\nvi /root/ls-test/weblog.txt   filebeat 서비스 시작\nsystemctl restart filebeat.service   결과 확인\nfilebeat 서비스 시작으로 logstash 처리까지 되었는지 확인합니다.\n아래는 정상처리가 되었을 경우 출력되는 로그 입니다.\n로그: 새 창 보기\n  filebeat-logstash-elastics 테스트   filebeat 와 logstash 서비스를 모두 stop 합니다.\n$ systemctl stop filebeat.service $ systemctl stop logstash.service \n  logstash pipeline 설정파일 output 에 elasticsearch 가 주석처리된 부분 해제\npipeline 설정파일: /etc/logstash/conf.d/exam_filebeat.conf\n... output { stdout { # 대량 데이터일 경우 1건당 .으로 표시되도록 설정 #codec =\u003e \"dots\" } elasticsearch { # 로그발생 일자(timestamp)별로 elasticsearch 에 생성되는 index가 을 rolling 되도록 설정 # 의 값으로 %{+yyyy.MM.dd} 포맷의 index가 일자별로 생성됨 index =\u003e \"mgkim-apache-log-%{+yyyy.MM.dd}\" # elasticsearch 에 전송시 id/pw 정보가 필요합니다. # security 미적용 시 평문으로된 \"votmdnjem\" 를 입력 hosts =\u003e [\"localhost:8200\"] user =\u003e \"elastic\" password =\u003e \"votmdnjem\" } } \n  logstash 서비스 및 filebeat 서비스 시작\n$ systemctl start logstash.service $ systemctl start filebeat.service logstash startup 로그: 새 창 보기\n(logstash pipeline 에 정의된 elasticsearch 접속정보로 정상 연결되었는지 확인)   elasticsearch 에서 처리결과 확인\nelasticsearch 에서 logstash 가 보낸 데이터로 생성된 index 를 조회\n$ curl -XGET -u elastic:votmdnjem \"http://localhost:8200/_cat/indices?pretty\u0026v\u0026s=index:desc 조회 결과 index 명은 logstash 의 pipeline 에 설정된 값으로 확인합니다.\npipeline 설정파일: /etc/logstash/conf.d/exam_filebeat.conf\nelasticsearch { index =\u003e \"mgkim-apache-log-%{+yyyy.MM.dd}\" } elasticsearch 에서 index 명 mgkim-apache-log-2022.01.09 의 데이터 조회\n$ curl -XGET -u elastic:votmdnjem \"http://localhost:8200/mgkim-apache-log-2022.01.09/_search?pretty\" curl 테스트: 새 창 보기   logstash 설정 (keystore) logstash 의 pipeline 설정 파일에 elasticsearch 패스워드 입력부분을 keystore 에서 가져오도록 할 수 있습니다.\nelasticsearch { hosts =\u003e [\"localhost:8200\"] user =\u003e \"elastic\" #password =\u003e \"votmdnjem\" # logstash-keystore 에서 es_password 값을 사용하도록 함 password =\u003e \"${es_password}\" } logstash 에서 keystore 를 생성하는 과정입니다.\n신경써야하는 부분은 keystore 의 password 를 저장하는 시스템변수 LOGSTASH_KEYSTORE_PASS 와 logstash 서비스의 설정과 관련있는 --path.settings 파라미터의 경로입니다.\n### logstash 서비스 파일에서 EnvironmentFile 파일 확인 ### EnvironmentFile 파일에 LOGSTASH_KEYSTORE_PASS 변수 추가할 목적으로 확인 ### --path.settings 의 경로를 확인 (logstash-keystore 로 keystore 생성 시 파라미터로 전달해야함) $ cat /etc/systemd/system/logstash.service [Unit] Description=logstash [Service] Type=simple User=logstash Group=logstash # Load env vars from /etc/default/ and /etc/sysconfig/ if they exist. # Prefixing the path with '-' makes it try to load, but if the file doesn't # exist, it continues onward. EnvironmentFile=-/etc/default/logstash EnvironmentFile=-/etc/sysconfig/logstash ExecStart=/usr/share/logstash/bin/logstash \"--path.settings\" \"/etc/logstash\" Restart=always WorkingDirectory=/ Nice=19 LimitNOFILE=16384 # When stopping, how long to wait before giving up and sending SIGKILL? # Keep in mind that SIGKILL on a process can cause data loss. TimeoutStopSec=infinity [Install] WantedBy=multi-user.target ### EnvironmentFile 파일의 마지막 부분에 LOGSTASH_KEYSTORE_PASS=1 추가 ### logstash 서비스가 logstash-keystore 에 접근할 때 사용합니다. $ cat /etc/default/logstash LS_HOME=\"/usr/share/logstash\" LS_SETTINGS_DIR=\"/etc/logstash\" LS_PIDFILE=\"/var/run/logstash.pid\" LS_USER=\"logstash\" LS_GROUP=\"logstash\" LS_GC_LOG_FILE=\"/var/log/logstash/gc.log\" LS_OPEN_FILES=\"16384\" LS_NICE=\"19\" SERVICE_NAME=\"logstash\" SERVICE_DESCRIPTION=\"logstash\" LOGSTASH_KEYSTORE_PASS=1 ### key 저장소 생성 $ /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash create Using JAVA_HOME defined java: /prod/java/openjdk-11.0.13.8-temurin WARNING: Using JAVA_HOME while Logstash distribution comes with a bundled JDK. DEPRECATION: The use of JAVA_HOME is now deprecated and will be removed starting from 8.0. Please configure LS_JAVA_HOME instead. OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. Created Logstash keystore at /etc/logstash/logstash.keystore ### key 저장소가 생성된 경로의 파일의 소유자를 logstash 로 변경 $ chown logstash:root /etc/logstash/logstash.keystore $ ls -al /etc/logstash/logstash.keystore -rw-r--r-- 1 logstash root 771 2022-01-28 16:55 /etc/logstash/logstash.keystore ### key 저장소에 es_password 추가 $ /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash add es_password Using JAVA_HOME defined java: /prod/java/openjdk-11.0.13.8-temurin WARNING: Using JAVA_HOME while Logstash distribution comes with a bundled JDK. DEPRECATION: The use of JAVA_HOME is now deprecated and will be removed starting from 8.0. Please configure LS_JAVA_HOME instead. OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. Enter value for es_password: Added 'es_password' to the Logstash keystore. ### key 저장소에 es_password 가 있는지 확인 $ /usr/share/logstash/bin/logstash-keystore --path.settings /etc/logstash list Using JAVA_HOME defined java: /prod/java/openjdk-11.0.13.8-temurin WARNING: Using JAVA_HOME while Logstash distribution comes with a bundled JDK. DEPRECATION: The use of JAVA_HOME is now deprecated and will be removed starting from 8.0. Please configure LS_JAVA_HOME instead. OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. es_password ### logstash 의 pipeline 설정 파일에 es_password 로 치환 ### pipeline 설정파일: /etc/logstash/conf.d/exam_filebeat.conf ... elasticsearch { hosts =\u003e [\"localhost:8200\"] user =\u003e \"elastic\" #password =\u003e \"votmdnjem\" # logstash-keystore 에서 es_password 값을 사용하도록 함 password =\u003e \"${es_password}\" } ... ### logstash 서비스 재시작 후 elasticsearch 접속 상태 로그에서 확인 $ systemctl restart logstash $ tail -f /var/log/messages | grep logstash Jan 28 21:34:53 centos8 logstash[100495]: [2022-01-28T21:34:53,467][INFO ][logstash.outputs.elasticsearch][main] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//localhost:8200\"]} Jan 28 21:34:53 centos8 logstash[100495]: [2022-01-28T21:34:53,791][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elastic:xxxxxx@localhost:8200/]}} Jan 28 21:34:54 centos8 logstash[100495]: [2022-01-28T21:34:54,027][WARN ][logstash.outputs.elasticsearch][main] Restored connection to ES instance {:url=\u003e\"http://elastic:xxxxxx@localhost:8200/\"} Jan 28 21:34:54 centos8 logstash[100495]: [2022-01-28T21:34:54,044][INFO ][logstash.outputs.elasticsearch][main] Elasticsearch version determined (7.16.3) {:es_version=\u003e7} ","categories":"","description":"","excerpt":"elasticsearch 설치 artifacts.elastic.co 에서 rpm 다운로드 후 설치\n$ curl -L -O …","ref":"/system/elk/","tags":"","title":"ELK"},{"body":"command loaded 모듈 목록 확인 httpd -M\n새 창 보기\nconfigure httpd.conf ServerRoot \"/etc/httpd\" Listen 80 Include conf.modules.d/*.conf User apache Group web ServerAdmin hi@mgkim.net ServerName develop:80 \u003cDirectory /\u003e AllowOverride none Require all denied \u003c/Directory\u003e DocumentRoot \"/var/www/html\" \u003cFiles \".ht*\"\u003e Require all denied \u003c/Files\u003e ErrorLog \"/outlog/WEB/httpd/error.log\" LogLevel warn \u003cIfModule log_config_module\u003e LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b\" common \u003cIfModule logio_module\u003e LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" %I %O\" combinedio \u003c/IfModule\u003e CustomLog \"/outlog/WEB/httpd/access.log\" combined \u003c/IfModule\u003e \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/var/www/cgi-bin/\" \u003c/IfModule\u003e \u003cDirectory \"/var/www/cgi-bin\"\u003e AllowOverride None Options None Require all granted \u003c/Directory\u003e \u003cIfModule mime_module\u003e TypesConfig /etc/mime.types AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType text/html .shtml AddOutputFilter INCLUDES .shtml \u003c/IfModule\u003e AddDefaultCharset UTF-8 \u003cIfModule mime_magic_module\u003e MIMEMagicFile conf/magic \u003c/IfModule\u003e EnableSendfile on IncludeOptional conf.d/*.conf ssl.conf Listen 443 https SSLPassPhraseDialog exec:/usr/libexec/httpd-ssl-pass-dialog SSLSessionCache shmcb:/run/httpd/sslcache(512000) SSLSessionCacheTimeout 300 SSLRandomSeed startup file:/dev/urandom 256 SSLRandomSeed connect builtin SSLCryptoDevice builtin \u003cVirtualHost _default_:443\u003e ServerName develop ErrorLog /outlog/WEB/httpd/develop-error_ssl.log TransferLog /outlog/WEB/httpd/develop-access_ssl.log LogLevel warn SSLEngine on SSLProtocol all -SSLv2 -SSLv3 SSLCipherSuite HIGH:3DES:!aNULL:!MD5:!SEED:!IDEA SSLCertificateFile /etc/httpd/conf.d/certs/develop.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/develop.key \u003cFiles ~ \"\\.(cgi|shtml|phtml|php3?)$\"\u003e SSLOptions +StdEnvVars \u003c/Files\u003e \u003cDirectory \"/var/www/cgi-bin\"\u003e SSLOptions +StdEnvVars \u003c/Directory\u003e BrowserMatch \"MSIE [2-5]\" nokeepalive ssl-unclean-shutdown downgrade-1.0 force-response-1.0 CustomLog /outlog/WEB/httpd/default-request_ssl.log \"%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\"%r\\\" %b\" \u003c/VirtualHost\u003e \nvhost-centos8.conf \u003cVirtualHost *:80\u003e ServerName centos8 RewriteEngine On RewriteCond %{HTTPS} !=On [NC] RewriteRule /(.*) https://centos8/$1 [P,L] #RewriteCond %{HTTP:Upgrade} =websocket [NC] #RewriteRule /(.*) wss://centos8/$1 [P,L] #RewriteCond %{HTTP:Upgrade} !=websocket [NC] #RewriteRule /(.*) https://centos8/$1 [P,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName centos8 SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/cockpit/ws-certs.d/centos8.crt SSLCertificateKeyFile /etc/cockpit/ws-certs.d/centos8.key ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/centos8-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/centos8-access.log.%Y-%m-%d 86400 +540\" combined ProxyRequests Off ProxyPreserveHost On # AH01961: SSL Proxy requested for centos8:443 but not enabled [Hint: SSLProxyEngine] SSLProxyEngine On AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" RequestHeader set X-Forwarded-Proto https \u003cProxy balancer://cluster1\u003e BalancerMember https://127.0.0.1:8000 \u003c/Proxy\u003e ProxyPass / balancer://cluster1/ stickysession=JSESSIONID|jsessionid ProxyPassReverse / balancer://cluster1/ RewriteEngine On RewriteCond %{HTTP:Upgrade} =websocket [NC] RewriteRule /(.*) wss://127.0.0.1:8000/$1 [P,L] \u003c/VirtualHost\u003e \nvhost-nexus.conf \u003cVirtualHost *:80\u003e ServerName nexus RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://nexus.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName nexus SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/nexus.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/nexus.key RewriteEngine On RewriteRule /(.*) https://nexus.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e ### mgkim.net \u003cVirtualHost *:80\u003e ServerName nexus.mgkim.net RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://%{HTTP_HOST}/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName nexus.mgkim.net ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/nexus.mgkim.net_ssl-error.log.%Y-%m-%d 86400 +540%\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/nexus.mgkim.net_ssl-access.log.%Y-%m-%d 86400 +540%\" combined SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/STAR.mgkim.net.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/STAR.mgkim.net.key AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" ProxyRequests Off ProxyPreserveHost On \u003cProxy *\u003e Require all granted \u003c/Proxy\u003e ProxyPass / http://127.0.0.1:8100/ ProxyPassReverse / http://127.0.0.1:8100/ RequestHeader set X-Forwarded-Proto \"https\" #ProxyPassMatch ^/(.*)$ http://127.0.0.1:8100/$1 \u003c/VirtualHost\u003e vhost-gitlab.conf \u003cVirtualHost *:80\u003e ServerName gitlab RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://gitlab.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName gitlab SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/gitlab.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/gitlab.key RewriteEngine On RewriteRule /(.*) https://gitlab.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e ### mgkim.net \u003cVirtualHost *:80\u003e ServerName gitlab.mgkim.net RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://%{HTTP_HOST}/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName gitlab.mgkim.net DocumentRoot \"/opt/gitlab/embedded/service/gitlab-rails/public\" ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/gitlab.mgkim.net_ssl-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/gitlab.mgkim.net_ssl-access.log.%Y-%m-%d 86400 +540\" combined SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/STAR.mgkim.net.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/STAR.mgkim.net.key ProxyRequests Off ProxyPreserveHost On \u003cProxy gitlab\u003e Require all granted \u003c/Proxy\u003e AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" ProxyPass / http://127.0.0.1:8200/ ProxyPassReverse / http://127.0.0.1:8200/ \u003c/VirtualHost\u003e vhost-jenkins.conf \u003cVirtualHost *:80\u003e ServerName jenkins RewriteEngine On RewriteCond %{HTTPS} !=On RewriteCond %{REQUEST_URI} ^/(computer)/.*$ RewriteRule /(.*) http://localhost:8400/$1 [QSA,P,L] RewriteCond %{REQUEST_URI} ^/(wsagents)/.*$ RewriteRule /(.*) ws://localhost:8400/$1 [QSA,P,L] RewriteRule /(.*) https://jenkins.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName jenkins SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/jenkins.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/jenkins.key RewriteEngine On RewriteRule /(.*) https://jenkins.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e ### mgkim.net \u003cVirtualHost *:80\u003e ServerName jenkins.mgkim.net RewriteEngine On RewriteCond %{HTTPS} !=On RewriteCond %{REQUEST_URI} ^/(computer)/.*$ RewriteRule /(.*) http://localhost:8400/$1 [QSA,P,L] RewriteCond %{REQUEST_URI} ^/(wsagents)/.*$ RewriteRule /(.*) ws://localhost:8400/$1 [QSA,P,L] RewriteRule /(.*) https://jenkins.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName jenkins.mgkim.net ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/jenkins.mgkim.net_ssl-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/jenkins.mgkim.net_ssl-access.log.%Y-%m-%d 86400 +540\" combined SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/STAR.mgkim.net.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/STAR.mgkim.net.key AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" RewriteEngine On RewriteCond %{HTTP:Upgrade} =websocket [NC] RewriteRule /(.*) ws://localhost:8400/$1 [P,L] RewriteCond %{HTTP:Upgrade} !=websocket [NC] RewriteRule /(.*) http://localhost:8400/$1 [P,L] \u003c/VirtualHost\u003e vhost-dlog.conf \u003cVirtualHost *:80\u003e ServerName dlog RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://dlog.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName dlog SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/dlog.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/dlog.key RewriteEngine On RewriteRule /(.*) https://dlog.mgkim.net/$1 [QSA,R,L] \u003c/VirtualHost\u003e ### mgkim.net \u003cVirtualHost *:80\u003e ServerName dlog.mgkim.net RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://%{HTTP_HOST}/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:443\u003e ServerName dlog.mgkim.net #DocumentRoot \"/opt/gitlab/embedded/service/gitlab-rails/public\" ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dlog.mgkim.net_ssl-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dlog.mgkim.net_ssl-access.log.%Y-%m-%d 86400 +540\" combined SSLEngine On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile /etc/httpd/conf.d/certs/STAR.mgkim.net.crt SSLCertificateKeyFile /etc/httpd/conf.d/certs/STAR.mgkim.net.key ProxyRequests Off ProxyPreserveHost On \u003cProxy gitlab\u003e Require all granted \u003c/Proxy\u003e AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" ProxyPass / http://127.0.0.1:1313/ ProxyPassReverse / http://127.0.0.1:1313/ \u003c/VirtualHost\u003e vhost-dwww.conf \u003cVirtualHost *:80\u003e ServerName dwww ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dwww-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/dwww-access.log.%Y-%m-%d 86400 +540\" combined AllowEncodedSlashes On # reverse proxy 사용 시 Off ProxyRequests Off ProxyPreserveHost On # BALANCER_WORKER_ROUTE: BalancerMember 의 route 값을 쿠키에 포함 (cluster1, cluster2) Header add Set-Cookie \"ROUTEID=.%{BALANCER_WORKER_ROUTE}e; path=/\" env=BALANCER_ROUTE_CHANGED Header set Access-Control-Allow-Origin \"*\" \u003cProxy balancer://cluster\u003e BalancerMember http://127.0.0.1:7100 route=cluster1 BalancerMember http://127.0.0.1:7101 route=cluster2 ProxySet stickysession=ROUTEID ## lbmethod # byrequests: 요청별 분배 # bytraffic: byte 트래픽 가중치 분배 # bybusyness: 보류중 요청 분배 #ProxySet lbmethod=byrequests \u003c/Proxy\u003e ProxyPass / balancer://cluster/ ProxyPassReverse / balancer://cluster/ \u003c/VirtualHost\u003e connector weblogic LoadModule weblogic_module modules/mod_wl_24.so \u003cIfModule mod_weblogic.c\u003e WebLogicCluster IP:PORT,IP:PORT,IP:PORT ConnectTimeoutSecs 8 ConnectRetrySecs 2 Idempotent OFF DynamicServerList OFF MatchExpression * KeepAliveEnabled OFF \u003c/IfModule\u003e \u003cLocation /api \u003e WLSRequest On #SetHandler weblogic-handler WebLogicCluster IP:PORT,IP:PORT,IP:PORT #Idempotent OFF \u003c/Location\u003e windows install command (Apache Lounge) httpd.exe -k install httpd.exe -k configtest configure  httpd.conf  ServerRoot \"Z:/www/httpd_2.4.25-win64-VC14/Apache24\" Listen 80 LoadModule access_compat_module modules/mod_access_compat.so LoadModule actions_module modules/mod_actions.so LoadModule alias_module modules/mod_alias.so LoadModule allowmethods_module modules/mod_allowmethods.so LoadModule asis_module modules/mod_asis.so LoadModule auth_basic_module modules/mod_auth_basic.so #LoadModule auth_digest_module modules/mod_auth_digest.so #LoadModule auth_form_module modules/mod_auth_form.so #LoadModule authn_anon_module modules/mod_authn_anon.so LoadModule authn_core_module modules/mod_authn_core.so #LoadModule authn_dbd_module modules/mod_authn_dbd.so #LoadModule authn_dbm_module modules/mod_authn_dbm.so LoadModule authn_file_module modules/mod_authn_file.so #LoadModule authn_socache_module modules/mod_authn_socache.so #LoadModule authnz_fcgi_module modules/mod_authnz_fcgi.so #LoadModule authnz_ldap_module modules/mod_authnz_ldap.so LoadModule authz_core_module modules/mod_authz_core.so #LoadModule authz_dbd_module modules/mod_authz_dbd.so #LoadModule authz_dbm_module modules/mod_authz_dbm.so LoadModule authz_groupfile_module modules/mod_authz_groupfile.so LoadModule authz_host_module modules/mod_authz_host.so #LoadModule authz_owner_module modules/mod_authz_owner.so LoadModule authz_user_module modules/mod_authz_user.so LoadModule autoindex_module modules/mod_autoindex.so #LoadModule buffer_module modules/mod_buffer.so #LoadModule cache_module modules/mod_cache.so #LoadModule cache_disk_module modules/mod_cache_disk.so #LoadModule cache_socache_module modules/mod_cache_socache.so #LoadModule cern_meta_module modules/mod_cern_meta.so LoadModule cgi_module modules/mod_cgi.so #LoadModule charset_lite_module modules/mod_charset_lite.so #LoadModule data_module modules/mod_data.so #LoadModule dav_module modules/mod_dav.so #LoadModule dav_fs_module modules/mod_dav_fs.so #LoadModule dav_lock_module modules/mod_dav_lock.so #LoadModule dbd_module modules/mod_dbd.so #LoadModule deflate_module modules/mod_deflate.so LoadModule dir_module modules/mod_dir.so #LoadModule dumpio_module modules/mod_dumpio.so LoadModule env_module modules/mod_env.so #LoadModule expires_module modules/mod_expires.so #LoadModule ext_filter_module modules/mod_ext_filter.so #LoadModule file_cache_module modules/mod_file_cache.so #LoadModule filter_module modules/mod_filter.so #LoadModule http2_module modules/mod_http2.so LoadModule headers_module modules/mod_headers.so #LoadModule heartbeat_module modules/mod_heartbeat.so #LoadModule heartmonitor_module modules/mod_heartmonitor.so #LoadModule ident_module modules/mod_ident.so #LoadModule imagemap_module modules/mod_imagemap.so LoadModule include_module modules/mod_include.so #LoadModule info_module modules/mod_info.so LoadModule isapi_module modules/mod_isapi.so #LoadModule lbmethod_bybusyness_module modules/mod_lbmethod_bybusyness.so #LoadModule lbmethod_byrequests_module modules/mod_lbmethod_byrequests.so #LoadModule lbmethod_bytraffic_module modules/mod_lbmethod_bytraffic.so #LoadModule lbmethod_heartbeat_module modules/mod_lbmethod_heartbeat.so #LoadModule ldap_module modules/mod_ldap.so #LoadModule logio_module modules/mod_logio.so LoadModule log_config_module modules/mod_log_config.so #LoadModule log_debug_module modules/mod_log_debug.so #LoadModule log_forensic_module modules/mod_log_forensic.so #LoadModule lua_module modules/mod_lua.so #LoadModule macro_module modules/mod_macro.so LoadModule mime_module modules/mod_mime.so #LoadModule mime_magic_module modules/mod_mime_magic.so LoadModule negotiation_module modules/mod_negotiation.so LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_ajp_module modules/mod_proxy_ajp.so LoadModule proxy_balancer_module modules/mod_proxy_balancer.so LoadModule proxy_connect_module modules/mod_proxy_connect.so LoadModule proxy_express_module modules/mod_proxy_express.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so LoadModule proxy_ftp_module modules/mod_proxy_ftp.so LoadModule proxy_hcheck_module modules/mod_proxy_hcheck.so LoadModule proxy_html_module modules/mod_proxy_html.so LoadModule proxy_http_module modules/mod_proxy_http.so #LoadModule proxy_http2_module modules/mod_proxy_http2.so #LoadModule proxy_scgi_module modules/mod_proxy_scgi.so #LoadModule proxy_wstunnel_module modules/mod_proxy_wstunnel.so #LoadModule ratelimit_module modules/mod_ratelimit.so #LoadModule reflector_module modules/mod_reflector.so #LoadModule remoteip_module modules/mod_remoteip.so #LoadModule request_module modules/mod_request.so #LoadModule reqtimeout_module modules/mod_reqtimeout.so LoadModule rewrite_module modules/mod_rewrite.so #LoadModule sed_module modules/mod_sed.so #LoadModule session_module modules/mod_session.so #LoadModule session_cookie_module modules/mod_session_cookie.so #LoadModule session_crypto_module modules/mod_session_crypto.so #LoadModule session_dbd_module modules/mod_session_dbd.so LoadModule setenvif_module modules/mod_setenvif.so #LoadModule slotmem_plain_module modules/mod_slotmem_plain.so LoadModule slotmem_shm_module modules/mod_slotmem_shm.so #LoadModule socache_dbm_module modules/mod_socache_dbm.so #LoadModule socache_memcache_module modules/mod_socache_memcache.so LoadModule socache_shmcb_module modules/mod_socache_shmcb.so #LoadModule speling_module modules/mod_speling.so LoadModule ssl_module modules/mod_ssl.so #LoadModule status_module modules/mod_status.so #LoadModule substitute_module modules/mod_substitute.so #LoadModule unique_id_module modules/mod_unique_id.so #LoadModule userdir_module modules/mod_userdir.so #LoadModule usertrack_module modules/mod_usertrack.so #LoadModule version_module modules/mod_version.so #LoadModule vhost_alias_module modules/mod_vhost_alias.so LoadModule watchdog_module modules/mod_watchdog.so LoadModule xml2enc_module modules/mod_xml2enc.so \u003cIfModule unixd_module\u003e User daemon Group daemon \u003c/IfModule\u003e ServerAdmin hi@mgkim.net ServerName mgkim.net:50001 \u003cDirectory /\u003e AllowOverride none Require all denied \u003c/Directory\u003e DocumentRoot \"Z:/www/20210825_171631\" \u003cDirectory \"Z:/www/20210825_171631\"\u003e Options Indexes FollowSymLinks AllowOverride None Require all granted \u003c/Directory\u003e \u003cIfModule dir_module\u003e DirectoryIndex index.html \u003c/IfModule\u003e \u003cFiles \".ht*\"\u003e Require all denied \u003c/Files\u003e ErrorLog \"logs/error.log\" LogLevel warn \u003cIfModule log_config_module\u003e LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b\" common \u003cIfModule logio_module\u003e LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" %I %O\" combinedio \u003c/IfModule\u003e CustomLog \"logs/access.log\" common \u003c/IfModule\u003e \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"c:/Apache24/cgi-bin/\" \u003c/IfModule\u003e \u003cIfModule headers_module\u003e RequestHeader unset Proxy early \u003c/IfModule\u003e \u003cIfModule mime_module\u003e TypesConfig conf/mime.types AddType application/x-compress .Z AddType application/x-gzip .gz .tgz \u003c/IfModule\u003e ### include Include conf/extra/vhost-dlog.conf Include conf/extra/ssl.conf ### exclude #Include conf/extra/httpd-mpm.conf #Include conf/extra/httpd-multilang-errordoc.conf #Include conf/extra/httpd-autoindex.conf #Include conf/extra/httpd-languages.conf #Include conf/extra/httpd-userdir.conf #Include conf/extra/httpd-info.conf #Include conf/extra/httpd-manual.conf #Include conf/extra/httpd-dav.conf #Include conf/extra/httpd-default.conf #\u003cIfModule proxy_html_module\u003e # Include conf/extra/proxy-html.conf #\u003c/IfModule\u003e \u003cIfModule ssl_module\u003e SSLRandomSeed startup builtin SSLRandomSeed connect builtin \u003c/IfModule\u003e  ssl.conf  Listen 9443 #Listen 443 SSLCipherSuite HIGH:MEDIUM:!MD5:!RC4 SSLProxyCipherSuite HIGH:MEDIUM:!MD5:!RC4 SSLHonorCipherOrder on SSLProtocol all -SSLv3 SSLProxyProtocol all -SSLv3 SSLPassPhraseDialog builtin SSLSessionCache \"shmcb:c:/Apache24/logs/ssl_scache(512000)\" SSLSessionCacheTimeout 300  vhost-dlog.conf  #\u003cVirtualHost *:80\u003e # ServerName vdlog.mgkim.net:80 # # RewriteEngine On # RewriteCond %{HTTPS} !=On # RewriteRule /(.*) https://vdlog.mgkim.net:9443/$1 [QSA,R,L] #\u003c/VirtualHost\u003e # #\u003cVirtualHost *:9443\u003e # ServerName vdlog.mgkim.net:9443 # # ErrorLog \"|bin/rotatelogs.exe logs/vdlog.mgkim.net_ssl-error.log.%Y-%m-%d 86400 +540\" # CustomLog \"|bin/rotatelogs.exe logs/vdlog.mgkim.net_ssl-access.log.%Y-%m-%d 86400 +540\" combined # # SSLEngine On # SSLProxyEngine On # SSLProtocol all -SSLv2 # SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 # SSLCertificateFile conf/certs/STAR.mgkim.net.crt # SSLCertificateKeyFile conf/certs/STAR.mgkim.net.key # # ProxyRequests Off # ProxyPreserveHost On # # \u003cProxy gitlab\u003e # Require all granted # \u003c/Proxy\u003e # # AllowEncodedSlashes On # Header set Access-Control-Allow-Origin \"*\" # # ProxyPass / http://127.0.0.1:1313/ # ProxyPassReverse / http://127.0.0.1:1313/ #\u003c/VirtualHost\u003e \u003cVirtualHost *:80\u003e ServerName vdlog.mgkim.net:80 ServerAlias mgkim.net:80 ErrorLog \"|bin/rotatelogs.exe logs/vdlog.mgkim.net-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|bin/rotatelogs.exe logs/vdlog.mgkim.net-access.log.%Y-%m-%d 86400 +540\" combined ProxyRequests Off ProxyPreserveHost On \u003cProxy gitlab\u003e Require all granted \u003c/Proxy\u003e AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" ProxyPass / http://127.0.0.1:1313/ ProxyPassReverse / http://127.0.0.1:1313/ \u003c/VirtualHost\u003e \u003cVirtualHost *:80\u003e ServerName vdlog:80 RewriteEngine On RewriteCond %{HTTPS} !=On RewriteRule /(.*) https://vdlog:9443/$1 [QSA,R,L] \u003c/VirtualHost\u003e \u003cVirtualHost *:9443\u003e ServerName vdlog:9443 SSLEngine On SSLProxyEngine On #SSLProxyCheckPeerCN On #SSLProxyCheckPeerExpire On SSLProtocol all -SSLv2 SSLCipherSuite HIGH:MEDIUM:!aNULL:!MD5 SSLCertificateFile conf/certs/vdlog.crt SSLCertificateKeyFile conf/certs/vdlog.key RewriteEngine On RewriteRule /(.*) https://dlog.mgkim.net:443/$1 [QSA,P,L] \u003c/VirtualHost\u003e openssl 인증서 생성하기  개인키(key) 생성 인증서발급신청서(CSR) 생성 인증서(CRT) 생성  useful 개인키(domain.key)와 인증서(domain.crt) 파일을 동시에 생성하는 스크립트 입니다.\n[root@develop /etc/httpd/conf.d/certs]$ cat create-cert.sh DOMAIN=$1 openssl req -x509 -nodes -days 730 -newkey rsa:2048 -keyout $DOMAIN.key -out $DOMAIN.crt -config \u003c(cat \u003c\u003c- TEXT [req] distinguished_name = req_distinguished_name x509_extensions = v3_req prompt = no [req_distinguished_name] countryName = KR stateOrProvinceName = Seoul localityName = Seonyudo organizationName = SPACESOFT organizationalUnitName = Dev Team CN = $DOMAIN [v3_req] keyUsage = critical, digitalSignature, keyAgreement extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1 = $DOMAIN TEXT) -sha256 [root@develop /etc/httpd/conf.d/certs]$ selinux chcon -Rt httpd_log_t /outlog/WEB chcon -Rt httpd_sys_content_t /app/WEB/dlog setsebool -P httpd_can_network_connect on systemctl restart httpd ","categories":"","description":"","excerpt":"command loaded 모듈 목록 확인 httpd -M\n새 창 보기\nconfigure httpd.conf …","ref":"/system/httpd/","tags":"","title":"httpd"},{"body":"installation start 스크립트 #!/bin/sh  #JAVA_HOME=/prod/java/jdk1.8.0_202 JAVA_HOME=/prod/java/openjdk-11.0.2 export PATH=$JAVA_HOME/bin:$PATH JAVA_OPTS=\"${JAVA_OPTS}-Dapp.id=jenkins\" JAVA_OPTS=\"${JAVA_OPTS}-Dcom.sun.akuma.Daemon=daemonized\" JAVA_OPTS=\"${JAVA_OPTS}-Djava.awt.headless=true\" JAVA_OPTS=\"${JAVA_OPTS}-DJENKINS_HOME=/data/PROD/jenkins\" JENKINS_ARGS=\"${JENKINS_ARGS}--logfile=/outlog/PROD/jenkins/default.log\" JENKINS_ARGS=\"${JENKINS_ARGS}--webroot=/prod/jenkins/jenkins/cache-war\" JENKINS_ARGS=\"${JENKINS_ARGS}--daemon\" JENKINS_ARGS=\"${JENKINS_ARGS}--httpPort=8400\" JENKINS_ARGS=\"${JENKINS_ARGS}--debug=5\" JENKINS_ARGS=\"${JENKINS_ARGS}--handlerCountMax=100\" JENKINS_ARGS=\"${JENKINS_ARGS}--handlerCountMaxIdle=20\" JENKINS_ARGS=\"${JENKINS_ARGS}--accessLoggerClassName=winstone.accesslog.SimpleAccessLogger\" JENKINS_ARGS=\"${JENKINS_ARGS}--simpleAccessLogger.format=combined\" JENKINS_ARGS=\"${JENKINS_ARGS}--simpleAccessLogger.file=/outlog/PROD/jenkins/access.log\" #JENKINS_ARGS=\"${JENKINS_ARGS} --httpsCertificate=/etc/pki/tls/mgkim/jenkins.crt\" #JENKINS_ARGS=\"${JENKINS_ARGS} --httpsPrivateKey=/etc/pki/tls/mgkim/jenkins.key\" case \"$1\" in start) echo \"starting jenkins\" nohup $JAVA_HOME/bin/java $JAVA_OPTS -jar /prod/jenkins/jenkins/jenkins.war $JENKINS_ARGS \u003e /dev/null 2\u003e\u00261 \u0026 ;; stop) echo \"stopping jenkins\" ps -ef | grep java | grep -v grep | grep jenkins | awk '{ print $2 }' | xargs kill -9 ;; *) echo \"Usage: $0{start|stop}\" exit 1 ;; esac \nsystemd 등록 [Unit] Description=Jenkins After=network.target syslog.target [Service] Type=forking User=jenkins Group=ci ExecStart=/prod/jenkins/jenkins.sh start ExecStop=/prod/jenkins/jenkins.sh stop Restart=on-abort [Install] WantedBy=multi-user.target \nplugins Publish Over SSH mvn 빌드 후 생성된 artifact 파일을 sftp 로 전송하고 ssh 로 command 를 실행하는 기능을 사용할 수 있습니다.\n 프로젝트 구성에서 빌드 후 조치 \u003e Send build artifacts over SSH 선택 Add Server 버튼을 클릭하여 SSH Server 선택  선택되는 서버는 빌드 결과물인 artifact 파일을 전송하고, ssh 로 command 를 실행할 서버를 의미함 아래 Transfer Set 에 설정되는 Exec command의 내용이 빌드 로그에 출력되도록 고급버튼을 눌러 Verbose output in console 을 선택할 것 [INFO] ------------------------------------------------------------------------ SSH: Connecting from host [i9-9900K] SSH: Connecting with configuration [tomcat@develop] ... SSH: Creating session: username [tomcat], hostname [develop], port [22] SSH: Connecting session ... SSH: Connected SSH: Opening SFTP channel ... SSH: SFTP channel open SSH: Connecting SFTP channel ... SSH: Connected SSH: cd [/app/WAS/prototype] SSH: OK SSH: cd [/app/WAS/prototype] SSH: OK SSH: cd [boot-www] SSH: OK SSH: put [boot-www-0.0.1-SNAPSHOT.war] SSH: OK SSH: cd [/app/WAS/prototype] SSH: OK SSH: cd [boot-www] SSH: OK SSH: put [deploy.sh] SSH: OK SSH: Opening exec channel ... SSH: EXEC: channel open SSH: EXEC: STDOUT/STDERR from command [chmod u+x /app/WAS/prototype/boot-www/deploy.sh /app/WAS/prototype/boot-www/deploy.sh restart] ... SSH: EXEC: connected Stopping boot-www stopped boot-www Starting boot-www SSH: EXEC: completed after 1,202 ms SSH: Disconnecting configuration [tomcat@develop] ... SSH: Transferred 2 ( 1 + 1 ) file(s) Finished: SUCCESS    Add Transfer Set 버튼을 클릭하여 Transfers Set 입력  Source files: 전송할 파일을 입력 (예: **/target/*.war) Remove prefix: 전송시 source files 의 파일경로를 제거 (예: ./boot-www/target/) Remote directory: … (예: boot-www 라고 입력하면 /app/WAS/prototype/boot-www 이렇게 base-dir 하위에 디렉토리를 생성하여 source files 가 전송됨) Exec command: 파일 전송 후 실행할 command 를 입력 (배포 후 container 재시작을 하기 위한 command 입력) 참고로 war 파일과 was 재시작을 위한 sh 파일을 같이 전송해야하는 경우에는 Transfers Set을 2개로 나눠서 전송하는 방법도 있음    SSH Server 추가하기 SSH Server 는 Jenkins 관리 \u003e 시스템 설정 \u003e Publish over SSH 에서 추가를 해야 선택하는 항목이 나옵니다.\n Passphrase: 시스템 계정 jenkins 로 생성한 rsa 키의 비밀번호를 입력합니다. Path to key: rsa 키 쌍 중 개인키의 경로를 입력합니다. (/home/jenkins/.ssh/id_rsa) jenkins node 구성에서 slave-node 을 추가했다면 jenkins 를 호스팅하고 있는 서버에서 생성한 개인키 파일에 접근할 수 없기에 Key 항목에 개인키를 설정하여 사용해야 함 Key: 개인키의 경로를 입력하지 않을 경우 개인키의 내용 추가로 설정할 수 있습니다. (키 경로 입력 시 생략할 것) 개인키의 형태는 다음과 같으며 참고로 jenkins 에 설정할때에는 BEGIN 부터 END 까지 모두 입력해야 합니다. -----BEGIN RSA PRIVATE KEY----- Proc-Type: 4,ENCRYPTED DEK-Info: AES-128-CBC,BB513C74CDF53133B6B805F08C716E14 lqXA6gIhaf3ztU1SoQVGvUtLWtXqINxbGzNfau3v+DIHRKJjVY1JvBj2mmADIxEq … YqTPbiAOgnHAD9CgWg/v55Zl9zLrPKLakCJPYzGNrLo2BJ4qXR1ZX371JEsXq8tq —–END RSA PRIVATE KEY—– \nSSH Servers에 추가 버튼을 클릭하여 hostname, username, remote directory 입력합니다. 입력이 끝나고 Test Configuration 버튼을 클릭하여 테스트를 해봅니다.   GitLab Plugin gitlab 과 연동하기 위한 플러그인입니다.\ngitlab 에서 push 이벤트가 발생했을 경우 jenkins 에서 build 가 실행되도록 하기위해 사용됩니다.\n gitlab 에서 User Settings \u003e Access Tokens 메뉴에서 Access Token 을 생성할 것 jenkins 플러그인 관리에서 GitLab Plugin 을 검색하고 설치 jenkins 관리 \u003e Manage Credentials 로 이동하여 Access Token을 추가함 jenkins 관리 \u003e 시스템 설정 메뉴로 이동하여 Gitlab 섹션으로 이동  Credentials: Manage Credentials에서 추가한 Gitlab API token 을 선택하고 Test Connection 버튼을 클릭하여 동작을 확인함   프로젝트의 구성에서 빌드 유발 섹션으로 이동  Build when a change is pushed to GitLab. GitLab webhook URL: http://jenkins/project/boot-www: 이 항목을 체크하면 세부 항목들이 나타남. (세부 항목에 대해 모르면 기본 체크 상태 유지) Secret token: (이 항목은 고급 버튼을 클릭해야 나타남) Generate 버튼을 클릭하면 값이 생성됨.    GitLab webhook URL, Secret token 항목을 gitlab Webhooks 에 설정하기 아래 2개의 항목은 gitlab 의 프로젝트 설정의 Webhooks 에서 설정해야하는 값입니다.\n GitLab webhook URL: 이 값은 체크항목에 레이블로 표시되어있는 http://jenkins/project/boot-www 이며, Webhooks 의 URL 에 입력해야 하는 값. Secret token: 이 값은 Generate 버튼 클릭으로 생성되며, Webhooks 의 Secret Token 에 입력해야 하는 값.   GitHub Integration Plugin github 저장소에서 webhook 으로 push 이벤트를 받아서 jenkins build가 실행되도록 할 때 사용합니다.\n활용법: github 연결\nbuild 분산 빌드 환경 jenkins 관리 에서 노드 관리 메뉴로 이동하면 분산 빌드 환경을 위한 노드를 추가할 수 있습니다.\n이 환경을 구성하면 jenkins 가 설치된 서버에서는 더 이상 빌드를 수행하지 않고 추가된 노드에서 빌드가 수행됩니다.\n다음은 windows 환경의 slave-node를 추가하는 예시입니다. (jenkins 는 master-node이며, 추가되는 node들은 slave-node 입니다.)\n주요 설정 항목  Name: slave-node 이름 (설명에는 9900K 로 했습니다.) Remote root directory: slave-node 의 workspace 디렉토리를 지정합니다. 참고로 Z:\\jenkins 라고 입력하면 빌드 시 Z:\\jenkins\\workspace\\boot-www 디렉토리가 생성됩니다. (boot-www 는 jenkins 프로젝트명 입니다.) Labels: jenkins 프로젝트에 label 을 설정할 수 있으며, 해당 프로젝트에 포함된 label 과 매핑된 노드에서 빌드가 수행됨 Launch method: Use WebSocket 항목을 체크할 것   slave-node 를 추가하면 slave-node에서 jenkins 와 연결하는 방법을 알려줍니다.\nConnect agent to Jenkins one of these ways: Java Web Start is not available for the JVM version running Jenkins Run from agent command line: javaws http://jenkins/computer/9900K/jenkins-agent.jnlp Or if the agent is headless: java -jar agent.jar -jnlpUrl http://jenkins/computer/9900K/jenkins-agent.jnlp -workDir \"Z:\\jenkins\" slave-node 와 jenkins 연결하기\n  Z:\\jenkins 에 agent.jar 를 다운로드 받음\n  Z:\\jenkins\\start-agent.cmd 파일을 생성하고 아래 내용으로 설정\nset JAVA_HOME=Z:\\develop\\java\\openjdk-11.0.2 set PATH=%JAVA_HOME%\\bin;%PATH% java -jar agent.jar -jnlpUrl http://jenkins/computer/9900K/jenkins-agent.jnlp -workDir \"Z:\\jenkins\"   start-agent.cmd 실행 후 아래와 같이 console 로그가 출력되면 정상 실행\nZ:\\jenkins\u003eset JAVA_HOME=Z:\\develop\\java\\openjdk-11.0.2 Z:\\jenkins\u003eset PATH=Z:\\develop\\java\\openjdk-11.0.2\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Git\\cmd;C:\\Program Files\\nodejs\\;C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps;Z:\\oracle\\ora12c_32bit\\client_12_1\\bin;Z:\\develop\\java\\openjdk-11.0.2\\bin;Z:\\develop\\build\\maven-3.6.3\\bin;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;Z:\\develop\\hugo\\hugo-ext-0.87.0;C:\\Users\\Administrator\\AppData\\Roaming\\npm;Z:\\www\\httpd_2.4.25-win64-VC14\\openssl-0.9.8e_X64\\bin; Z:\\jenkins\u003ejava -jar agent.jar -jnlpUrl http://jenkins/computer/9900K/jenkins-agent.jnlp -workDir \"Z:\\jenkins\" 9월 13, 2021 11:55:53 오후 org.jenkinsci.remoting.engine.WorkDirManager initializeWorkDir INFO: Using Z:\\jenkins\\remoting as a remoting work directory 9월 13, 2021 11:55:53 오후 org.jenkinsci.remoting.engine.WorkDirManager setupLogging INFO: Both error and output logs will be printed to Z:\\jenkins\\remoting 9월 13, 2021 11:55:53 오후 hudson.remoting.jnlp.Main createEngine INFO: Setting up agent: 9900K 9월 13, 2021 11:55:53 오후 hudson.remoting.jnlp.Main$CuiListener \u003cinit\u003e INFO: Jenkins agent is running in headless mode. 9월 13, 2021 11:55:53 오후 hudson.remoting.Engine startEngine INFO: Using Remoting version: 4.10 9월 13, 2021 11:55:53 오후 org.jenkinsci.remoting.engine.WorkDirManager initializeWorkDir INFO: Using Z:\\jenkins\\remoting as a remoting work directory 9월 13, 2021 11:55:53 오후 hudson.remoting.jnlp.Main$CuiListener status INFO: WebSocket connection open 9월 13, 2021 11:55:53 오후 hudson.remoting.jnlp.Main$CuiListener status INFO: Connected 참고로 여기서 연결이 안되는 상황이 발생함\n agent.jar 실행 시 jenkins 에 접속할 때 websocket 으로 접속을 하게되는데 ssl 이 적용된 프로토콜 https, wss 은 handshake 오류가 발생함 httpd 설정에 http 를 https 로 redirect 하도록 mod_rewrite 를 설정했는데 오류로 인해 rewrite 설정은 제거함 jenkins 의 가상호스트 설정은 다음과 같습니다. \u003cVirtualHost *:80\u003e ServerName jenkins ErrorLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/jenkins-error.log.%Y-%m-%d 86400 +540\" CustomLog \"|/usr/sbin/rotatelogs /outlog/WEB/httpd/jenkins-access.log.%Y-%m-%d 86400 +540\" combined AllowEncodedSlashes On Header set Access-Control-Allow-Origin \"*\" RewriteEngine On RewriteCond %{HTTP:Upgrade} =websocket [NC] RewriteRule /(.*) ws://localhost:8400/$1 [P,L] RewriteCond %{HTTP:Upgrade} !=websocket [NC] RewriteRule /(.*) http://localhost:8400/$1 [P,L] \u003c/VirtualHost\u003e     jenkins 프로젝트에 label 을 추가된 slave-node 의 label 로 변경하고 빌드를 실행하면 Z:\\jenkins\\workspace\\ 디렉토리에 jenkins 프로젝트 디렉토리가 생성되고 소스 코드 관리를 설정했을 경우 소스코드가 checkout 되어있을 것입니다.\n   이후 Publish Over SSH 플러그인을 사용하여 was 서버에 war 파일을 publish 를 하고 was 를 재시작하는 command 를 ssh 로 수행하도록 설정하면 됩니다.  github 연결 required plugin: GitHub Integration Plugin\njenkins 프로젝트의 소스 코드 관리 섹션에서 github 저장소와 연결하는 설정입니다.\n Repository URL: github 의 프로젝트 저장소 url 을 입력 https://github.com/lislroow/spring.git Credentials: github 에서 Personal access tokens 을 발급받고 jenkins 에 등록하고 선택  github 에서 Personal access tokens 발급 및 jenkins Credentials 등록  github 로그인 후 Settings \u003e Developer settings \u003e Personal access tokens 메뉴 이동 Generate new token 버튼 클릭 후 Expiration 과 Select scopes 를 선택 Select scopes은 repo, admin:repo_hook를 전체 선택 Generate token 버튼 클릭으로 토큰을 생성  생성된 토큰(access token) 값은 다시 확인할 수 없습니다. (재생성해야하는 것으로 알고 있음) jenkins 에 등록될 access token 은 github 의 id 와 함께 사용되는 패스워드입니다.   jenkins Manage Credentials 에서 Add Credentials 을 합니다.  Kind: Username with password 를 선택합니다. Username: github 에 로그인할 때 사용하는 id 를 입력합니다. (lislroow) Password: github 에서 생성한 토큰(access token)을 입력합니다. (ghp_***생략***)     jenkins 프로젝트의 빌드 유발 섹션에서 github 저장소에 push 이벤트를 받을 수 있도록 설정합니다. GitHub hook trigger for GITScm polling 체크\ngithub 에서 push 이벤트 jenkins 로 전송하기  github 의 프로젝트로 이동한 다음 Settings \u003e Webhooks 메뉴로 이동합니다. Add webhook 버튼을 클릭하여 다음을 입력합니다.  Payload URL: http://{jenkins-domain}/github-webhook/ 으로 입력합니다. 참고로 uri 는 반드시 /github-webhook/ 으로 되어야 합니다. (/github-webhook 으로하면 302 를 응답받고 실패합니다.) Payload URL 을 입력하게되면 github 저장소에 push 이벤트가 발생할 때 해당 URL 을 호출하게되고, jenkins 는 이 http 요청을 받고 build 를 실행하게 되는 형태입니다. Content type: application/json 으로 설정 저장 후 소스코드를 수정하고 commit;push 를 하게되면 추가된 webhook 항목을 클릭했을 때 Recent Deliveries 를 볼 수 있습니다.     ","categories":"","description":"","excerpt":"installation start 스크립트 #!/bin/sh  #JAVA_HOME=/prod/java/jdk1.8.0_202 …","ref":"/system/jenkins/","tags":"","title":"jenkins"},{"body":"_cat/indices 인덱스 목록, index명 desc 정렬, index 컬럼만 조회\nGET _cat/indices?v\u0026s=index:desc\u0026h=index ","categories":"","description":"","excerpt":"_cat/indices 인덱스 목록, index명 desc 정렬, index 컬럼만 조회\nGET …","ref":"/system/kibana/","tags":"","title":"kibana"},{"body":"systemd systemd 는 centos 7 부터 포함된 기능입니다.\n/etc/init.d 에서 서비스를 관리했던 것을 systemd 로 관리하게 되었습니다.\n실행 명령어는 systemctl 입니다.\n서비스 생성 새로운 서비스를 등록할 경우 아래 템플릿으로 파일을 생성합니다.\n 파일경로: /etc/systemd/system/{서비스명}.service  [root@develop /etc/systemd/system]$ cat jenkins.service [Unit] Description=Jenkins After=network.target syslog.target [Service] Type=forking User=jenkins Group=ci ExecStart=/prod/jenkins/jenkins.sh start ExecStop=/prod/jenkins/jenkins.sh stop Restart=on-abort [Install] WantedBy=multi-user.target [root@develop /etc/systemd/system]$ yum 으로 패키지 설치시 systemctl 에 등록된 정보를 아래와 같은 방법으로 확인합니다.\n[root@develop /etc/systemd/system]$ systemctl --help systemctl [OPTIONS...] {COMMAND} ... Unit Commands: list-units [PATTERN...] List loaded units [root@develop /etc/systemd/system]$ systemctl list-units | grep httpd httpd.service loaded active running The Apache HTTP Server [root@develop /etc/systemd/system]$ [root@develop /etc/systemd/system]$ systemctl status httpd.service ● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) [root@develop /etc/systemd/system]$ httpd 의 서비스 파일은 /usr/lib/systemd/system/httpd.service 에 있음을 확인할 수 있습니다.\n서비스 등록 서비스 파일을 생성한 다음 systemctl 에 등록을 해야 합니다.\n[root@develop /etc/systemd/system]$ systemctl --help | grep reload --no-reload Don't reload daemon after en-/dis-abling unit files reload NAME... Reload one or more units reload-or-restart NAME... Reload one or more units if possible, reload-or-try-restart NAME... Reload one or more units if possible, daemon-reload Reload systemd manager configuration [root@develop /etc/systemd/system]$ [root@develop /etc/systemd/system]$ systemctl daemon-reload [root@develop /etc/systemd/system]$ systemctl daemon-reload 명령으로 reload 를 합니다.\n서비스 활성화 서비스 활성화 상태로 설정을 하게되면 os booting 시 자동으로 실행이 됩니다.\n[root@develop /etc/systemd/system]$ systemctl --help | grep enable --preset-mode= Apply only enable, only disable, or all presets enable NAME... Enable one or more unit files reenable NAME... Reenable one or more unit files is-enabled NAME... Check whether unit files are enabled [root@develop /etc/systemd/system]$ [root@develop /etc/systemd/system]$ systemctl is-enabled orcl@oracledb.service enabled [root@develop /etc/systemd/system]$ systemctl is-enabled httpd.service enabled [root@develop /etc/systemd/system]$ systemctl enable {서비스} 명령으로 enabled 상태로 설정합니다.\nnetwork [root@develop ~]$ cat /etc/sysconfig/network-scripts/ifcfg-ens32 TYPE=\"Ethernet\" PROXY_METHOD=\"none\" BROWSER_ONLY=\"no\" BOOTPROTO=\"none\" DEFROUTE=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"no\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_FAILURE_FATAL=\"no\" IPV6_ADDR_GEN_MODE=\"stable-privacy\" NAME=\"ens32\" UUID=\"d18679f4-c760-4621-b73a-8e7b513594a7\" DEVICE=\"ens32\" ONBOOT=\"yes\" IPADDR=\"172.28.200.20\" PREFIX=\"24\" GATEWAY=\"172.28.200.2\" DNS1=\"8.8.8.8\" [root@develop ~]$ hostname [root@develop ~]$ hostnamectl set-hostname develop [root@develop ~]$ shell [ -z ] : 문자열의 길이가 0이면 참 [ -n ] : 문자열의 길이가 0이 아니면 참 [ -eq ] : 값이 같으면 참 [ -ne ] : 값이 다르면 참 [ -gt ] : 값1 \u003e 값2 [ -ge ] : 값1 \u003e= 값2 [ -lt ] : 값1 \u003c 값2 [ -le ] : 값1 \u003c= 값2 [ -a ] : \u0026\u0026연산과 동일 and 연산 [ -o ] : ||연산과 동일 xor 연산 [ -d ] : 파일이 디렉토리면 참 [ -e ] : 파일이 있으면 참 [ -L ] : 파일이 심볼릭 링크면 참 [ -r ] : 파일이 읽기 가능하면 참 [ -s ] : 파일의 크기가 0 보다 크면 참 [ -w ] : 파일이 쓰기 가능하면 참 [ -x ] : 파일이 실행 가능하면 참 [ 파일1 -nt 파일2 ] : 파일1이 파일2보다 최신파일이면 참 [ 파일1 -ot 파일2 ] : 파일1이 파일2보다 이전파일이면 참 [ 파일1 -ef 파일2 ] : 파일1이 파일2랑 같은 파일이면 참 ","categories":"","description":"","excerpt":"systemd systemd 는 centos 7 부터 포함된 기능입니다.\n/etc/init.d …","ref":"/system/linux/","tags":"","title":"linux"},{"body":"(java) keytool 인증서 생성 java 에 포함되어 있는 keytool 명령으로 아래 절차로 인증서를 생성합니다.\n생성된 인증서는 spring-boot 어플리케이션 설정파일인 application.yaml 주요 설정값을 암복호화를 할 때 사용하려 합니다.\n# keytool 경로 확인 $ which keytool /z/develop/java/openjdk-11.0.13.8-temurin/bin/keytool # private-key 파일 생성 (mgkim-pc.jks) $ keytool -genkeypair -alias mgkim-pc -keyalg RSA -dname \"CN=mgkim, OU=API Development, O=mgkim.net, L=Seoul, C=KR\" -keypass \"votmdnjem\" -keystore mgkim-pc.jks -storepass \"votmdnjem\" $ ls -al mgkim-pc.* -rw-r--r-- 1 Administrator 197121 2733 2022-01-27 21:56 mgkim-pc.jks # 인증서 파일 생성 (mgkim-pc.cer) $ keytool -export -alias mgkim-pc -keystore mgkim-pc.jks -rfc -file mgkim-pc.cer 키 저장소 비밀번호 입력: votmdnjem 인증서가 \u003cmgkim-pc.cer\u003e 파일에 저장되었습니다. $ ls -al mgkim-pc.* -rw-r--r-- 1 Administrator 197121 1236 2022-01-27 21:58 mgkim-pc.cer -rw-r--r-- 1 Administrator 197121 2733 2022-01-27 21:56 mgkim-pc.jks # public-key 파일 생성 (mgkim-pc.jks.pub) $ keytool -import -alias mgkim-pc -file mgkim-pc.cer -keystore mgkim-pc.jks.pub 키 저장소 비밀번호 입력: votmdnjem 새 비밀번호 다시 입력: votmdnjem 소유자: CN=mgkim, OU=API Development, O=mgkim.net, L=Seoul, C=KR 발행자: CN=mgkim, OU=API Development, O=mgkim.net, L=Seoul, C=KR 일련 번호: 59e8ce89 적합한 시작 날짜: Thu Jan 27 21:56:38 KST 2022 종료 날짜: Wed Apr 27 21:56:38 KST 2022 인증서 지문: SHA1: 1D:5F:AF:4A:BE:13:E8:2C:3A:17:3D:DF:D4:0B:32:31:8C:FA:F2:88 SHA256: CC:89:1A:2A:E0:2E:6D:E5:82:12:57:B7:95:30:C8:09:F5:4D:46:13:C1:06:D1:3B:FB:A1:68:72:24:5E:18:A3 서명 알고리즘 이름: SHA256withRSA 주체 공용 키 알고리즘: 2048비트 RSA 키 버전: 3 확장: #1: ObjectId: 2.5.29.14 Criticality=false SubjectKeyIdentifier [ KeyIdentifier [ 0000: 89 34 C5 D9 38 29 88 26 43 6B DF B8 34 E7 AE 74 .4..8).\u0026Ck..4..t 0010: FD 35 0B 8F .5.. ] ] 이 인증서를 신뢰합니까? [아니오]: y 인증서가 키 저장소에 추가되었습니다. $ ls -al mgkim-pc.* -rw-r--r-- 1 Administrator 197121 1236 2022-01-27 21:58 mgkim-pc.cer -rw-r--r-- 1 Administrator 197121 2733 2022-01-27 21:56 mgkim-pc.jks -rw-r--r-- 1 Administrator 197121 1239 2022-01-27 22:00 mgkim-pc.jks.pub $  mgkim-pc.jks: private-key 파일 mgkim-pc.cer: 인증서 파일 mgkim-pc.jks.pub: public-key 파일  (docsy) Code highlighting with Prism 설정파일config.toml의 prism_syntax_highlighting = true 항목을 추가하면 prismjs.com 에서 배포하는 js/css 로 theme 를 적용할 수 있습니다.\n config.toml의 prism_syntax_highlighting = true 항목을 추가 prismjs.com 에서 스타일을 선택한 다음 prism.js, prism.css 파일 다운로드 prism.js, prism.css 파일은 각 /static/js/prism.js, /static/css/prism.css 에 복사  supported languages: 새 창 보기\n(maven) 패스워드 암호화 settings.xml에는 nexus 저장소에 deploy 를 할 때 아래와 같이 nexus 의 계정정보를 포함하고 있어야 합니다.\n\u003cservers\u003e \u003cserver\u003e \u003cid\u003enexus-release\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003e패스워드\u003c/password\u003e \u003c/server\u003e \u003cserver\u003e \u003cid\u003enexus-snapshot\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003e패스워드\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e 패스워드를 암호화하여 설정하는 방법입니다. (settings-security.xml 파일은 로컬 저장소 .m2 디렉토리에 있어야 합니다.)\n mvn -emp 마스터패스워드명령으로 master 패스워드 문자열을 생성하고, ~/.m2/settings-security.xml 파일을 아래와 같이 생성하고 저장합니다. (참고로 -emp 는 --encrypt-master-password 입니다.) $ mvn -emp 마스터패스워드 {h/JmfOxXj2IH/whyc5/7wpvOT5AeBmlHV/nzmk7rzY+i7vEvpg46lHddfEwHFtN1} $ $ cat \u003c\u003c EOF \u003e ~/.m2/settings-security.xml \u003csettingsSecurity\u003e \u003cmaster\u003e{h/JmfOxXj2IH/whyc5/7wpvOT5AeBmlHV/nzmk7rzY+i7vEvpg46lHddfEwHFtN1}\u003c/master\u003e \u003c/settingsSecurity\u003e EOF $  mvn -ep 패스워드명령으로 nexus 의 계정에 해당되는 패스워드 문자열을 생성하고 $M2_HOME/conf/settings.xml의 \u003cpassword\u003e에 추가합니다. $ mvn -ep 패스워드 {nvTOxUicu5EHTqNwVFkrSKjAQnANDMwZy6sCuPND00w=} $ vi $M2_HOME/conf/settings.xml \u003cserver\u003e \u003cid\u003enexus-snapshot\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003e{nvTOxUicu5EHTqNwVFkrSKjAQnANDMwZy6sCuPND00w=}\u003c/password\u003e \u003c/server\u003e   (windows) vbs MsgBox 사용하기 vbs 내용을 별도 파일MessageBox.vbs로 저장하고, cmd 창에서 cscript Z:/develop/script/MessageBox.vbs \"팝업 메시지\" 형태로 사용할 수 있습니다.\n(윈도우즈에서 백업 스크립트가 처리 완료되었음을 알릴 때 활용할 수 있습니다.)\nSet objArgs = WScript.Arguments messageText = objArgs(0) MsgBox messageText 백업 스크립트 새 창 보기\n(maven) deploy, release 관련 플러그인 spring-boot 를 배포할 때 의존성 라이브러리를 포함하여 executable-jar 파일을 생성하는 spring-boot:repackage 플러그인을 추가했습니다.\nmaven 기존 플러그인 maven-deploy-plugin 를 nexus-staging-maven-plugin 로 교체했습니다.\nrelease 버전의 아티팩트를 nexus 에 배포하고 버전을 올려주는 기능을 위해 maven-release-plugin 설정을 했습니다.\n\u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-deploy-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003c!-- nexus-staging-maven-plugin 로 인해 skip 설정을 해야 합니다. --\u003e \u003cskip\u003etrue\u003c/skip\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.sonatype.plugins\u003c/groupId\u003e \u003cartifactId\u003enexus-staging-maven-plugin\u003c/artifactId\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003c!-- default-deploy 에 추가합니다. --\u003e \u003cid\u003edefault-deploy\u003c/id\u003e \u003cphase\u003edeploy\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003edeploy\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003cconfiguration\u003e \u003c!-- nexus pro 버전에만 staging-repository 기능을 사용할 수 있습니다. --\u003e \u003cskipStaging\u003etrue\u003c/skipStaging\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003c!-- default-install 에 추가합니다. --\u003e \u003c!-- deploy 을 실행하면 실행됩니다. --\u003e \u003cid\u003edefault-install\u003c/id\u003e \u003cphase\u003einstall\u003c/phase\u003e \u003cgoals\u003e \u003c!-- spring-boot-maven-plugin 의 repackage 가 실행되도록 합니다. --\u003e \u003cgoal\u003erepackage\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-release-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003cautoVersionSubmodules\u003efalse\u003c/autoVersionSubmodules\u003e \u003c!-- release:perform 이 실행될 때 deploy 를 실행하여 --\u003e \u003c!-- spring-boot:repackage 까지 같이 실행되도록 합니다. --\u003e \u003cgoals\u003edeploy\u003c/goals\u003e \u003cscmCommentPrefix\u003e[build]\u003c/scmCommentPrefix\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \n(eclipse) path-tools (git-bash) 이클립스 Command Line Shell 버튼을 클릭할때 cmd 창이 아닌 git-bash 터미널이 열리도록 설정을 바꿀 수 있습니다.\n새 창 보기\n(git-bash) bash_profile.sh /etc/profile.d/bash_profile.sh\nalias dlog='cd /z/project/dlog' alias pilot='cd /z/project/pilot' alias deploy-dlog='/z/project/dlog/deploy.sh ' alias run-dlog='/z/project/dlog/run.sh ' alias ls='ls -F --color=auto --show-control-chars --time-style=long-iso ' \n(eclipse) ANSI Escape in Console 플러그인 ANSI Escape in Console 플러그인은 console 에 ANSI 색상 코드를 해당 색상으로 표시해주는 플러그인입니다.\n다른 ANSI 관련 플러그인은 console 의 텍스트를 복사(ctrl+c)할 때 색상코드까지 같이 복사되어 불편했는데 이 플러그인은 그런 부분이 개선되었습니다.\n새 창 보기\n(eclipse) Bash Editor 플러그인 Bash Editor 플러그인은 shell 스크립트 파일 편집을 할 때 구문강조 및 자동 완성 기능을 제공합니다.\n새 창 보기\n(eclipse) .md 파일 add bookmark Mylyn WikiText 플러그인으로 .md 파일을 열었을 경우에는 Add Bookmark 메뉴가 표시되지 않습니다.\nGeneric Text Editor 로 열어서 추가할 수 있으며 .md 파일 편집은 WikiText 로 하면 됩니다.\n(maven) help:evaluate 로컬 저장소 경로 mvn 명령으로 현재 설정된 로컬 저장소를 반환하는 goal 입니다.\n$ mvn help:evaluate -Dexpression=settings.localRepository -q -DforceStdout \n(maven) deploy:deploy-file 시 저장소 지정 pom.xml 에 포함되어있는 version 에 -SNAPSHOT 이 있으면 release 저장소에 deploy 할 수 없다는 오류가 발생하므로 주의가 필요합니다.\nMVN_ARGS=\"\" MVN_ARGS=\"${MVN_ARGS}-DpomFile=${PROJECT_BASE}/pom.xml\" MVN_ARGS=\"${MVN_ARGS}-Dfile=${PROJECT_BASE}/target/${JAR_FILE}\" # jar 파일명에 \"-SNAPSHOT\" 이 있으면 snapshot 저장소에 deploy 되어야 합니다.  if [[ \"${JAR_FILE}\" = *\"-SNAPSHOT\"* ]]; then MVN_ARGS=\"${MVN_ARGS}-DrepositoryId=maven-snapshot\" MVN_ARGS=\"${MVN_ARGS}-Durl=http://nexus/repository/maven-snapshot/\" else MVN_ARGS=\"${MVN_ARGS}-DrepositoryId=maven-release\" MVN_ARGS=\"${MVN_ARGS}-Durl=http://nexus/repository/maven-release/\" fi mvn deploy:deploy-file $MVN_ARGS \n(git) pull.ff only git config --global pull.ff only 설정을 추가하면 됩니다.\n$ git pull origin main warning: Pulling without specifying how to reconcile divergent branches is discouraged. You can squelch this message by running one of the following commands sometime before your next pull: git config pull.rebase false # merge (the default strategy) git config pull.rebase true # rebase git config pull.ff only # fast-forward only You can replace \"git config\" with \"git config --global\" to set a default preference for all repositories. You can also pass --rebase, --no-rebase, or --ff-only on the command line to override the configured default per invocation. \n(maven) spring-boot:repackage packaging 이 jar 인 프로젝트를 mvn package 으로 jar 를 생성한 다음에 mvn spring-boot:repackage 을 실행해야 합니다.\n리패키징이되면 jar 아티팩트에 의존성으로 설정된 jar 파일들이 포함됩니다.\n아래는 리패키징이 정상이면 볼 수 있는 로그 입니다.\n[INFO] --- spring-boot-maven-plugin:2.6.1:repackage (default-cli) @ service-www --- [INFO] Replacing main artifact with repackaged archive \n(maven) Malformed \\uxxxx encoding. maven 빌드 시 Malformed \\uxxxx encoding. 가 발생하면 로컬 저장소를 삭제하고 빌드해주세요.\n(git) turn off crlf warning warning: LF will be replaced by CRLF in 메시지를 보고 싶지 않을 경우 아래 옵션을 추가합니다.\n$ git config --global core.safecrlf false \n(hugo) 전체 rebuild 아래 2개의 디렉토리의 파일들을 모두 삭제하고 빌드를 합니다.\n/resources, /public\n(eclipse) 이클립스 로그 Z:\\develop\\eclipse\\eclipse-jee-R-win32-x86_64\\workspace\\.metadata\\.plugins\\org.eclipse.m2e.logback.configuration wintail 다운로드\n(windows) setx cmd 에서 아래 명령을 실행하면 시스템 변수 에 추가됩니다.\nsetx /m JAVA_HOME \"D:\\develop\\java\\openjdk-11.0.2\" \n(plex) DaumMovie.bundle https://github.com/axfree/DaumMovie.bundle\n%LOCALAPPDATA%\\Plex Media Server\\Plug-ins 에서 압축 해제합니다.\n(nexus) curl PUT curl -u {id}:{passwd} -X PUT -v -T org/apache/poi/poi/3.10-FINAL/poi-3.10-FINAL.jar http://nexus/repository/maven-public-hosted/org/apache/poi/poi/3.10-FINAL/poi-3.10-FINAL.jar \n(windows) dism dism(배포 이미지 서비스 및 관리) 이미지 생성, 분할, 추가, 삭제, 추출, 적용, 마운트, 언 마운트, 커밋들이 가능하다.\n(eclipse) xml editor: tab to space xml editor 에서 tab 키 입력 시 space 가 입력되도록 변환하는 방법은 2가지를 설정해야 합니다.\n single-line: General \u003e Editors \u003e Text Editors: Insert spaces for tabs 체크 multi-line: XML \u003e XML Files \u003e Editor: Indent using spaces 선택  새 창 보기\n(eclipse) mybatipse 플러그인 mybatipse 플러그인은 Mapper의 메소드명과 mybatis의 \u003csql\u003e을 ctrl + L-click으로 연결해주는 편의성을 제공합니다.\n(erwin) database connection 우선 display 를 물리 모델로 변경합니다.\n상단 메뉴 Database \u003e Database Connection 선택하면 아래 팝업 창이 열립니다.\nConnection String: 의 값은 tnsnames.ora 에 등록된 항목으로 입력합니다.\n새 창 보기\n(regex) not matched word # string say hello world # regex \\b(?!hello)\\b\\w+ # string release-service-bom release-service-www snapshot-service-bom snapshot-service-www # regex ^release\\-(?!.*\\-bom).* \n(maven) release github \u003cscm\u003e \u003cconnection\u003escm:git:git@github.com:lislroow/pilot.git\u003c/connection\u003e \u003c/scm\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-release-plugin\u003c/artifactId\u003e \u003cversion\u003e3.0.0-M1\u003c/version\u003e \u003cconfiguration\u003e \u003cautoVersionSubmodules\u003etrue\u003c/autoVersionSubmodules\u003e \u003cgoals\u003edeploy\u003c/goals\u003e \u003cscmCommentPrefix\u003e[jenkins]\u003c/scmCommentPrefix\u003e \u003c/configuration\u003e \u003c/plugin\u003e \n(git) tag # 태그 삭제 $ git tag -d framework-bom-0.2 'framework-bom-0.2' 태그 삭제함 (과거 2c5b9f1) $ git push origin :framework-bom-0.2 To github.com:lislroow/pilot.git - [deleted] framework-bom-0.2 $ # 태그 조회 $ git tag -l framework-* framework-bom-0.1 # 태그 추가 (Lightweight 태그) $ git tag framework-bom-0.2 # 태그 추가 (Annotated 태그) $ git tag -a framework-bom-0.2 -m \"Release framework-bom-0.2\" # 태그 보기 $ git show framework-bom-0.2 # 태그 원격저장소 push (모두 올리기) $ git push origin --tags \n(git) 특정 경로만 checkout 하기 $ git init $ git config core.sparseCheckout true #git config --local credential.helper \"\" $ git remote add -f origin git@github.com:lislroow/pilot.git $ echo \"bom/framework-bom/*\" \u003e .git/info/sparse-checkout $ git pull origin main \n(maven) version ranges artifact 의 scope 가 import 일 경우에는 [0.1,) 형태로 ranges 를 적용할 수 없습니다.\n\u003cdependencyManagement\u003e \u003cdependencies\u003e \u003c!-- mgkim.proto --\u003e \u003cdependency\u003e \u003cgroupId\u003emgkim.proto\u003c/groupId\u003e \u003cartifactId\u003eproto\u003c/artifactId\u003e \u003cversion\u003e[0.1,)\u003c/version\u003e \u003c!-- 오류 --\u003e \u003cversion\u003e0.1\u003c/version\u003e \u003c!-- 정상 --\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c!-- //mgkim.proto --\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \n(eclipse) STS Boot Dashboard filter 새 창 보기\n(eclipse) eclipse-update 이클립스를 업데이트 할 경우(플러그인 업데이트가 아닌), Can not remove ... eclipse.exe 오류가 발생할 수 있습니다.\n이 경우에는 아래 이미지와 같이 업데이트 진행 중에 eclipse.exe 파일을 eclipse.exe.bak 로 변경하면 업데이트가 오류없이 진행됩니다.\n새 창 보기\n(eclipse) scm ignore Preferences \u003e Version Control (Team) \u003e Ignored Resources\n아래 항목들을 추가 합니다.\n*target* *target*/* pom.xml.releaseBackup release.properties 새 창 보기\n(github) ssh key 등록 ssh-keygen -t ed25519 -C \"hi@mgkim.net\"\n생성된 공개키 파일, C:\\Users\\Administrator\\.ssh\\id_ed25519.pub 의 내용을 github 에 등록합니다.\ngithub 메뉴 경로: Settings \u003e SSH and GPG keys\nremote origin 변경\nssh-agent 는 공개키 인증을 위한 개인키를 보관하는 프로그램으로 여러 서버에 인증이 필요할 경우 사용할 수 있습니다.\n등록된 공개키 정상여부 확인을 하기 위해, 키 생성을 한 곳에서 ssh -T git@github.com 명령을 실행을 해봅니다.\n키 파일의 경로를 명시적으로 지정\nssh -v -i /C/Users/Administrator/.ssh/id_ed25519.pub -T git@github.com\nssh -i C:\\Users\\Administrator\\.ssh\\id_ed25519.pub -T git@github.com\nAdministrator@I5-1135G7 MINGW64 / $ ssh -T git@github.com The authenticity of host 'github.com (15.164.81.167)' can't be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'github.com' (ED25519) to the list of known hosts. Hi lislroow! You've successfully authenticated, but GitHub does not provide shell access. github 에 key를 등록한 다음 cli 환경에서 사용하려면 아래 명령을 실행합니다.\n$ eval \"$(ssh-agent -s)\" Agent pid 126681 $ ps -ef | grep ssh-agent root 31343 1 0 12월14 ? 00:00:00 ssh-agent -s jenkins 126681 1 0 17:12 ? 00:00:00 ssh-agent -s jenkins 126683 126640 0 17:12 pts/1 00:00:00 grep --color=auto ssh-agent $ ssh-add ~/.ssh/id_ed25519 Identity added: /home/jenkins/.ssh/id_ed25519 (jenkins@mgkim.net) $ \n(github) unable to read askpass 오류 오류 상황입니다.\n$ git push origin (gnome-ssh-askpass:19816): Gtk-WARNING **: 10:22:08.209: cannot open display: error: unable to read askpass response from '/usr/libexec/openssh/gnome-ssh-askpass' Username for 'https://github.com': SSH_ASKPASS 변수를 unset 하면 됩니다.\n$ echo $SSH_ASKPASS /usr/libexec/openssh/gnome-ssh-askpass $ unset SSH_ASKPASS \n(github) Personal access tokens Settings \u003e Developer settings \u003e Personal access tokens 이동 후\nGenerate new token 버튼 클릭으로 token 생성 (repo 만 체크하면 push 할 수 있음)\ntoken 생성 후 이클립스에서 id에 email 입력, password 에 생성된 토큰 입력\n# token-name: centos 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 \n(eclipse) debugging 필수 옵션 디버깅 시 아래와 같은 오류가 발생할 경우 이클립스 옵션을 확인해보세요.\n  오류 상황\n  경로: Preferences \u003e Java \u003e Debug\n  체크사항: Use advanced source lookup (JRE 1.5 and higher) 체크를 반드시 해제해주셔야 합니다.\n새 창 보기\n  체크 유무에 따라 정상/오류 상황을 캡처한 이미지 입니다.\n새 창 보기\n  (win) win 11 taskbar 그룹해제 아래 파일 다운로드 후 실행\n다운로드\n새 창 보기\n(maven) release 명령어\n$ mvn -B clean release:prepare release:perform deploy $M2_HOME/conf/settings.xml 파일\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003cservers\u003e \u003cserver\u003e \u003cid\u003enexus-release\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003epasswd\u003c/password\u003e \u003c/server\u003e \u003cserver\u003e \u003cid\u003enexus-snapshot\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003epasswd\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003enexus\u003c/name\u003e \u003curl\u003ehttp://nexus/repository/maven-group/\u003c/url\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003c/settings\u003e pom.xml 파일\n\u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-release-plugin\u003c/artifactId\u003e \u003cversion\u003e3.0.0-M1\u003c/version\u003e \u003c!-- 필수 사항 --\u003e \u003cconfiguration\u003e \u003cautoVersionSubmodules\u003etrue\u003c/autoVersionSubmodules\u003e \u003cgoals\u003edeploy\u003c/goals\u003e \u003cusername\u003emgkim\u003c/username\u003e \u003cpassword\u003epasswd\u003c/password\u003e \u003c/configuration\u003e \u003c!-- //필수 사항 --\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c!-- 필수 사항 --\u003e \u003cscm\u003e \u003cconnection\u003escm:svn:svn://develop/test/trunk/proto.www\u003c/connection\u003e \u003c/scm\u003e \u003c!-- //필수 사항 --\u003e \u003cdistributionManagement\u003e \u003csnapshotRepository\u003e \u003cid\u003emgkim-snapshot\u003c/id\u003e \u003curl\u003ehttp://nexus/repository/maven-mgkim-snapshot/\u003c/url\u003e \u003c/snapshotRepository\u003e \u003crepository\u003e \u003cid\u003emgkim-release\u003c/id\u003e \u003curl\u003ehttp://nexus/repository/maven-mgkim-release/\u003c/url\u003e \u003c/repository\u003e \u003c/distributionManagement\u003e \n(maven) help:evaluate 명령어\nSNAPSHOT_NM=$(mvn -f pom.xml help:evaluate -Dexpression=project.version -q -DforceStdout) \n(maven) dependency 명령어: dependency:resolve\njavadoc 다운로드\n$ mvn dependency:resolve -Dclassifier=javadoc 명령어: dependency:sources\nsources 다운로드\n$ mvn dependency:sources \n(maven) deploy:deploy-file 명령어\nset JAVA_HOME=Z:\\develop\\java\\openjdk-11.0.2 set M2_HOME=Z:\\develop\\build\\maven-3.6.3 set PATH=%JAVA_HOME%\\bin;%M2_HOME%\\bin;%PATH% set NEXUS_REPO=-DrepositoryId=nexus-release -Durl=http://nexus/repository/maven-public-hosted/ set GROUP_ID=net.mgkim set ARTIFACT_ID=spring-core set VERSION=1.0.0 set FILE=Z:\\mgkim-spring-core-1.0.0.jar %M2_HOME%\\bin\\mvn.cmd -U deploy:deploy-file -DgroupId=%GROUP_ID% -DartifactId=%ARTIFACT_ID% -Dversion=%VERSION% -Dpackaging=jar -Dfile=%FILE% %NEXUS_REPO% 플러그인\n\u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-deploy-plugin\u003c/artifactId\u003e \u003cversion\u003e3.0.0-M1\u003c/version\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \n2021.12.14 nexus deploy 401 unauthorized\nmvn deploy 에 전달된 인자 -DrepositoryId=nexus-release 이 참조하는 settings.xml 의 \u003cServers\u003e 의 id/passwd 정보가 있어야 합니다.\n새 창 보기\n\u003cservers\u003e \u003cserver\u003e \u003cid\u003enexus-release\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003e***(passwd)***\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e \n2021.12.14 nexacro 라이브러리 추가\n스크립트 보기\n(maven) settings.xml 파일 $M2_HOME/conf/settings.xml\n새 창 보기\n(maven) password 암호화 # 평문 `mypassword` 는 `{ODOdTfm09eMHYfUVt4vkUfm9dw1pkSRC+HAXsuqE0p0=}` 문자열로 암호화됨 $ mvn --encrypt-master-password mypassword {ODOdTfm09eMHYfUVt4vkUfm9dw1pkSRC+HAXsuqE0p0=} \n(java) vmargs (2개) # request.getRemoteAddr() 가 IPv6 로 출력되는 경우 JAVA_OPTS=\"${JAVA_OPTS}-Djava.net.preferIPv4Stack=true\" # cannot be cast to javax.net.ssl.HttpsURLConnection # URLConnection 객체를 사용할 때 HttpsURLConnection 이 반환되지 않는 경우 JAVA_OPTS=\"${JAVA_OPTS}-DUseSunHttpHandler=true\" \n(win) win11 system-tray 설정 cmd 창에서 아래 명령어를 입력하여 시스템 트레이에 모든 아이콘을 표시하도록 합니다.\n시스템 아이콘 켜기 또는 끄기 를 선택하여 시계를 표시할 수도 있습니다.\n\u003e explorer shell:::{05d7b0f4-2121-4eff-bf6b-ed3f69b894d9} 새 창 보기\n(win) font 추천 hugo-site\n/assets/scss/_variables_project.scss\n$google_font_name: \"Bitstream Vera Sans Mono\" !default; $google_font_family: \"Bitstream Vera Sans Mono:300,300i,400,400i,700,700i\" !default; $web-font-path: \"http://fonts.cdnfonts.com/css/bitstream-vera-sans-mono\"; scss 파일의 수정된 내용이 적용되려면 npm 빌드 환경이 필요합니다.\n# 초기 구성을 위해 준비할 것 $ git submodule add -b master https://github.com/lislroow/lislroow.github.io.git public $ git clone --recurse-submodules --depth 1 https://github.com/google/docsy.git themes/docsy # 2개의 npm 패키지 설치 $ npm install autoprefixer -D --save $ npm install postcss-cli -D --save $ npm install postcss -D --save # npm 패키지 설치 후 hugo -t docsy 로 build 하면  # `/assets/scss/_variables_project.scss` 파일에 수정된 내용을 포함하여 # 아래 경로에 build 결과 파일을 생성합니다. # `/resources/_gen/assets/scss/scss/main.scss_4853eb546e7a6c0898ed71feae7357c0.content` system\nBitstream 은 coding 목적으로 많이 사용되는 font 입니다.\n새 창 보기\n다운로드: BitstreamVeraSansMono.ttf\nColors and Fonts \u003e Basic \u003e Text Font 를 선택하고 Edit 버튼을 클릭하면 변경할 수 있습니다.\n새 창 보기\n(eclipse) hidpi 설정 # eclipse.ini 파일의 맨 마지막에 추가 -Dswt.autoScale=150 # 150 == 1.5배 새 창 보기\n(win) 절전 cmd %windir%\\System32\\rundll32.exe powrprof.dll SetSuspendState \n(vmware) 실행 cmd set \"VMWARE_HOME=C:\\Program Files (x86)\\VMware\\VMware Workstation\" set \"PATH=%PATH%;%VMWARE_HOME%\" vmrun -T ws start \"Z:\\centos7-develop\\centos7-develop.vmx\" nogui \n(win) wol 설정 절전 상태에서 wol 이 작동하려면 아래 옵션을 선택해야 합니다.\n새 창 보기\n(win) port-forwarding cmd # 설정 \u003e netsh interface portproxy add v4tov4 listenport=8222 listenaddress=0.0.0.0 connectport=22 connectaddress=172.28.200.20 # 해제 \u003e netsh interface portproxy delete v4tov4 listenport=8222 listenaddress=0.0.0.0 # 확인 \u003e netsh interface portproxy show v4tov4 \n(win) 파일 공유 설정 windows 에서 파일 공유 시 권한이 없다는 메시지가 나오는 경우가 있음\nwindows 계정에 패스워드가 설정되어 있지 않으면 발생하는 사항\n# 비밀번호 설정하기 \u003e net user administrator * centos 에서 windows 공유 디렉토리 mount\n$ mkdir /share $ mount -t cifs //172.28.200.1/share /share -o username=administrator,password=1 $ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 3.8G 0 3.8G 0% /dev tmpfs 3.9G 12K 3.9G 1% /dev/shm tmpfs 3.9G 14M 3.8G 1% /run tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/nvme0n1p9 76G 15G 61G 20% / /dev/nvme0n1p8 3.0G 2.7G 378M 88% /var /dev/nvme0n1p7 5.0G 2.6G 2.4G 53% /home /dev/nvme0n1p2 100G 27G 74G 27% /data /dev/nvme0n1p5 20G 5.0G 16G 25% /app /dev/nvme0n1p3 30G 9.8G 21G 33% /prod /dev/nvme0n1p1 474M 149M 326M 32% /boot tmpfs 781M 0 781M 0% /run/user/0 //172.28.200.1/share 345G 284G 62G 83% /share $ vi /etc/fstab //172.28.200.1/share /share cifs username=administrator,password=1 0 0 \n(vmware) nat 설정 vmware \u003e Edit \u003e Virtual Network Editor\nNAT Settings... \u003e Gateway IP 확인\nSubnet IP: 172.28.200.0, Subnet mask: 255.255.255.0\nvmware 의 guest os는 172.28.200.2~254 로 설정하고, host os(windows) 와 통신은 172.28.200.1 로 합니다.\n(7z) 7z 압축 cmd \u003e \"C:\\Program Files\\7-Zip\\7z.exe\" a -mx7 -mmt Z:\\project.zip \"Z:\\project\" \u003e \"C:\\Program Files\\7-Zip\\7z.exe\" a -mx5 -t7z Z:\\project.zip \"Z:\\project\" -xr!target -xr!node_modules target 디렉토리와 node_modules 디렉토리는 압축 대상에서 제외됩니다.\n(jmeter) jmeter 실행 cmd jmeter 실행 결과 디렉토리에 timestamp 변수 사용하기\n\u003e set ts=%DATE:~0,4%%DATE:~5,2%%DATE:~8,2%_%TIME:~0,2%%TIME:~3,2%%TIME:~6,2% \u003e apache-jmeter-5.4.1\\bin\\jmeter.bat -n -t jmeter-mgkim-core.jmx -l data\\%ts%.csv -e -o data\\%ts% \n(win) xcopy cmd \u003e xcopy C:\\exp\\*.* Z:\\exp\\ /d/i/s/c/y \n(chrome) https 자동 접속 현상   chrome://net-internals/#hsts 로 이동\n  Delete domain security policies 에서 해당 도메인 delete\n  chrome://restart chrome 재시작\n새 창 보기\n  (git) config cmd \u003e git config --global core.autocrlf true \u003e git config --global user.email hi@mgkim.net \u003e git config --global user.name 김명구 \n(git) pre-commit shell git-commit 을 하기 전에 사전 검사를 하기 위한 코드를 bash-shell 로 체크하는 방법입니다.\n# project/.git/hooks/pre-commit #!/bin/sh LIST=$(git diff --cached --name-only --diff-filter=ACRM) for file in $LIST do if [ $file = \".settings/org.eclipse.wst.common.component\" ]; then echo \"이클립스 설정 파일($file)은 commit을 할 수 없습니다.\" exit 1 fi done exit 0 \n(oracle) client 무설치 설정 시스템변수\n새 창 보기\nHKEY_LOCAL_MACHINE\\SOFTWARE\\ORACLE\\KEY_client\n새 창 보기\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\ORACLE\\KEY_client\n새 창 보기\ntnsnames.ora\n새 창 보기\n(oracle) sqlplus C:\\Users\\Administrator\u003esqlplus /nolog SQL*Plus: Release 12.1.0.2.0 Production on 목 9월 2 11:39:53 2021 Copyright (c) 1982, 2014, Oracle. All rights reserved. SQL\u003e conn SPADBA/password@develop:1521/SPADBP 연결되었습니다. SQL\u003e show con_name CON_NAME ------------------------------ CDB$ROOT SQL\u003e set line 150 pages 1000 SQL\u003e col name for a30 SQL\u003e select con_id, dbid, name, open_mode from v$containers order by 1; CON_ID DBID NAME OPEN_MODE ---------- ---------- ------------------------------ ---------- 1 1588065228 CDB$ROOT READ WRITE 2 2599163564 PDB$SEED READ ONLY 3 673775647 SPADBP READ WRITE SQL\u003e alter session set container=SPADBP; 세션이 변경되었습니다. SQL\u003e show con_name CON_NAME ------------------------------ SPADBP SQL\u003e \n(oracle) object 조회 query dictionary 뷰에서부터 object 정보를 확인하고 생성된 상태를 확인할 수 있습니다.\nsqlgate 에 단축키로 등록하고 사용하면 유용할 query 입니다.\n#테이블검색SELECT/* (Alt+1) 테이블 검색 */A.OWNER,A.COMMENTSAST_COMMENT,A.TABLE_NAMEAST_NAME,B.COLUMN_NAMEASC_NAME,B.COMMENTSASC_COMMENT,B1.COLUMN_IDFROMALL_TAB_COMMENTSA,ALL_COL_COMMENTSB,ALL_TAB_COLSB1WHERE1=1ANDA.TABLE_NAMELIKE'%\u0026Var%'ANDA.TABLE_NAME=B.TABLE_NAMEANDB.TABLE_NAME=B1.TABLE_NAMEANDB.COLUMN_NAME=B1.COLUMN_NAMEANDA.OWNER=B.OWNERANDB.OWNER=B1.OWNER(+)ANDA.OWNERIN('SPADBA')ORDERBYA.OWNERDESC,B1.COLUMN_ID,A.COMMENTS;#컬럼검색SELECT/* (Alt+2) 컬럼 검색 */A.OWNER,A.COMMENTSAST_COMMENT,A.TABLE_NAMEAST_NAME,B.COLUMN_NAMEASC_NAME,B.COMMENTSASC_COMMENT,B1.COLUMN_IDFROMALL_TAB_COMMENTSA,ALL_COL_COMMENTSB,ALL_TAB_COLSB1,ALL_CONS_COLUMNSCWHERE1=1AND(B.COLUMN_NAMELIKE'%\u0026Var%'ORB.COMMENTSLIKE'%\u0026Var%')ANDA.TABLE_NAME=B.TABLE_NAMEANDB.TABLE_NAME=C.TABLE_NAME(+)ANDB.TABLE_NAME=B1.TABLE_NAMEANDB.COLUMN_NAME=B1.COLUMN_NAMEANDA.OWNER=B.OWNERANDB.OWNER=B1.OWNER(+)ANDB.OWNER=C.OWNERANDB.COLUMN_NAME=C.COLUMN_NAME(+)ANDC.CONSTRAINT_NAME(+)LIKE'%PK'ANDA.OWNERIN('SPADBA')AND(A.TABLE_NAMELIKE'E%'ORA.TABLE_NAMELIKE'CB%')ORDERBYA.OWNERDESC,A.COMMENTS,B1.COLUMN_ID,C.POSITION;#테이블조회SELECT/* (Alt+3) 테이블 조회 */*FROM\u0026VarWHEREROWNUM\u003c200;#dict검색SELECT/* (Alt+4) DICT 검색 */*FROMDICTWHERETABLE_NAMELIKE'%'||'\u0026Var'||'%'ORDERBYTABLE_NAME;\n","categories":"","description":"","excerpt":"(java) keytool 인증서 생성 java 에 포함되어 있는 keytool 명령으로 아래 절차로 인증서를 생성합니다.\n생 …","ref":"/localenv/","tags":"","title":"localenv"},{"body":"패키지 확인 [root@develop ~]$ yum list *openssh* Loaded plugins: fastestmirror, langpacks Repodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast Loading mirror speeds from cached hostfile * base: mirror.kakao.com * epel: ftp.yz.yamagata-u.ac.jp * extras: mirror.kakao.com * updates: mirror.kakao.com Installed Packages openssh.x86_64 7.4p1-21.el7 @anaconda [root@develop ~]$ [root@develop ~]$ rpm -ql openssh.x86_64 /etc/ssh /etc/ssh/moduli /usr/bin/ssh-keygen [root@develop ~]$ key 생성 ssh-keygen 인자 -t rsa 는 rsa 타입으로 생성 입니다. key 생성 경로는 home 디렉토리의 .ssh 디렉토리에 생성이 됩니다. passphrase 는 key 의 비밀번호 입니다.\nkey 생성이 되면 .ssh 디렉토리에는 id_rsa(개인키), id_rsa.pub(공개키) 2개의 파일이 있습니다.\n공개키인 id_rsa.pub 파일의 내용은 SSH로 접속하려는 대상 서버의 시스템계정 홈디렉토리의 .ssh/authorized_keys 파일에 추가하여 사용됩니다.\n[tomcat@develop ~]$ pwd /home/tomcat [tomcat@develop ~]$ ls -al 합계 28 drwx------. 4 tomcat ap 140 9월 13 11:41 . drwxr-xr-x. 7 root root 74 11월 22 2020 .. -rw-------. 1 tomcat ap 1357 9월 13 11:41 .bash_history -rw-r--r--. 1 tomcat ap 18 4월 1 2020 .bash_logout -rw-r--r--. 1 tomcat ap 616 12월 24 2020 .bash_profile -rw-r--r--. 1 tomcat ap 231 4월 1 2020 .bashrc drwxr-xr-x. 3 tomcat ap 18 12월 24 2020 .cache drwxr-xr-x. 3 tomcat ap 18 12월 24 2020 .config -rw------- 1 tomcat ap 1024 9월 13 11:39 .rnd -rw------- 1 tomcat ap 5762 9월 13 11:39 .viminfo [tomcat@develop ~]$ ssh-keygen --help unknown option -- - usage: ssh-keygen [-q] [-b bits] [-t dsa | ecdsa | ed25519 | rsa | rsa1] [-N new_passphrase] [-C comment] [-f output_keyfile] ssh-keygen -p [-P old_passphrase] [-N new_passphrase] [-f keyfile] ssh-keygen -i [-m key_format] [-f input_keyfile] ssh-keygen -e [-m key_format] [-f input_keyfile] ssh-keygen -y [-f input_keyfile] ssh-keygen -c [-P passphrase] [-C comment] [-f keyfile] ssh-keygen -l [-v] [-E fingerprint_hash] [-f input_keyfile] ssh-keygen -B [-f input_keyfile] ssh-keygen -D pkcs11 ssh-keygen -F hostname [-f known_hosts_file] [-l] ssh-keygen -H [-f known_hosts_file] ssh-keygen -R hostname [-f known_hosts_file] ssh-keygen -r hostname [-f input_keyfile] [-g] ssh-keygen -G output_file [-v] [-b bits] [-M memory] [-S start_point] ssh-keygen -T output_file -f input_file [-v] [-a rounds] [-J num_lines] [-j start_line] [-K checkpt] [-W generator] ssh-keygen -s ca_key -I certificate_identity [-h] [-n principals] [-O option] [-V validity_interval] [-z serial_number] file ... ssh-keygen -L [-f input_keyfile] ssh-keygen -A ssh-keygen -k -f krl_file [-u] [-s ca_public] [-z version_number] file ... ssh-keygen -Q -f krl_file file ... [tomcat@develop ~]$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/tomcat/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/tomcat/.ssh/id_rsa. Your public key has been saved in /home/tomcat/.ssh/id_rsa.pub. The key fingerprint is: SHA256:Lp68Qh20r1rnsr+IyTTayVl/pbd8VlEL3mWGuez3IYY tomcat@develop The key's randomart image is: +---[RSA 2048]----+ | o | | . .o =| | . . ..o++| | o .o+ | | . oS .. .| | . ... E.o..o| | .o +.o o. .oo| | *.@oB o.. o .| | . XoB==o .o+ | +----[SHA256]-----+ [tomcat@develop ~]$ [tomcat@develop ~]$ ls -al /home/tomcat/.ssh 합계 8 drwx------ 2 tomcat ap 38 9월 13 11:51 . drwx------. 5 tomcat ap 152 9월 13 11:48 .. -rw------- 1 tomcat ap 1766 9월 13 11:51 id_rsa -rw-r--r-- 1 tomcat ap 396 9월 13 11:51 id_rsa.pub [tomcat@develop ~]$ ","categories":"","description":"","excerpt":"패키지 확인 [root@develop ~]$ yum list *openssh* Loaded plugins: …","ref":"/system/openssh/","tags":"","title":"openssh"},{"body":"sysctl 설정 파일: /etc/sysctl.conf\nfs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 kernel.shmmax = 4056393728 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048586 반영: sysctl -p\n확인: sysctl -a\nlimits 설정 /etc/security/limits.conf\noracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 \n시스템 계정 groupadd oinstall groupadd dba useradd -g oinstall -G dba oracle \n설치 디렉토리 mkdir -p /prod/oracle12/app mkdir -p /prod/oracle12/oraInventory chown -R oracle:oinstall /prod/oracle12/app chown -R oracle:oinstall /prod/oracle12/oraInventory chmod -R 775 /prod/oracle12/app chmod -R 775 /prod/oracle12/oraInventory chmod g+s /prod/oracle12/app chmod g+s /prod/oracle12/oraInventory \n시스템 변수 export TMPDIR=$TMP export ORACLE_BASE=/prod/oracle12/app/ export ORACLE_HOME=$ORACLE_BASE/product/12.2.0/dbhome_1 export ORACLE_HOME_LISTNER=$ORACLE_HOME/bin/lsnrctl export ORACLE_SID=orcl export LD_LIBRARY_PATH=/lib:/usr/lib:/usr/lib64:$ORACLE_HOME/lib export CLASSPATH=$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib export PATH=$ORACLE_HOME/bin:$PATH:$HOME/.local/bin:$HOME/bin \ngui 패키지 설치 $ yum grouplist 사용 가능한 환경 그룹 : 서버 - GUI 사용 최소 설치 워크스테이션 가상화 호스트 사용자 정의 운영 체제 $ yum groupinstall \"서버 - GUI 사용\" 설치 후 runlevel 변경: $ systemctl set-default graphical.target\noracle12c-ee 설치 gui 환경으로 booting 후 oracle 계정으로 로그인하고 runInstaller 실행\n설치 파일: oracle-ee_12102_linux_x64_1of2.zip, oracle-ee_12102_linux_x64_2of2.zip\ninstall response rpm runInstaller sshsetup stage welcome.html \nsystemctl 등록 systemctl 환경변수 파일: /etc/sysconfig/ora12c.env\n소유자(oracle) 설정: chown oracle:db /etc/sysconfig/ora12c.env\nORACLE_BASE=/prod/oracle12/app ORACLE_HOME=$ORACLE_BASE/product/12.2.0/dbhome_1 ORACLE_SID=ora12c \n각종 오류   ORA-01102: cannot mount database in EXCLUSIVE mode\ncat $ORACLE_BASE/admin/ora12c/pfile/init.ora.1028202115570 cp $ORACLE_BASE/admin/ora12c/pfile/init.ora.1028202115570 $ORACLE_HOME/dbs/initora12c.ora   ORA-01033: ORACLE initialization or shutdown in progress\nalterpluggabledatabasepdborclopenreadwrite;  systemctl service 파일 생성\nservice 파일에는 환경변수 파일을 적용할 것\nora12c@lsnrctl.service, ora12c@dbms.service\noratab 파일 파일: /etc/oratab\nora12c:/prod/oracle12/app/product/12.2.0/dbhome_1:Y 소유자(oracle) 설정: chown oracle:db /etc/oratab\nmax_string_size = EXTENDED startupmount;alterdatabaseopenmigrate;selectcon_id,name,open_modefromv$pdbs;altersessionsetcontainer=PDB$SEED;altersystemsetmax_string_size=extendedscope=spfile;@?/rdbms/admin/utl32k.sql;altersessionsetcontainer=SPADBP;alterpluggabledatabaseSPADBPopenupgrade;altersystemsetmax_string_size=extendedscope=spfile;@?/rdbms/admin/utl32k.sql;@?/rdbms/admin/utlrp.sql;alterpluggabledatabaseSPADBPcloseimmediate;\nPDB 자동 시작 selectcon_id,name,open_modefromv$pdbs;CREATEORREPLACETRIGGERopen_pdbsAFTERSTARTUPONDATABASEBEGINEXECUTEIMMEDIATE'ALTER PLUGGABLE DATABASE ALL OPEN';ENDopen_pdbs;/commit;\noracle 계정 생성 altersessionset\"_oracle_script\"=true;CREATETABLESPACETS_DATA01DATAFILE'/data/DB/oradata/ora12c/SPADBP/TS_DATA01.dbf'SIZE1GAUTOEXTENDONNEXT10M;CREATEUSERSPADBAIDENTIFIEDBY1DEFAULTTABLESPACETS_DATA01;CREATEUSERSPAAPPIDENTIFIEDBYSPAAPP1234DEFAULTTABLESPACETS_DATA01;ALTERUSERSPADBAQUOTAUNLIMITEDONTS_DATA01;GRANTCONNECT,RESOURCE,CREATEVIEW,EXP_FULL_DATABASE,IMP_FULL_DATABASE,DBATOSPADBA;CREATEROLERL_SPA_APP;GRANTCONNECT,RESOURCETORL_SPA_APP;GRANTRL_SPA_APPTOSPAAPP;\noracle imp/exp exp.exe SPADBA/1@SPADBP FILE='Z:\\SPADBP.dmp' GRANTS=Y INDEXES=Y ROWS=Y CONSTRAINTS=Y TRIGGERS=N COMPRESS=Y DIRECT=N CONSISTENT=N OWNER=(SPADBA) imp.exe SPADBA/1@SPADBP FILE='Z:\\SPADBP.dmp' FEEDBACK=1000 GRANTS=Y INDEXES=Y ROWS=Y CONSTRAINTS=Y IGNORE=N SHOW=N DESTROY=N ANALYZE=Y SKIP_UNUSABLE_INDEXES=N RECALCULATE_STATISTICS=N FROMUSER=SPADBA TOUSER=SPADBA \ndrop table 문 select'drop table '||table_name||' cascade constraints;'fromuser_tables;oracle character-set 설정 select*fromnls_database_parameterswhereparameterlike'%NLS_CHARACTERSET%';/** NLS_CHARACTERSET WE8MSWIN1252 **//** NLS_CHARACTERSET AL32UTF8 */SHUTDOWNIMMEDIATE;STARTUPMOUNT;ALTERSYSTEMENABLERESTRICTEDSESSION;ALTERSYSTEMSETJOB_QUEUE_PROCESSES=0;ALTERSYSTEMSETAQ_TM_PROCESSES=0;ALTERDATABASEOPEN;ALTERDATABASECHARACTERSETINTERNAL_USEAL32UTF8;SHUTDOWNIMMEDIATE;STARTUP;\n","categories":"","description":"","excerpt":"sysctl 설정 파일: /etc/sysctl.conf\nfs.aio-max-nr = 1048576 fs.file-max = …","ref":"/system/oracle12c/","tags":"","title":"oracle12c"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"(systemctl) Requires 속성 logstash 서비스를 elasticsearch 서비스의 종속으로 구성해야할 필요가 생겼습니다.\n$ vi /etc/systemd/system/logstash.service [Unit] Description=logstash Requires=elasticsearch.service # 종속성 확인 $ systemctl list-dependencies logstash.service logstash.service ● ├─-.mount ● ├─elasticsearch.service ● ├─system.slice ● └─sysinit.target ● ├─dev-hugepages.mount ● ├─dev-mqueue.mount \n(cockpit) grafana, grafana-pcp $ yum install grafana grafana-pcp $ systemctl enable --now grafana-server http://host:3000/ 으로 접속\n최초 로그인: 새 창 열림\n포트 변경은 /etc/grafana/grafana.ini 파일에서 http_port = 3000 를 변경하면 됩니다.\n서비스 재시작: systemctl restart grafana-server\n가상호스트 설정: 새 창 보기\n로그인 후 설정\n 좌측 메뉴 Configuration \u003e Plugin 선택 Performance Co-Pilot 플러그인을 활성화 (enable 버튼 클릭) cockpit-pcp에서 redis 설치 후 grafana에서 Configuration \u003e Data Sources 선택 (grafana는 cockpit-pcp 의 메트릭 정보를 redis 를 통해 가져옵니다. redis 설치는 cockpit 에서 버튼 클릭 한번으로 끝남) HTTP의 URL 항목만 http://127.0.0.1:44322 으로 입력 후 Save \u0026 Test 버튼 클릭  대시보드: 새 창 보기\n(cockpit) cockpit-pcp 설치 시스템모니터링 기능이며 cockpit-pcp를 설치하여 메트릭 정보를 볼 수 있습니다.\n새 창 보기\n$ yum install cockpit-pcp $ systemctl enable pmlogger.service $ systemctl enable pmproxy.service $ systemctl daemon-reload $ systemctl start pmlogger.service $ systemctl start pmproxy.service pmproxy.service 활성화를 통해 여러 머신의 메트릭 정보를 볼 수도 있습니다. (redis 설치됨)\n참고: 새 창 보기\n(dnf-makecache) 오류 dnf-makecache는 centos의 자동업데이트 기능입니다.\n오류: repo 'appstream': Cannot prepare internal mirrorlist: No URLs in mirrorlist 를 위해 메타데이타 내려받기에 실패하였습니다\n새 창 보기\ndisable 명령어는 다음과 같습니다.\n$ gsettings set org.gnome.software download-updates false $ systemctl disable dnf-makecache.service $ systemctl disable dnf-makecache.timer 정상 작동하도록 하기 위해 yum 저장소 설정 파일을 수정합니다.\n새 창 보기\n$ sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-Linux-* $ sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-Linux-* # yum upgrade 테스트 참고: dnf 저장소 관리 새 창 보기\n(ELK) elasticsearch 패스워드 설정 elasticsearch와 kibana에 id/pw 방식의 보안을 적용하기 위해 elasticsearch 에 패스워드를 설정합니다.\nelasticsearch 에 패스워드를 설정하는 명령어는 elasticsearch-setup-passwords interactive 입니다.\n오류 내용이 ERROR: X-Pack Security is disabled by configuration 으로 나올 경우 설정파일elasticsearch.yml이 기본으로 되어있을 경우 발생합니다.\n$ /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive Unexpected response code [500] from calling GET http://172.28.200.30:8200/_security/_authenticate?pretty It doesn't look like the X-Pack security feature is enabled on this Elasticsearch node. Please check if you have enabled X-Pack security in your elasticsearch.yml configuration file. ERROR: X-Pack Security is disabled by configuration. $ 설정파일elasticsearch.yml에서 아래와 같이 옵션을 추가합니다.\n참고 링크: 새 창 보기\n102 103 # 2022.01.27 104 xpack.security.enabled: true 설정 추가 후 systemctl restart elasticsearch 재시작을하면 xpack.security.transport.ssl.enabled 을 추가하라는 메시지가 나옵니다.\n-- Unit elasticsearch.service has begun starting up. 1월 27 18:25:13 centos8 systemd-entrypoint[11169]: ERROR: [1] bootstrap checks failed. You must address the points described in the following [1] lines before starting Elasticsearch. 1월 27 18:25:13 centos8 systemd-entrypoint[11169]: bootstrap check failure [1] of [1]: Transport SSL must be enabled if security is enabled on a [basic] license. Please set [xpack.security.transport.ssl.enabled] to [true] or disa\u003e 1월 27 18:25:13 centos8 systemd-entrypoint[11169]: ERROR: Elasticsearch did not exit normally - check the logs at /outlog/PROD/es/elasticsearch.log 변경 후 재시작을 합니다.\n103 # 2022.01.27 104 xpack.security.enabled: true 105 xpack.security.transport.ssl.enabled: true elasticsearch-setup-passwords interactive 명령으로 패스워드를 설정합니다.\n$ /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: passwords must be at least [6] characters long Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana_system]: Reenter password for [kibana_system]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] $ elasticsearch 의 security 적용으로 인해 kibana 의 설정을 확인해야합니다.\n설정파일/etc/kibana/kibana.yml에 아래 내용을 추가하고 kibana를 재시작(systemctl restart kibana)합니다.\n50 #elasticsearch.username: \"kibana_system\" 51 #elasticsearch.password: \"pass\" 52 elasticsearch.username: \"elastic\" 53 elasticsearch.password: \"패스워드\" 브라우저로 kibana 에 접속하면 id/pw 를 요구합니다.\n새 창 보기\nkibana 설정파일/etc/kibana/kibana.yml에 elasticsearch.password 값이 평문이 아닌 encryption 문자열로 설정하겠습니다.\n kibana-keystore 명령어로 key 저장소 생성 생성된 key 저장소에 elasticsearch.password 추가  # kibana-keystore 의 경로를 확인합니다. $ rpm -ql kibana | grep '/bin/kibana' /usr/share/kibana/bin/kibana /usr/share/kibana/bin/kibana-encryption-keys /usr/share/kibana/bin/kibana-keystore /usr/share/kibana/bin/kibana-plugin $ # key 저장소를 생성합니다. $ /usr/share/kibana/bin/kibana create A Kibana keystore already exists. Overwrite? [y/N] N Exiting without modifying keystore. $ # 이미 key 저장소가 있다고하여 저장소를 확인해보려 했지만 찾을 수 없었습니다. # 어딘가에 key 저장소가 있다고 생각하고 add 를 합니다. $ $ ./kibana-keystore add elasticsearch.password Enter value for elasticsearch.password: ********* # 저장된 key 를 확인합니다. $ ./kibana-keystore list elasticsearch.password # kibana.yml 설정파일에 \"elasticsearch.password\" 항목을 주석처리 합니다. # kibana 에서 관리하는 key 저장소에 등록된 값으로 사용될 것입니다. $ vi /etc/kibana/kibana.yml #elasticsearch.password=패스워드 kibana-keystore 에 정상적으로 등록되지 않았다면 아래와 같은 로그를 만나게 됩니다.\n아래 오류를 보기위해 테스트를 하려면,\n$ ./kibana-keystore list elasticsearch.password $ ./kibana-keystore remove elasticsearch.password $ ./kibana-keystore list $ systemctl restart kibana $ tail -f /outlog/PROD/kibana/kibana.log # 서비스 오류 로그: key 를 찾을 수 없을 경우 {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:40:02+09:00\",\"tags\":[\"warning\",\"plugins\",\"alerting\"],\"pid\":14494,\"message\":\"APIs are disabled because the Encrypted Saved Objects plugin is missing encryption key. Please set xpack.encryptedSavedObjects.encryptionKey in the kibana.yml or use the bin/kibana-encryption-keys command.\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:40:02+09:00\",\"tags\":[\"info\",\"plugins\",\"ruleRegistry\"],\"pid\":14494,\"message\":\"Installing common resources shared between all indices\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:40:02+09:00\",\"tags\":[\"warning\",\"plugins\",\"reporting\",\"config\"],\"pid\":14494,\"message\":\"Chromium sandbox provides an additional layer of protection, but is not supported for Linux CentOS 8.5.2111\\n OS. Automatically setting 'xpack.reporting.capture.browser.chromium.disableSandbox: true'.\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:40:02+09:00\",\"tags\":[\"warning\",\"process\"],\"pid\":14494,\"message\":\"Error [ProductNotSupportedSecurityError]: The client is unable to verify that the server is Elasticsearch due to security privileges on the server side. Some functionality may not be compatible if the server is running an unsupported product.\\n at /usr/share/kibana/node_modules/@elastic/elasticsearch/lib/Transport.js:576:19\\n at onBody (/usr/share/kibana/node_modules/@elastic/elasticsearch/lib/Transport.js:369:9)\\n at IncomingMessage.onEnd (/usr/share/kibana/node_modules/@elastic/elasticsearch/lib/Transport.js:291:11)\\n at IncomingMessage.emit (node:events:402:35)\\n at endReadableNT (node:internal/streams/readable:1343:12)\\n at processTicksAndRejections (node:internal/process/task_queues:83:21)\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:40:03+09:00\",\"tags\":[\"error\",\"elasticsearch-service\"],\"pid\":14494,\"message\":\"Unable to retrieve version information from Elasticsearch nodes. security_exception: [security_exception] Reason: missing authentication credentials for REST request [/_nodes?filter_path=nodes.*.version%2Cnodes.*.http.publish_address%2Cnodes.*.ip]\"} # 서비스 정상 로그 {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:51:17+09:00\",\"tags\":[\"warning\",\"plugins\",\"reporting\",\"chromium\"],\"pid\":14712,\"message\":\"Enabling the Chromium sandbox provides an additional layer of protection.\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:51:19+09:00\",\"tags\":[\"info\",\"plugins\",\"securitySolution\",\"endpoint:metadata-check-transforms-task:0\",\"0\",\"1\"],\"pid\":14712,\"message\":\"no endpoint metadata transforms found\"} {\"type\":\"log\",\"@timestamp\":\"2022-01-27T20:51:26+09:00\",\"tags\":[\"info\",\"status\"],\"pid\":14712,\"message\":\"Kibana is now available (was degraded)\"} \n(centos) 디스크 size 확장 lsblk 명령으로 디스크 size 를 확인합니다.\n(디스크 sda 가 70G 로 되어있습니다.)\n$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 70G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 69G 0 part ├─cl_centos8-root 253:0 0 56.7G 0 lvm / ├─cl_centos8-swap 253:1 0 7G 0 lvm [SWAP] └─cl_centos8-home 253:2 0 5.3G 0 lvm /home sr0 11:0 1 1024M 0 rom $ guest-os 를 shutdown 하고, vmware 에서 디스크 capacity 를 확장합니다.\n(디스크 sda 를 80G 확장합니다.)\nguest-os 를 startup 하고 lsblk 로 확장된 크기를 확인합니다.\n(디스크 sda 가 80G 로 확장된 것을 확인할 수 있습니다.)\n$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 80G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 69G 0 part ├─cl_centos8-root 253:0 0 56.7G 0 lvm / ├─cl_centos8-swap 253:1 0 7G 0 lvm [SWAP] └─cl_centos8-home 253:2 0 5.3G 0 lvm /home sr0 11:0 1 1024M 0 rom $ sda2 를 69G 에서 79G 로 확장합니다. 확장에 사용될 명령어는 growpart 입니다.\n패키지가 설치되어 있지 않으면 yum 으로 설치를 합니다.\n$ yum install cloud-utils-growpart $ which growpart /usr/bin/growpart growpart 명령으로 피지컬 파티션sda2의 size를 확장합니다.\n확장 전에 피지컬 파티션을 상태를 확인합니다.\n$ vgdisplay --- Volume group --- VG Name cl_centos8 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 3 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c69.00 GiB PE Size 4.00 MiB Total PE 17663 Alloc PE / Size 17663 / \u003c69.00 GiB Free PE / Size 0 / 0 VG UUID tJ9xgp-NhNP-7kPQ-JwKe-y1TQ-8jkP-1U5ox4 $ growpart 명령으로 size 를 확장합니다.\n확장 후 lsblk, vgdisplay 로 변경된 사항을 확인합니다.\n(lsblk 에서 sda2 의 size가 +10G 된 것을 볼 수 있습니다.)\n$ growpart /dev/sda 2 CHANGED: partition=2 start=2099200 old: size=144701440 end=146800640 new: size=165672927 end=167772127 $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 80G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 79G 0 part ├─cl_centos8-root 253:0 0 56.7G 0 lvm / ├─cl_centos8-swap 253:1 0 7G 0 lvm [SWAP] └─cl_centos8-home 253:2 0 5.3G 0 lvm /home sr0 11:0 1 1024M 0 rom $ 피지컬 파티션sda2 에 추가된 용량을 할당해야 합니다. (명령어 pvresize /dev/sda2)\n할당 후 vgdisplay 에서 Free PE / Size 에서 변경된 것을 확인할 수 있습니다.\n(Free PE / Size 0 / 0  \u003e Free PE / Size 2560 / 10.00 GiB)\n$ vgdisplay --- Volume group --- VG Name cl_centos8 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 3 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c69.00 GiB PE Size 4.00 MiB Total PE 17663 Alloc PE / Size 17663 / \u003c69.00 GiB Free PE / Size 0 / 0 VG UUID tJ9xgp-NhNP-7kPQ-JwKe-y1TQ-8jkP-1U5ox4 $ pvresize /dev/sda2 Physical volume \"/dev/sda2\" changed 1 physical volume(s) resized or updated / 0 physical volume(s) not resized $ $ vgdisplay --- Volume group --- VG Name cl_centos8 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 5 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 3 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c79.00 GiB PE Size 4.00 MiB Total PE 20223 Alloc PE / Size 17663 / \u003c69.00 GiB Free PE / Size 2560 / 10.00 GiB VG UUID tJ9xgp-NhNP-7kPQ-JwKe-y1TQ-8jkP-1U5ox4 $ \u003cbr\u003e 로지컬 파티션cl_centos8-root을 확장해야 합니다.\n로지컬 파티션을 확인부터 합니다. (명령어 lvdisplay 혹은 df로 확인할 수 있습니다.)\n(확장할 로지컬 파티션은 /dev/cl_centos8/root 입니다.)\n$ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 3.8G 0 3.8G 0% /dev tmpfs 3.8G 0 3.8G 0% /dev/shm tmpfs 3.8G 9.5M 3.8G 1% /run tmpfs 3.8G 0 3.8G 0% /sys/fs/cgroup /dev/mapper/cl_centos8-root 57G 43G 15G 75% / /dev/sda1 1014M 378M 637M 38% /boot /dev/mapper/cl_centos8-home 5.4G 372M 5.0G 7% /home //172.28.200.1/share 345G 234G 112G 68% /share tmpfs 775M 0 775M 0% /run/user/0 $ $ lvdisplay --- Logical volume --- LV Path /dev/cl_centos8/root LV Name root VG Name cl_centos8 LV UUID DzRXf6-roJe-0He9-MBow-ccu0-bWjk-qPxfZS LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:35 +0900 LV Status available # open 1 LV Size \u003c56.66 GiB Current LE 14504 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 --- Logical volume --- LV Path /dev/cl_centos8/home LV Name home VG Name cl_centos8 LV UUID 9dT8j9-MTd1-dlO2-ceHH-vnpS-KtGJ-je2ReA LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:35 +0900 LV Status available # open 1 LV Size \u003c5.34 GiB Current LE 1367 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 --- Logical volume --- LV Path /dev/cl_centos8/swap LV Name swap VG Name cl_centos8 LV UUID VSq1ve-Dn73-RLjq-q2GP-wa0r-De07-CO7edF LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:36 +0900 LV Status available # open 2 LV Size 7.00 GiB Current LE 1792 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:1 $ 로지컬 파티션의 size 확장 명령어 lvextend 를 사용하여 확장합니다.\n로지컬 파티션명은 lvdisplay 에 표시되는 /dev/cl_centos8/root를 사용해도되고, df 에 표시되는 /dev/mapper/cl_centos8-root를 사용해도 됩니다.\n(df 에서 /dev/mapper/cl_centos8-root 의 size 가 +10G 된 것을 확인할 수 있고, lvdisplay에서도 LV Size \u003c56.66 GiB \u003e LV Size \u003c66.66 GiB 로 변경된 것을 확인할 수 있습니다.)\n$ lvextend -r -l +100%FREE /dev/cl_centos8/root Size of logical volume cl_centos8/root changed from \u003c56.66 GiB (14504 extents) to \u003c66.66 GiB (17064 extents). Logical volume cl_centos8/root successfully resized. meta-data=/dev/mapper/cl_centos8-root isize=512 agcount=4, agsize=3713024 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=14852096, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=7252, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 14852096 to 17473536 $ $ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 3.8G 0 3.8G 0% /dev tmpfs 3.8G 0 3.8G 0% /dev/shm tmpfs 3.8G 9.5M 3.8G 1% /run tmpfs 3.8G 0 3.8G 0% /sys/fs/cgroup /dev/mapper/cl_centos8-root 67G 43G 25G 64% / /dev/sda1 1014M 378M 637M 38% /boot /dev/mapper/cl_centos8-home 5.4G 372M 5.0G 7% /home //172.28.200.1/share 345G 234G 112G 68% /share tmpfs 775M 0 775M 0% /run/user/0 $ $ lvdisplay --- Logical volume --- LV Path /dev/cl_centos8/root LV Name root VG Name cl_centos8 LV UUID DzRXf6-roJe-0He9-MBow-ccu0-bWjk-qPxfZS LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:35 +0900 LV Status available # open 1 LV Size \u003c66.66 GiB Current LE 17064 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 --- Logical volume --- LV Path /dev/cl_centos8/home LV Name home VG Name cl_centos8 LV UUID 9dT8j9-MTd1-dlO2-ceHH-vnpS-KtGJ-je2ReA LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:35 +0900 LV Status available # open 1 LV Size \u003c5.34 GiB Current LE 1367 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 --- Logical volume --- LV Path /dev/cl_centos8/swap LV Name swap VG Name cl_centos8 LV UUID VSq1ve-Dn73-RLjq-q2GP-wa0r-De07-CO7edF LV Write Access read/write LV Creation host, time centos8, 2021-11-28 12:38:36 +0900 LV Status available # open 2 LV Size 7.00 GiB Current LE 1792 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:1 $ \n(jenkins) Role-based Authorization Strategy 플러그인 플러그인 설치 후 Jenkins 관리 \u003e Configure Global Security 메뉴로 이동합니다.\nAuthorization 영역에 Role-Based Strategy 를 체크합니다.\n새 창 보기\nJenkins 관리 \u003e Manage and Assign Roles 에서 세부 설정을 합니다.\n새 창 보기\n(jenkins) AnsiColor 플러그인 플러그인 설치 후 개별 job 의 구성에서 빌드 환경에 Color ANSI Console Output 을 선택하면 됩니다.\n플러그인 설명은 Adds ANSI coloring to the Console Output 입니다.\n새 창 보기\n(ansible) [TODO] 내용 확인 후 세부 작성\nansible 설치 로그 새 창 보기\n(nexus) cleanup / compact blob nexus 저장소에 오래된 snapshot 이 많아져서 공간이 부족해지면 아래 2가지 작업을 등록합니다.\ncleanup policy 및 cleanup task 만 등록할 경우 실제 blob 파일은 삭제되지 않기에 compact blob task 까지 등록해야 합니다.\ntask 등록이 된 다음에는 해당 task 에서 Run 버튼을 클릭하여 실행하고 du 명령어로 공간이 확보된 것을 확인할 수 있을 것입니다.\n  Repository \u003e Cleanup Policies 메뉴에서 정책 등록\ncleanup policy 등록: 새 창 보기\n  System \u003e Task 메뉴에서 작업 등록\ncleanup task 등록: 새 창 보기\ncompact blob task 등록: 새 창 보기\n  (shell) script arguments iterator argc=$# argv=(\"$@\") echo \"argc=${argc}\" echo \"argv=${argv[*]}\" for ((i=0; i\u003cargc; i++)); do echo \"argv[$i]=${argv[$i]}\" done $ ./test.sh a b 'c d' 3 ### [start] test.sh a b c d 3 ### +++ (system-env) +++ SCRIPT_DIR=/z/project/pilot/service argc=4 argv=a b c d 3 argv[0]=a argv[1]=b argv[2]=c d argv[3]=3 \n(shell) script 정보 bash 에서 script 파일을 실행할 때 기본 정보를 출력했습니다.\n#!/bin/bash  echo echo \"# arguments called with ----\u003e ${@}\" echo \"# \\$1 ----------------------\u003e $1\" echo \"# \\$2 ----------------------\u003e $2\" echo \"# path to me ---------------\u003e ${0}\" echo \"# parent path --------------\u003e ${0%/*}\" echo \"# my name ------------------\u003e ${0##*/}\" echo exit $ /z/project/pilot/service/service-www/a.sh 1 2 4 # arguments called with ----\u003e 1 2 4 # $1 ----------------------\u003e 1 # $2 ----------------------\u003e 2 # path to me ---------------\u003e /z/project/pilot/service/service-www/a.sh # parent path --------------\u003e /z/project/pilot/service/service-www # my name ------------------\u003e a.sh \n(libxml2) xmllint xmllint 를 이용하여 nexus 의 maven-metadata.xml 을 파싱하는 예시입니다.\n$ XML_URL=\"https://nexus/repository/maven-snapshot/mgkim/framework/framework-online/maven-metadata.xml\" $ curl -s ${XML_URL} | cat - \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cmetadata\u003e \u003cgroupId\u003emgkim.framework\u003c/groupId\u003e \u003cartifactId\u003eframework-online\u003c/artifactId\u003e \u003cversioning\u003e \u003cversions\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cversion\u003e2.0-SNAPSHOT\u003c/version\u003e \u003c/versions\u003e \u003clastUpdated\u003e20220110062815\u003c/lastUpdated\u003e \u003c/versioning\u003e \u003c/metadata\u003e # --xpath 에 존재하지 않는 node 명을 입력했을 경우 'XPath set is empty' 가 표시됨 $ echo $(curl -s ${XML_URL} | xmllint --xpath \"//aaa/text()\" -) XPath set is empty # node명 \"\u003cgroupId\u003e\" 의 값을 가져오는 2가지 예시 $ echo $(curl -s ${XML_URL} | xmllint --xpath \"metadata/groupId/text()\" -) mgkim.framework $ echo $(curl -s ${XML_URL} | xmllint --xpath \"//groupId/text()\" -) mgkim.framework # node명 \"\u003cversion\u003e\" 이 여러개일 경우 마지막만 반환하는 예시 $ echo $(curl -s ${XML_URL} | xmllint --xpath \"//version[last()]/text()\" -) 2.0-SNAPSHOT # curl 의 결과를 xmllint 에 전달하기 위해  # xmllint 의 마지막에 dash`-` 문자가 반드시 포함되어야 함 --xpath 는 쌍따옴표\"로 해주세요. ('일 경우 변수를 포함한 값으로 표현이 안됩니다.)\n아래는 여러 node 가 select 되는 예시에서 index 변수로 접근하는 예시입니다.\n$ XML_URL=\"https://nexus/repository/maven-snapshot/mgkim/framework/framework-online/maven-metadata.xml\" $ curl -s ${XML_URL} | cat - \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cmetadata\u003e \u003cgroupId\u003emgkim.framework\u003c/groupId\u003e \u003cartifactId\u003eframework-online\u003c/artifactId\u003e \u003cversioning\u003e \u003cversions\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cversion\u003e2.0-SNAPSHOT\u003c/version\u003e \u003c/versions\u003e \u003clastUpdated\u003e20220110062815\u003c/lastUpdated\u003e \u003c/versioning\u003e \u003c/metadata\u003e $ count=$(curl -s ${XML_URL} | xmllint --xpath \"count(//version)\" -) $ echo \"count=${count}\" count=2 $ for ((i=1; i\u003c=${count}; i++)); do # --xpath '//version[$i]/text()' 일 경우 # \"XPath error : Undefined variable\" 오류가 발생합니다. echo $(curl -s ${XML_URL} | xmllint --xpath \"//version[$i]/text()\" -) done 1.0-SNAPSHOT 2.0-SNAPSHOT xmllint 는 libxml2 패키지에 포함되어 있습니다.\n$ yum provides xmllint 마지막 메타자료 만료확인 17:42:56 이전인: 2022년 01월 11일 (화) 오후 04시 01분 22초. libxml2-2.9.7-9.el8_4.2.x86_64 : Library providing XML and HTML support 리포지토리 : baseos 일치하는 항목 : 파일 이름 : /usr/bin/xmllint \n(vim) .vimrc vi ~/.vimrc 로 아래 기본 설정을 등록합니다.\n.vimrc 에는 # 주석이 오류를 일으키니 설정 시 제거해야 합니다.\n$ vi ~/.vimrc if has(\"syntax\") syntax on endif set paste # / 검색 강조 set hlsearch # 자동 들여쓰기 set autoindent set cindent # tab 설정 set ts=2 set sts=2 set shiftwidth=2 # 커서 위 괄호 강조 set showmatch # 줄번호와 행번호 표시 set ruler \n(self-signed-cert) git-bash 등록 git-bash 에서 curl 을 사용할 때 ssl 인증 문제가 발생할 경우입니다.\n$ curl https://nexus/repository/maven-release/mgkim/service/service-www/maven-metadata.xml curl: (60) SSL certificate problem: self signed certificate More details here: https://curl.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. 해당 사이트(https://nexus/)의 crt 파일을 저장하고 git-bash 에서 관리하는 ca-bundle.crt 의 끝부분에 내용을 추가합니다.\n파일 경로: C:\\Program Files\\Git\\mingw64\\ssl\\certs\\ca-bundle.crt\n(self-signed-cert) java 등록 로컬 설치된 java 에 인증서 파일(*.crt) 등록을 하기 위해서는 $JAVA_HOME/bin/keytool 를 사용해야 합니다.\nca 에 등록되지 않은 인증서로 https 통신을 하는 경우에는 ssl-handshake 과정에서 오류가 발생하므로\n해당 사이트의 인증서를 로컬 java 에 신뢰할 수 있는 인증서에 등록해야 합니다.\n아래는 hello.crt 라는 인증서를 등록하는 예시입니다.\n# 인증서 등록 # oracle java8 에서 cacerts 파일 위치 # CACERTS=$JAVA_HOME/jre/lib/security/cacerts # temurin java11 에서 cacerts 파일 위치 $ CACERTS=$JAVA_HOME/lib/security/cacerts $ keytool -importcert -keystore $CACERTS -file \"hello.crt\" -alias \"hello\" 키 저장소 비밀번호 입력: (changeit 입력) 이 인증서를 신뢰합니까? [아니오]: (y 입력) 인증서가 키 저장소에 추가되었습니다. # 인증서 조회 $ keytool -list -keystore $CACERTS | grep \"hello\" 키 저장소 비밀번호 입력: (changeit 입력) hello, 2020. 5. 8, trustedCertEntry, # 인증서 삭제 $ keytool -delete -alias \"hello\" -keystore $CACERTS nexus 를 https 로 서비스 중인 상태에서 java에 인증서를 등록하지 않았을 경우 아래와 같은 오류가 발생합니다.\nTransfer failed for http://nexus/repository/maven-snapshot/mgkim/service/service-www/2.0-SNAPSHOT/maven-metadata.xml: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target -\u003e [Help 1] jenkins 에서 빌드 시 오류가 발생하여 java 에 인증서를 추가합니다.\n$ CACERTS=$JAVA_HOME/lib/security/cacerts $ keytool -importcert -keystore $CACERTS -file /z/nexus.crt -alias 'nexus' ### `키 저장소 비밀번호` 에는 changeit 으로 입력해야 합니다. ### $ keytool -importcert -keystore $CACERTS -file /etc/httpd/conf.d/certs/nexus.crt -alias 'nexus' 경고: -cacerts 옵션을 사용하여 cacerts 키 저장소에 액세스하십시오. 키 저장소 비밀번호 입력: 소유자: CN=nexus, OU=Dev Team, O=SPACESOFT, L=Seonyudo, ST=Seoul, C=KR 발행자: CN=nexus, OU=Dev Team, O=SPACESOFT, L=Seonyudo, ST=Seoul, C=KR 일련 번호: 7aa1637941794c08365e9f9a3c531189b87f0b5e 적합한 시작 날짜: Mon Jan 10 12:15:12 KST 2022 종료 날짜: Wed Jan 10 12:15:12 KST 2024 인증서 지문: SHA1: D4:A6:92:2A:0C:97:1F:56:93:03:EC:8C:50:B3:27:5D:51:BD:30:63 SHA256: 62:BA:47:E9:3F:A6:A7:7D:78:99:87:E1:9B:E7:23:D5:B6:6B:2A:CC:5E:D9:BF:4A:DB:95:AD:67:47:70:86:96 서명 알고리즘 이름: SHA256withRSA 주체 공용 키 알고리즘: 2048비트 RSA 키 버전: 3 확장: #1: ObjectId: 2.5.29.37 Criticality=false ExtendedKeyUsages [ serverAuth ] #2: ObjectId: 2.5.29.15 Criticality=true KeyUsage [ DigitalSignature Key_Agreement ] #3: ObjectId: 2.5.29.17 Criticality=false SubjectAlternativeName [ DNSName: nexus ] 이 인증서를 신뢰합니까? [아니오]: y 인증서가 키 저장소에 추가되었습니다. $ \n(self-signed-cert) centos 등록  /etc/pki/ca-trust/source/anchors/ 경로에 crt 파일을 복사 update-ca-trust extract 실행으로 신뢰할 수 있는 인증서를 추가  $ cp /etc/httpd/conf.d/certs/nexus.crt /etc/pki/ca-trust/source/anchors/ $ update-ca-trust extract \nupdate-ca-trust 명령으로 등록이 안될 경우 직접 추가하는 방법입니다.\n/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem 파일에 crt 파일의 내용을 직접 추가합니다.\n$ chmod u+w /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem $ cat nexus.crt \u003e\u003e /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem $ chmod u-w /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem \n(shell) script 파일 디렉토리 /project/script/build.sh 파일이 실행될 때 현재 디렉토리/project/script/를 확인하는 방법입니다.\nmaven 프로젝트의 build.sh 파일이 pom.xml 과 같은 디렉토리가 아닐 경우 활용할 수 있습니다.\n# build.sh 가 존재하는 디렉토리를 반환합니다. $ DIR=\"$( cd $( dirname \"$0\" ) \u0026\u0026 pwd -P )\" $ echo \"${DIR}\" /home/user/ # build.sh 의 parent 디렉토리를 반환합니다. $ DIR=\"$( cd $( dirname \"$0\" )/.. \u0026\u0026 pwd -P )\" $ echo \"${DIR}\" /home \n(shell) process 및 port 체크 새 창 보기\nAPP_HOME=/app/WAS/pilot APP_NAME=service-www LIST=( \"dwww11\" \"dwww12\" \"swww11\" \"swww12\" ) for APP_ID in ${LIST[*]} do echo \"--- ${APP_ID}---\" PS_CMD=\"ps aux | grep -v grep | grep -v tail | grep -v .sh | grep ${APP_ID}\" eval \"${PS_CMD}\" _PID=$(eval \"${PS_CMD}| awk '{ print \\$2}'\") if [ \"${_PID}\" != \"\" ]; then netstat -ntplu | grep ${_PID} SERVER_PORT=$(netstat -tnplu | grep ${_PID} | awk '{ if (match($4, /([0-9]*)$/, m)) print m[0] }') if [ \"${SERVER_PORT}\" != \"\" ]; then HTTP_CODE=$(curl --write-out \"%{http_code}\" --silent --output /dev/null \"http://localhost:${SERVER_PORT}/\") if [ \"${HTTP_CODE}\" == \"200\" ]; then echo \"${APP_ID}is avaiable. (SERVER_PORT=${SERVER_PORT})\" else echo \"${APP_ID}is not avaiable. (SERVER_PORT=${SERVER_PORT})\" fi else echo \"${APP_ID}is not avaiable.\" fi else echo \"${APP_ID}is not running\" fi echo \"\" done (shell) find newer samefile 오래된 파일을 찾을 경우, 기준이되는 파일은 제외하는 예시입니다.\n# 기준이 되는 파일을 생성 (e.g 1981년 07월 19일) $ touch -t 198107190000.00 a.txt $ ls -al a.txt # alias ls='ls --time-style long-iso ' 일 경우 시각까지 표시됨 -rw-r--r-- 1 root root 0 1981-07-19 00:00 a.txt # 기준보다 오래된 파일 생성 $ touch -t 198101010000 old.txt $ ls -al old.txt -rw-r--r-- 1 root root 0 1981-01-01 00:00 old.txt # find 검색 (a.txt 파일보다 오래된 파일을 찾음) $ find . -maxdepth 1 -type f ! -newer a.txt -name '*.txt' ./a.txt ./old.txt # find 검색 (기준이 되는 파일을 제외하고 찾음) # -samefile 혹은 -name 해도됨 $ find . -maxdepth 1 -type f ! -newer a.txt -name '*.txt' ! -samefile a.txt ./old.txt \n(shell) curl curl 로 http_code 를 받아오는 예시 입니다.\n이 예시는 was 가 정상 기동되었는지 확인하는데 활용할 수 있습니다.\n$ curl --write-out \"%{http_code}\" --silent --output /dev/null \"http://localhost:7100/\" 200 # 서버가 기동되지 않은 상태이면 즉시 응답이 오며, http_code 는 000 가 반환됩니다. \n(shell) 파일명 문자열 # 파일명에서 확장자 분리 $ FILE_NAME=service-www-2.0-SNAPSHOT.jar $ echo ${FILE_NAME%.*} service-www-2.0-SNAPSHOT $ echo ${FILE_NAME##*.} jar # 파일경로에서 파일명 $ FILE_PATH=/app/WAS/pilot/service-www-2.0-SNAPSHOT.jar $ echo ${FILE_PATH##*/} service-www-2.0-SNAPSHOT.jar \n(shell) while 문 PS_CMD=\"ps -ef | grep -v grep | egrep ${INST_ID}.*\\\\.jar | awk '{ print \\$2 }'\" _PID=$(eval \"${PS_CMD}\") # kill -15 실행 kill -15 $_PID # 프로세스가 종료되었는지 while 문에서 확인 while [ $i -lt 600 ]; do _CHECK_PID=$(eval \"${PS_CMD}\") if [ \"${_CHECK_PID}\" == \"\" ]; then echo \"${INST_ID}(pid:'${_PID}') killed\" break fi i=$(( $i + 1 )) done \n(shell) for 문 배열을 생성하고 for 문으로 출력하는 예시 입니다.\nSVR_LIST=( '172.28.200.20' '172.28.200.30' ) echo \"SVR_LIST=${SVR_LIST[*]}\" total=${#SVR_LIST[*]} idx=0 for SVR in ${SVR_LIST[*]} do idx=$(( $idx + 1 )) echo \"[${idx}/${total}]SVR=${SVR}\" done \n(shell) case 문 case $var in a*) # a로 시작하는 문자열일 경우 ;; a?) # a뒤에 1개의 문자가 올 경우 ;; a[bc]) # ab 혹은 ac 일 경우 ;; esac \n(tomcat) start/stop jamwiki 라는 webapp 을 서비스하는 tomcat 설정 기본입니다.\n아래 sh 파일을 포함하여 tomcat 설정에 필요한 파일들만 tgz 로 압축했습니다.\n다운로드\nstart.sh 파일\n#!/bin/sh  PROD_HOME=/prod/${INST_ID} DATA_HOME=/data/PROD/${INST_ID} LOG_HOME=/outlog/PROD/${INST_ID} EXE_USER=tomcat PS_CMD=\"ps -ef | grep -v grep | grep -v '.sh' | grep -v rotatelogs | grep -v tail | grep ${INST_ID}\" CATALINA_BASE=/prod/${INST_ID}/config CATALINA_OUT=${LOG_HOME}/catalina.out JAVA_OPTS=\"${JAVA_OPTS}-Xms256m -Xmx256m\" JAVA_OPTS=\"${JAVA_OPTS}-Djava.net.preferIPv4Stack=true\" export CATALINA_BASE export CATALINA_OUT export JAVA_OPTS if [ ! -e ${LOG_HOME}/backup ]; then su ${EXE_USER} -c 'mkdir -p ${LOG_HOME}/backup' fi if [ -e ${LOG_HOME}/catalina.out ]; then mv ${LOG_HOME}/catalina.out ${LOG_HOME}/backup/catalina.out_`date +'%Y%m%d_%H%M%S'` fi _PID=`eval ${PS_CMD} | awk '{ print $2 }'` if [ \"${_PID}\" != \"\" ]; then echo \"${INST_ID}is already running. pid: ${_PID}\" ${PROD_HOME}/stop-${INST_ID}.sh fi sleep 2 if [ ${EXE_USER} != `whoami` ]; then su ${EXE_USER} -c '/prod/${INST_ID}/tomcat/bin/startup.sh' else /prod/${INST_ID}/tomcat/bin/startup.sh fi _PID=`eval ${PS_CMD} | awk '{ print $2 }'` if [ \"${_PID}\" != \"\" ]; then echo \"${INST_ID}is starting. pid: ${_PID}\" echo \"ps -ef | grep ${_PID}\" echo \"netstat -ntplu | grep ${_PID}\" else echo \"${INST_ID}is not started\" fi exit 0 \nstart-jamwiki.sh 파일\n#!/bin/sh  # configuration export JAVA_HOME=/prod/java/jdk1.8.0_202 export PATH=$JAVA_HOME/bin:$PATH export INST_ID=jamwiki /prod/${INST_ID}/bin/start.sh exit 0 \nstop.sh 파일\n#!/bin/sh  PROD_HOME=/prod/${INST_ID} DATA_HOME=/data/PROD/${INST_ID} LOG_HOME=/outlog/PROD/${INST_ID} EXE_USER=tomcat PS_CMD=\"ps -ef | grep -v grep | grep -v '.sh' | grep -v rotatelogs | grep -v tail | grep ${INST_ID}\" CATALINA_BASE=/prod/${INST_ID}/config export CATALINA_BASE _PID=`eval ${PS_CMD} | awk '{ print $2 }'` if [ \"${_PID}\" == \"\" ]; then echo \"${INST_ID}is not running\" exit 0 fi sleep 2 if [ ${EXE_USER} != `whoami` ]; then su ${EXE_USER} -c '/prod/${INST_ID}/tomcat/bin/shutdown.sh' else /prod/${INST_ID}/tomcat/bin/shutdown.sh fi echo \"${INST_ID}is stopped. pid: ${_PID}\" exit 0 \nstop-jamwiki.sh 파일\n#!/bin/sh  # configuration export INST_ID=jamwiki /prod/${INST_ID}/bin/stop.sh exit 0 \nstatus-jamwiki.sh 파일\n#!/bin/sh  echo \"---------------- jamwiki ----------------\" ps -ef | grep -v grep | grep -v '.sh' | grep -v rotatelogs | grep -v tail | grep jamwiki echo \"\" exit 0 \n(cockpit) cockpit 은 centos 의 web console 을 제공하는 패키지 입니다.\n설치\n$ dnf install cockpit $ systemctl enable --now cockpit.socket $ netstat -ntplu | grep 9090 cockpit 에 ssl 인증서 교체하기\n참고: create-cert.sh\n# create-cert.sh 로 인증서를 생성합니다. # 인자는 web console 에 접근할 도메인으로 생성하면 됩니다. # 예시는 centos8 이라는 도메인으로 생성합니다. $ ./create-cert.sh centos8 $ ls -al -rw-r--r-- 1 root root 1310 1월 2 14:58 centos8.crt -rw------- 1 root root 1708 1월 2 14:58 centos8.key $ cd /etc/cockpit/ws-certs.d $ ls -al -rw-r--r-- 1 root root 2094 1월 2 00:46 0-self-signed-ca.pem -rw-r--r-- 1 root root 1684 1월 2 00:46 0-self-signed.cert -rw-r----- 1 root cockpit-ws 1704 1월 2 00:46 0-self-signed.key $ cp centos8.crt centos8.key /etc/cockpit/ws-certs.d $ chmod 640 centos8.key $ chown root:cockpit-ws centos8.key $ chmod 644 centos8.crt $ remotectl certificate centos8.crt centos8.key generated combined certificate file: /etc/cockpit/ws-certs.d/centos8.cert $ remotectl certificate certificate: /etc/cockpit/ws-certs.d/centos8.crt $ systemctl restart cockpit \ncentos8 인증서 등록하기\nhttps://centos8:9090/ 링크로 이동하면 신뢰할 수 없는 사이트라고 표시됩니다.\n인증서를 내보내기 한 다음 아래 절차대로 인증서를 등록합니다.\n chrome 에서 chrome://settings/security?q=enhanced 링크로 이동합니다. 인증서 관리 메뉴를 클릭하면 팝업이 열립니다. 신뢰할 수 있는 루트 인증 기관 탭에서 가져오기를 클릭 합니다. 내보내기 한 인증서를 선택하고 가져오기를 합니다. chrome 에서 chrome://net-internals/#hsts 링크로 이동합니다. Delete domain security policies 에서 centos8 을 입력하고 Delete 버튼을 클릭합니다. chrome 에서 chrome://restart 링크 이동으로 chrome 을 재시작합니다. chrome 에서 https://centos8:9090/ 링크로 이동하여 정상 작동하는지를 확인합니다.  정상 예시\n새 창 보기\nlisten-port 변경하기\n/etc/systemd/system/sockets.target.wants/cockpit.socket 파일을 아래와 같이 편집합니다.\n[Unit] Description=Cockpit Web Service Socket Documentation=man:cockpit-ws(8) Wants=cockpit-motd.service [Socket] #ListenStream=9090 # 기본값 ListenStream=127.0.0.1:8000 # 변경값 (httpd 에서 proxy 로 접근) ExecStartPost=-/usr/share/cockpit/motd/update-motd '' localhost ExecStartPost=-/bin/ln -snf active.motd /run/cockpit/motd ExecStopPost=-/bin/ln -snf inactive.motd /run/cockpit/motd [Install] WantedBy=sockets.target redhat 공식문서에서는 /etc/systemd/system/cockpit.socket.d/listen.conf 파일을 생성하고 daemon-reload 를 하라고 되어있습니다.\n[Socket] ListenStream= ListenStream=127.0.0.1:8000 FreeBind=yes www.freedesktop.org에서는 아래와 같이 FreeBind=yes 를 권장한다고 되어있습니다.\nIf an IP address is used here, it is often desirable to listen on it before the interface it is configured on is up and running, and even regardless of whether it will be up and running at any point. To deal with this, it is recommended to set the FreeBind= option described below. 편집 후 아래 명령어를 실행합니다.\n$ systemctl daemon-reload cockpit.socket $ systemctl restart cockpit.socket # 변경 상태를 확인합니다. $ netstat -ntplu | grep 8000 (mosh) 설치\n$ yum install mosh 상태\n# 접속 후 netstat 상태 보기 $ mosh root@172.28.200.30 $ netstat -ntplu | grep 3253 udp 0 0 172.28.200.30:60001 0.0.0.0:* 3253/mosh-server $ netstat -ntplu | grep 3217 udp 0 0 0.0.0.0:19001 0.0.0.0:* 3217/mosh-client # 접속 옵션 $ mosh -ssh='ssh -vvv' root@172.28.200.30 chrome 확장 프로그램 Secure Shell\n링크\n(xmlstarlet) 설치\n$ dnf install epel-release $ yum install xmlstarlet 사용법\nxmlstarlet sel -N x=\"http://maven.apache.org/POM/4.0.0\" -t -v \"x:project/x:version\" ./pom.xml \n(oracle) 12c 설치 oracle 12c ee 버전 설치\npluggable database 설정, MAX_STRING_SIZE 설정, character-set 설정, oracle 계정 설정\n새 창 보기\n(yum) 설치된 목록 확인 yum list installed\n(firewall) disabled 추가된 목록: /etc/firewalld/zones/public.xml\n서비스명: firewalld\n(selinux) disabled 파일: /etc/selinux/config\nSELINUX=disabled 적용: shutdown -r now\n(network) ip 설정 파일: /etc/sysconfig/network-scripts/ifcfg-ens33\nBOOTPROTO=\"none\" IPV6INIT=\"no\" IPADDR=\"172.28.200.30\" PREFIX=\"24\" GATEWAY=\"172.28.200.2\" DNS1=\"8.8.8.8\" 적용: systemctl restart NetworkManager\n(openssl) key 생성 cmd # 암호화하지 않은 개인키 $ openssl genrsa -out private_key.pem 2048 # 3des로 암호화된 개인키 생성 # passphrase를 입력이 필요합니다. $ openssl genrsa -des3 -out enc_private_key.pem 2048 # 기존 개인키에 패스워드 추가 $ openssl rsa -des3 -in private_key.pem -out enc_private_key.pem # 기존 개인키에 패스워드 제거 $ openssl rsa -in enc_private_key.pem -out private_key.pem \n(sed) 문자열 치환 $ sed -i -e 's/hello/world/g' test.txt \n(tar) 분할 압축 # split $ tar cvfz - target | split -b 3072m - target.tgz $ cat target.tgz.* | tar zxvf - \n(tar) exclude 설정 # exclude $ cat .tarexclude build.* run.* bin .svn/* .git/* .project .tarexclude backup.sh $ tar cvfz ../target.tgz * -X .tarexclude \n(httpd) 설정 httpd.conf, vhost 설정, ssl 적용에 대한 예시\n새 창 보기\n(jenkins) 설정 플러그인 Publish Over SSH, GitLab Plugin, GitHub Integration Plugin에 대한 사용법\n새 창 보기\n","categories":"","description":"","excerpt":"(systemctl) Requires 속성 logstash 서비스를 elasticsearch 서비스의 종속으로 구성해야할 필요 …","ref":"/system/","tags":"","title":"system"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"}]